<!DOCTYPE html>
<!-- saved from url=(0198)https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/branch-latest.min.js.下載"></script><script>!function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a="pointerup",u="pointercancel";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;"pointerdown"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)}}function w(e){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(n){e(n,l,r)})}w(c),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){e.push(n),s()}}(addEventListener,removeEventListener)</script><title>機器/深度學習-基礎數學(二):梯度下降法(gradient descent) - Tommy Huang - Medium</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2019-04-18T08:09:11.949Z"><meta data-rh="true" name="title" content="機器/深度學習-基礎數學(二):梯度下降法(gradient descent) - Tommy Huang - Medium"><meta data-rh="true" property="og:title" content="機器/深度學習-基礎數學(二):梯度下降法(gradient descent)"><meta data-rh="true" property="twitter:title" content="機器/深度學習-基礎數學(二):梯度下降法(gradient descent)"><meta data-rh="true" name="twitter:site" content="@Medium"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/406e1fd001f"><meta data-rh="true" property="al:android:url" content="medium://p/406e1fd001f"><meta data-rh="true" property="al:ios:url" content="medium://p/406e1fd001f"><meta data-rh="true" name="apple-itunes-app" content="app-id=828256236,app-argument=medium://p/406e1fd001f"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="機器/深度學習-基礎數學篇(一):純量、向量、矩陣、矩陣運算、逆矩陣、矩陣轉置介紹
機器/深度學習-基礎數學(二):梯度下降法(gradient descent)
機器/深度學習-基礎數學(三):梯度最佳解相關算法(gradient descent optimization algorithms) 梯度下降法(gradient…"><meta data-rh="true" property="og:description" content="其他相關連結"><meta data-rh="true" property="twitter:description" content="其他相關連結"><meta data-rh="true" property="og:url" content="https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f"><meta data-rh="true" property="al:web:url" content="https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f"><meta data-rh="true" property="og:image" content="https://miro.medium.com/freeze/max/560/1*ohVPiStlsbMP0XL1_X-fkQ.gif"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/freeze/max/560/1*ohVPiStlsbMP0XL1_X-fkQ.gif"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="/@chih.sheng.huang821"><meta data-rh="true" name="author" content="Tommy Huang"><meta data-rh="true" name="robots" content="index,follow"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" value="Reading time"><meta data-rh="true" name="twitter:data1" value="7 min read"><meta data-rh="true" name="parsely-post-id" content="406e1fd001f"><link data-rh="true" rel="publisher" href="https://plus.google.com/103654360130207659246"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><link data-rh="true" rel="icon" href="https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/m2.css"><link data-rh="true" rel="author" href="https://medium.com/@chih.sheng.huang821"><link data-rh="true" rel="canonical" href="https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/406e1fd001f"><style type="text/css" data-fela-rehydration="400" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@-moz-keyframes k1{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@keyframes k1{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:fixed}.n{top:0}.o{left:0}.p{right:0}.q{z-index:500}.r{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.s{transition:transform 300ms ease}.t{will-change:transform}.v{margin-left:auto}.w{margin-right:auto}.x{width:100%}.y{box-sizing:border-box}.aq{height:65px}.ar{display:flex}.as{align-items:center}.av{flex:1 0 auto}.aw{display:none}.ax{fill:rgba(0, 0, 0, 0.84)}.ba{flex:0 0 auto}.bb{color:inherit}.bc{fill:inherit}.bd{font-size:inherit}.be{border:inherit}.bf{font-family:inherit}.bg{letter-spacing:inherit}.bh{font-weight:inherit}.bi{padding:0}.bj{margin:0}.bk:hover{cursor:pointer}.bl:hover{color:rgba(0, 0, 0, 0.9)}.bm:hover{fill:rgba(0, 0, 0, 0.9)}.bn:focus{outline:none}.bo:disabled{cursor:default}.bp:disabled{color:rgba(0, 0, 0, 0.54)}.bq:disabled{fill:rgba(0, 0, 0, 0.54)}.br{font-family:medium-content-sans-serif-font, "Lucida Grande", "Lucida Sans Unicode", "Lucida Sans", Geneva, Arial, sans-serif}.bs{font-style:normal}.bt{line-height:20px}.bu{font-size:15.8px}.bv{letter-spacing:0px}.bw{color:rgba(0, 0, 0, 0.54)}.bx{fill:rgba(0, 0, 0, 0.54)}.by{margin-left:16px}.bz{color:rgba(2, 158, 116, 1)}.ca{fill:rgba(3, 168, 124, 1)}.cb:hover{color:rgba(1, 143, 105, 1)}.cc:hover{fill:rgba(2, 158, 116, 1)}.cd:disabled{color:rgba(3, 168, 124, 0.5)}.ce:disabled{fill:rgba(3, 168, 124, 0.5)}.cf{padding:8px 16px}.cg{background:0}.ch{border-color:rgba(3, 168, 124, 1)}.ci:hover{border-color:rgba(2, 158, 116, 1)}.cj{border-radius:4px}.ck{border-width:1px}.cl{border-style:solid}.cm{display:inline-block}.cn{text-decoration:none}.co{margin-bottom:0px}.cq{padding-left:24px}.cr{padding-right:24px}.cs{max-width:728px}.ct{flex-direction:column}.cu{opacity:0}.cv{pointer-events:none}.cw{will-change:opacity}.cx{transition:opacity 200ms}.cy{width:131px}.cz{left:50%}.da{transform:translateX(-516px)}.db{top:calc(65px + 54px + 40px)}.dc{padding-top:28px}.dd{margin-bottom:19px}.de{margin-left:-5px}.df{margin-right:5px}.dg{position:relative}.dh{outline:0}.di{border:0}.dj{user-select:none}.dk{cursor:pointer}.dl> svg{pointer-events:none}.dm:active{border-style:none}.dn{-webkit-user-select:none}.do{fill:rgba(0, 0, 0, 0.76)}.dp:focus{fill:rgba(0, 0, 0, 0.54)}.dq:hover{fill:rgba(0, 0, 0, 0.54)}.dr{margin-top:5px}.ds button{text-align:left}.dt{font-weight:300}.du{font-size:16px}.dv{margin-top:40px}.dw{clear:both}.dx{justify-content:center}.ed{max-width:680px}.ee{flex-wrap:wrap}.ef{margin-top:25px}.eg{margin-top:15px}.eh{justify-content:space-between}.ei{margin-right:16px}.ej{border:1px solid rgba(0, 0, 0, 0.1)}.ek{border-radius:50%}.el{height:60px}.em{transition:border-color 150ms ease}.en{width:60px}.eo:hover{border-color:rgba(0, 0, 0, 0.54)}.ep::before{background:
      radial-gradient(circle, rgba(0, 0, 0, 0.84) 60%, transparent 70%)
    }.eq::before{border-radius:50%}.er::before{content:""}.es::before{display:block}.et::before{z-index:0}.eu::before{left:0}.ev::before{height:100%}.ew::before{position:absolute}.ex::before{top:0}.ey::before{width:100%}.ez:hover::before{animation:k1 2000ms infinite cubic-bezier(.1,.12,.25,1)}.fa:active{border-style:solid}.fb{background:rgba(255, 255, 255, 1)}.fc{transition:fill 200ms ease}.fd{z-index:2}.fe{height:100%}.ff{position:absolute}.fg{color:rgba(0, 0, 0, 0.84)}.fh{padding-right:8px}.fi{padding-top:32px}.fj{border-top:1px solid rgba(0, 0, 0, 0.1)}.fk{margin-bottom:25px}.fl{margin-bottom:32px}.fm{min-height:80px}.fr{height:80px}.fs{width:80px}.ft{padding-left:102px}.fv{font-size:15px}.fw{text-transform:uppercase}.fx{letter-spacing:0.05em}.fy{margin-bottom:6px}.fz{font-weight:600}.ga{font-size:28px}.gb{line-height:36px}.gc{padding:4px 12px}.gd{border-color:rgba(0, 0, 0, 0.54)}.ge:hover{color:rgba(0, 0, 0, 0.97)}.gf:hover{fill:rgba(0, 0, 0, 0.97)}.gg:hover{border-color:rgba(0, 0, 0, 0.84)}.gh:disabled{fill:rgba(0, 0, 0, 0.76)}.gi:disabled{border-color:rgba(0, 0, 0, 0.2)}.gj:disabled{cursor:inherit}.gk:disabled:hover{color:rgba(0, 0, 0, 0.54)}.gl:disabled:hover{fill:rgba(0, 0, 0, 0.76)}.gm:disabled:hover{border-color:rgba(0, 0, 0, 0.2)}.gn{max-width:555px}.go{max-width:450px}.gp{font-size:18px}.gq{line-height:24px}.gs{padding-top:25px}.gt{padding:20px}.gu{border:1px solid rgba(3, 168, 124, 1)}.gv{border-radius:3px}.gw{text-align:center}.gx{margin-top:64px}.gy{background-color:rgba(0, 0, 0, 0.02)}.gz{max-width:1032px}.ha{padding:60px 0}.hb{background-color:rgba(0, 0, 0, 0.9)}.hd{padding-bottom:48px}.he{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.hf{margin:0 -12px}.hg{margin:0 12px}.hh{flex:1 1 0}.hi{padding-bottom:12px}.hj:hover{color:rgba(255, 255, 255, 0.99)}.hk:hover{fill:rgba(255, 255, 255, 0.99)}.hl:disabled{color:rgba(255, 255, 255, 0.7)}.hm:disabled{fill:rgba(255, 255, 255, 0.7)}.hn{color:rgba(255, 255, 255, 0.98)}.ho{fill:rgba(255, 255, 255, 0.98)}.hp{text-align:inherit}.hq{font-size:21.6px}.hr{letter-spacing:-0.32px}.hs{color:rgba(255, 255, 255, 0.7)}.ht{fill:rgba(255, 255, 255, 0.7)}.hu{text-decoration:underline}.hv{padding-bottom:8px}.hw{padding-top:8px}.hx{width:200px}.hz:hover{text-decoration:underline}.ia{top:calc(100vh + 100px)}.ib{bottom:calc(100vh + 100px)}.ic{width:10px}.id{word-break:break-word}.ie{word-wrap:break-word}.if:after{display:block}.ig:after{content:""}.ih:after{clear:both}.ii{margin:0 auto}.ij{line-height:1.23}.ik{letter-spacing:0}.il{font-family:medium-content-title-font, Georgia, Cambria, "Times New Roman", Times, serif}.im{font-size:40px}.is{margin-bottom:-0.27em}.it{line-height:48px}.iu{margin-top:32px}.iv{height:48px}.iw{width:48px}.ix{margin-left:12px}.iy{margin-bottom:2px}.ja{overflow:hidden}.jb{max-height:20px}.jc{text-overflow:ellipsis}.jd{display:-webkit-box}.je{-webkit-line-clamp:1}.jf{-webkit-box-orient:vertical}.jg{margin-left:8px}.jh{padding:0px 8px}.ji{line-height:18px}.jj{font-family:medium-content-slab-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.jk{border:none}.jl{margin-top:30px}.jm:before{content:"..."}.jn:before{letter-spacing:0.6em}.jo:before{text-indent:0.6em}.jp:before{font-style:italic}.jq:before{line-height:1.4}.jr{line-height:1.58}.js{letter-spacing:-0.004em}.jt{font-family:medium-content-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.ke{margin-bottom:-0.46em}.kf{background-repeat:repeat-x}.kg{background-image:linear-gradient(to right,rgba(0, 0, 0, 0.84) 100%,rgba(0, 0, 0, 0.84) 0);background-image:url('data:image/svg+xml;utf8,<svg preserveAspectRatio="none" viewBox="0 0 1 1" xmlns="http://www.w3.org/2000/svg"><line x1="0" y1="0" x2="1" y2="1" stroke="rgba(0, 0, 0, 0.84)" /></svg>')}.kh{background-size:1px 1px}.ki{background-position:0 1.05em;background-position:0 calc(1em + 1px)}.ko{max-width:378px}.kp{transition:opacity 100ms 400ms}.kq{transform:translateZ(0)}.kr{margin:auto}.ks{background-color:rgba(0, 0, 0, 0.05)}.kt{padding-bottom:17.98941798941799%}.ku{filter:blur(20px)}.kv{transform:scale(1.1)}.kw{visibility:visible}.kx{padding-bottom:22.88888888888889%}.ky{max-width:526px}.kz{padding-bottom:28.136882129277566%}.la{max-width:444px}.lb{padding-bottom:23.1981981981982%}.lc{font-style:italic}.ld{font-weight:700}.le{line-height:1.12}.lf{letter-spacing:-0.022em}.lq{margin-bottom:-0.28em}.lw{padding-left:30px}.lx{line-height:1.48}.ly{letter-spacing:-0.014em}.lz{color:rgba(0, 0, 0, 0.76)}.ma{font-size:24px}.mg{font-size:30px}.mh{line-height:44px}.mi{font-style:inherit}.mo{max-width:472px}.mp{padding-bottom:74.57627118644068%}.mq{max-width:538px}.mr{padding-bottom:16.91449814126394%}.ms{max-width:1000px}.mt{padding-bottom:34.1%}.mu{padding-bottom:73.2%}.mv{line-height:1.18}.ng{margin-bottom:-0.31em}.nh{max-width:446px}.ni{padding-bottom:16.367713004484305%}.nj{max-width:720px}.nk{padding-bottom:28.194444444444443%}.nl{max-width:561px}.nm{padding-bottom:74.86631016042782%}.nn{line-height:1.4}.no{margin-top:10px}.nr{max-width:1008px}.ns{padding-bottom:24.8015873015873%}.od{max-width:560px}.oe{padding-bottom:75%}.of{margin-top:0px}.og{max-width:856px}.oh{padding-bottom:38.55140186915888%}.oi{padding-bottom:45.2%}.oj{max-width:544px}.ok{padding-bottom:16.727941176470587%}.ol{-webkit-user-select:none}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.an{padding-left:24px}.ao{padding-right:24px}.ap{max-width:1080px}.ec{margin:0 24px}.ir{margin-top:0.78em}.kc{font-size:21px}.kd{margin-top:2em}.kn{margin-top:56px}.lo{font-size:34px}.lp{margin-top:1.25em}.lv{margin-top:0.86em}.mf{margin-top:2.75em}.mn{margin-top:3.14em}.ne{font-size:26px}.nf{margin-top:1.72em}.nx{margin-top:1.75em}.oc{margin-top:80px}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ak{padding-left:24px}.al{padding-right:24px}.am{max-width:1080px}.np{margin-left:auto}.nq{text-align:center}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.ah{padding-left:24px}.ai{padding-right:24px}.aj{max-width:904px}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.ae{padding-left:24px}.af{padding-right:24px}.ag{max-width:728px}.at{height:56px}.au{display:flex}.ay{margin-left:-5px}.az{display:block}.cp{margin-bottom:0px}.fn{margin-bottom:24px}.fo{align-items:center}.fp{width:102px}.fq{position:relative}.fu{padding-left:0}.gr{margin-top:24px}.hc{padding:32px 0}.hy{width:140px}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.z{padding-left:24px}.ab{padding-right:24px}.ac{max-width:552px}.dy{margin:0 24px}.in{margin-top:0.39em}.iz{margin-bottom:0px}.ju{font-size:18px}.jv{margin-top:1.56em}.kj{margin-top:40px}.lg{font-size:30px}.lh{margin-top:0.93em}.lr{margin-top:0.67em}.mb{margin-top:1.42em}.mj{margin-top:2em}.mw{font-size:24px}.mx{margin-top:1.23em}.nt{margin-top:1.08em}.ny{margin-top:48px}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.eb{margin:0 24px}.iq{margin-top:0.78em}.ka{font-size:21px}.kb{margin-top:2em}.km{margin-top:56px}.lm{font-size:34px}.ln{margin-top:1.25em}.lu{margin-top:0.86em}.me{margin-top:2.75em}.mm{margin-top:3.14em}.nc{font-size:26px}.nd{margin-top:1.72em}.nw{margin-top:1.75em}.ob{margin-top:80px}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.ea{margin:0 24px}.ip{margin-top:0.78em}.jy{font-size:21px}.jz{margin-top:2em}.kl{margin-top:56px}.lk{font-size:34px}.ll{margin-top:1.25em}.lt{margin-top:0.86em}.md{margin-top:2.75em}.ml{margin-top:3.14em}.na{font-size:26px}.nb{margin-top:1.72em}.nv{margin-top:1.75em}.oa{margin-top:80px}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.dz{margin:0 24px}.io{margin-top:0.39em}.jw{font-size:18px}.jx{margin-top:1.56em}.kk{margin-top:40px}.li{font-size:30px}.lj{margin-top:0.93em}.ls{margin-top:0.67em}.mc{margin-top:1.42em}.mk{margin-top:2em}.my{font-size:24px}.mz{margin-top:1.23em}.nu{margin-top:1.08em}.nz{margin-top:48px}</style><style type="text/css" data-fela-rehydration="400" data-fela-type="RULE" media="print">.u{display:none}</style><script charset="utf-8" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/vendors_tracing.eaae9f79.chunk.js.下載"></script><script charset="utf-8" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/tracing.8a1ef8a7.chunk.js.下載"></script><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Ffreeze\u002Fmax\u002F1200\u002F1*ohVPiStlsbMP0XL1_X-fkQ.gif"],"url":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f","dateCreated":"2018-07-25T09:53:16.952Z","datePublished":"2018-07-25T09:53:16.952Z","dateModified":"2019-04-18T08:09:11.949Z","headline":"機器\u002F深度學習-基礎數學(二):梯度下降法(gradient descent)","name":"機器\u002F深度學習-基礎數學(二):梯度下降法(gradient descent)","description":"機器\u002F深度學習-基礎數學篇(一):純量、向量、矩陣、矩陣運算、逆矩陣、矩陣轉置介紹\n機器\u002F深度學習-基礎數學(二):梯度下降法(gradient descent)\n機器\u002F深度學習-基礎數學(三):梯度最佳解相關算法(gradient descent optimization algorithms) 梯度下降法(gradient…","identifier":"406e1fd001f","keywords":["Lite:true","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:0"],"author":{"@type":"Person","name":"Tommy Huang","url":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821"},"creator":["Tommy Huang"],"publisher":{"@type":"Organization","name":"Medium","url":"https:\u002F\u002Fmedium.com\u002F","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F308\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f"}</script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><nav class="l m n o p c q r s t u"><div class="branch-journeys-top"><section class="v w x y l z ab ac ae af ag ah ai aj ak al am an ao ap"><div class="aq ar as at au"><div class="l av q"><div class="ar as"><a href="https://medium.com/?source=post_page-----406e1fd001f----------------------" aria-label="Homepage"><div class="aw g"><svg height="22" width="112" viewBox="0 0 111.5 22" class="ax"><path d="M56.3 19.5c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5V19c-.7 1.8-2.4 3-4.3 3-3.3 0-5.8-2.6-5.8-7.5 0-4.5 2.6-7.6 6.3-7.6 1.6-.1 3.1.8 3.8 2.4V3.2c0-.3-.1-.6-.3-.7l-1.4-1.4V1l6.5-.8v19.3zm-4.8-.8V9.5c-.5-.6-1.2-.9-1.9-.9-1.6 0-3.1 1.4-3.1 5.7 0 4 1.3 5.4 3 5.4.8.1 1.6-.3 2-1zm9.1 3.1V9.4c0-.3-.1-.6-.3-.7l-1.4-1.5v-.1h6.5v12.5c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5zm-.2-19.2C60.4 1.2 61.5 0 63 0c1.4 0 2.6 1.2 2.6 2.6S64.4 5.3 63 5.3a2.6 2.6 0 0 1-2.6-2.7zm22.5 16.9c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5v-3.2c-.6 2-2.4 3.4-4.5 3.4-2.9 0-4.4-2.1-4.4-6.2 0-1.9 0-4.1.1-6.5 0-.3-.1-.5-.3-.7L67.7 7v.1H74v8c0 2.6.4 4.4 2 4.4.9-.1 1.7-.6 2.1-1.3V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v12.4zm22 2.3c0-.5.1-6.5.1-7.9 0-2.6-.4-4.5-2.2-4.5-.9 0-1.8.5-2.3 1.3.2.8.3 1.7.3 2.5 0 1.8-.1 4.2-.1 6.5 0 .3.1.5.3.7l1.5 1.4v.1H96c0-.4.1-6.5.1-7.9 0-2.7-.4-4.5-2.2-4.5-.9 0-1.7.5-2.2 1.3v9c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v3.1a4.6 4.6 0 0 1 4.6-3.4c2.2 0 3.6 1.2 4.2 3.5.7-2.1 2.7-3.6 4.9-3.5 2.9 0 4.5 2.2 4.5 6.2 0 1.9-.1 4.2-.1 6.5-.1.3.1.6.3.7l1.4 1.4v.1h-6.6zm-81.4-2l1.9 1.9v.1h-9.8v-.1l2-1.9c.2-.2.3-.4.3-.7V7.3c0-.5 0-1.2.1-1.8L11.4 22h-.1L4.5 6.8c-.1-.4-.2-.4-.3-.6v10c-.1.7 0 1.3.3 1.9l2.7 3.6v.1H0v-.1L2.7 18c.3-.6.4-1.3.3-1.9v-11c0-.5-.1-1.1-.5-1.5L.7 1.1V1h7l5.8 12.9L18.6 1h6.8v.1l-1.9 2.2c-.2.2-.3.5-.3.7v15.2c0 .2.1.5.3.6zm7.6-5.9c0 3.8 1.9 5.3 4.2 5.3 1.9.1 3.6-1 4.4-2.7h.1c-.8 3.7-3.1 5.5-6.5 5.5-3.7 0-7.2-2.2-7.2-7.4 0-5.5 3.5-7.6 7.3-7.6 3.1 0 6.4 1.5 6.4 6.2v.8h-8.7zm0-.8h4.3v-.8c0-3.9-.8-4.9-2-4.9-1.4.1-2.3 1.6-2.3 5.7z"></path></svg></div><div class="l ay az"><svg width="45" height="45" viewBox="0 0 45 45" class="ax"><path d="M5 40V5h35v35H5zm8.56-12.63c0 .56-.03.69-.32 1.03L10.8 31.4v.4h6.97v-.4L15.3 28.4c-.29-.34-.34-.5-.34-1.03v-8.95l6.13 13.36h.71l5.26-13.36v10.64c0 .3 0 .35-.19.53l-1.85 1.8v.4h9.2v-.4l-1.83-1.8c-.18-.18-.2-.24-.2-.53V15.94c0-.3.02-.35.2-.53l1.82-1.8v-.4h-6.47l-4.62 11.55-5.2-11.54h-6.8v.4l2.15 2.63c.24.3.29.37.29.77v10.35z"></path></svg></div></a></div></div><div class="l ba q"><div class="ar as"><div class="ar g"><div><a href="https://medium.com/membership?source=upgrade_membership---nav_full------------------------" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><span class="br b bs bt bu bv l bw bx">Become a member</span></a></div><div class="by l"><span class="br b bs bt bu bv l bw bx"><a href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_page-----406e1fd001f---------------------nav_reg-" class="bz ca bd be bf bg bh bi bj bk cb cc bn bo cd ce">Sign in</a></span></div></div><div class="by l"><button class="cf cg bz ca ch cb cc ci bk cj br b bs bt bu bv ck cl y cm cn bn">Get started</button></div></div></div></div></section></div></nav><div class="co aq l cp at"></div><article><section class="cq cr v w x cs y ar ct"></section><span class="l"></span><div><div class="ff o ia ib ic cv"></div><section class="id ie if ig ih"><div class="y ii x cs cq cr"><div><div id="347b" class="ij ik fg bs il b im in io ip iq ir is"><h1 class="il b im it fg">機器/深度學習-基礎數學(二):梯度下降法(gradient descent)</h1></div><div class="iu"><div class="as ar"><div><a href="https://medium.com/@chih.sheng.huang821?source=post_page-----406e1fd001f----------------------"><img alt="Tommy Huang" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_d_eKs6OyA07h7e8tXxj5OA.jpeg" class="l ek iv iw" width="48" height="48"></a></div><div class="ix x l"><div class="ar"><div style="flex:1"><span class="br b bs bt bu bv l fg ax"><div class="iy ar as iz"><span class="br dt du bt ja jb jc jd je jf fg"><a class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq" href="https://medium.com/@chih.sheng.huang821?source=post_page-----406e1fd001f----------------------">Tommy Huang</a></span><div class="jg l ba h"><button class="jh fg ax cg gd ge gf gg bk bp gh gi gj gk gl gm cj br b bs ji fv bv ck cl y cm cn bn">Follow</button></div></div></span></div></div><span class="br b bs bt bu bv l bw bx"><span class="br dt du bt ja jb jc jd je jf bw"><div><a class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq" href="https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f?source=post_page-----406e1fd001f----------------------">Jul 25, 2018</a> <!-- -->·<!-- --> <!-- -->7<!-- --> min read</div></span></span></div></div></div></div></div></section><hr class="jj dt ga jk jl gw jm jn jo jp jq"><section class="id ie if ig ih"><div class="y ii x cs cq cr"><p id="018d" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">其他相關連結</p><p id="11a4" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph=""><a class="bb cn kf kg kh ki" target="_blank" href="https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8%E7%AF%87-%E4%B8%80-1c8337179ad6">機器/深度學習-基礎數學篇(一):純量、向量、矩陣、矩陣運算、逆矩陣、矩陣轉置介紹</a><br><a class="bb cn kf kg kh ki" target="_blank" href="https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f">機器/深度學習-基礎數學(二):梯度下降法(gradient descent)<br></a><a class="bb cn kf kg kh ki" target="_blank" href="https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%B8%89-%E6%A2%AF%E5%BA%A6%E6%9C%80%E4%BD%B3%E8%A7%A3%E7%9B%B8%E9%97%9C%E7%AE%97%E6%B3%95-gradient-descent-optimization-algorithms-b61ed1478bd7">機器/深度學習-基礎數學(三):梯度最佳解相關算法(gradient descent optimization algorithms)</a></p></div></section><hr class="jj dt ga jk jl gw jm jn jo jp jq"><section class="id ie if ig ih"><div class="y ii x cs cq cr"><p id="081d" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">微積分找極值方式:</p><p id="d10a" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">一般微積分說將要找極大值或極小值的式子做微分等於0找解，找到的不是極大值，就是極小值，是極大還是極小就看二階微分帶入找出來的解，看結果是大於0，還是小於0。</p><p id="c75c" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這邊舉個範例</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w ko"><div class="kr l dg ks"><div class="kt l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_phk6yUULlWuub2EsFNX6Qw.png" class="ff n o fe x ku kv sa sb" width="378" height="68"></div><img class="om on ff n o fe x fb" width="378" height="68" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_phk6yUULlWuub2EsFNX6Qw(1).png"><noscript><img src="https://miro.medium.com/max/756/1*phk6yUULlWuub2EsFNX6Qw.png" class="ff n o fe x" width="378" height="68"/></noscript></div></div></div></figure><p id="a23f" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">微分很簡單</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w go"><div class="kr l dg ks"><div class="kx l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_p5hZPjcr5j_BdFZEgwh6-A.png" class="ff n o fe x ku kv sa sb" width="450" height="103"></div><img class="om on ff n o fe x fb" width="450" height="103" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_p5hZPjcr5j_BdFZEgwh6-A(1).png"><noscript><img src="https://miro.medium.com/max/900/1*p5hZPjcr5j_BdFZEgwh6-A.png" class="ff n o fe x" width="450" height="103"/></noscript></div></div></div></figure><p id="d9c4" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">微分等於0</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w ky"><div class="kr l dg ks"><div class="kz l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_3M9cY-HoWK84xUoXP6Ybjw.png" class="ff n o fe x ku kv sa sb" width="526" height="148"></div><img class="om on ff n o fe x fb" width="526" height="148" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_3M9cY-HoWK84xUoXP6Ybjw(1).png"><noscript><img src="https://miro.medium.com/max/1052/1*3M9cY-HoWK84xUoXP6Ybjw.png" class="ff n o fe x" width="526" height="148"/></noscript></div></div></div></figure><p id="d70d" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">二階微分</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w la"><div class="kr l dg ks"><div class="lb l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_fo5vuij88sB-595BSGkLQg.png" class="ff n o fe x ku kv sa sb" width="444" height="103"></div><img class="om on ff n o fe x fb" width="444" height="103" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_fo5vuij88sB-595BSGkLQg(1).png"><noscript><img src="https://miro.medium.com/max/888/1*fo5vuij88sB-595BSGkLQg.png" class="ff n o fe x" width="444" height="103"/></noscript></div></div></div></figure><p id="65a0" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">所以剛剛的式子找到的極值是極小值，當<em class="lc">x</em>=5，有極小值-24。</p><p id="490b" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這個範例是可以找的到唯一解的式子，但在<strong class="jt ld">實際應用根本不可能向微積分考試這麼理想一定找得到唯一解</strong>，這時候就必須要靠找近似解的方式去逼近極值，也就是這篇要說的梯度下降法(gradient descent)。</p></div></section><hr class="jj dt ga jk jl gw jm jn jo jp jq"><section class="id ie if ig ih"><div class="y ii x cs cq cr"><h1 id="04f6" class="le lf fg bs br fz lg lh li lj lk ll lm ln lo lp lq" data-selectable-paragraph="">梯度下降法(gradient descent)</h1><p id="ff7b" class="jr js fg bs jt b ju lr jw ls jy lt ka lu kc lv ke" data-selectable-paragraph="">梯度下降法(gradient descent)是最佳化理論裡面的一個一階找最佳解的一種方法，主要是希望用梯度下降法找到函數(剛剛舉例的式子)的局部最小值，因為梯度的方向是走向局部最大的方向，所以在梯度下降法中是往梯度的反方向走。</p><p id="7953" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這邊我們先大概說一下梯度， 要算一個函數<em class="lc">f</em>(<em class="lc">x</em>)的梯度有一個前提，就是這個函數要是任意可微分函數，這也是深度學習為什麼都要找可微分函數出來當激活函數(activation function)。</p><p id="f46c" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">一維度的純量<em class="lc">x</em>的梯度，通常用<em class="lc">f'</em>(<em class="lc">x</em>)表示。<br> 多維度的向量<strong class="jt ld"><em class="lc">x</em></strong>的梯度，通常用∇<em class="lc">f</em>(<strong class="jt ld"><em class="lc">x</em></strong>)表示。</p><blockquote class="lw"><div id="8a3d" class="lx ly lz bs il b ma mb mc md me mf ke" data-selectable-paragraph=""><p class="il b mg mh bw">白話一點，一維度的純量<em class="mi">x</em>的梯度就是算<em class="mi">f</em>(<em class="mi">x</em>)對<em class="mi">x</em>的微分，多維度的向量<strong class="bh"><em class="mi">x</em></strong>的梯度就是算<em class="mi">f</em>(<strong class="bh"><em class="mi">x</em></strong>)對<strong class="bh"><em class="mi">x</em></strong>所有元素的偏微分</p></div></blockquote><p id="5250" class="jr js fg bs jt b ju mj jw mk jy ml ka mm kc mn ke" data-selectable-paragraph="">一維度的容易理解，上面也有範例。多維度的梯度，一般公式寫的是</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w mo"><div class="kr l dg ks"><div class="mp l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_ySkxwxuRSZ8bWqUm3bp3-Q.png" class="ff n o fe x ku kv sa sb" width="472" height="352"></div><img class="om on ff n o fe x fb" width="472" height="352" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_ySkxwxuRSZ8bWqUm3bp3-Q(1).png"><noscript><img src="https://miro.medium.com/max/944/1*ySkxwxuRSZ8bWqUm3bp3-Q.png" class="ff n o fe x" width="472" height="352"/></noscript></div></div></div></figure><p id="999f" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這邊可能有人看不懂，我舉一個實際的例子</p><p id="cb21" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">假設我們的<strong class="jt ld"><em class="lc">x</em></strong>有兩個維度的參數，梯度就分別需要對不同維度的參數做偏微分</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w mq"><div class="kr l dg ks"><div class="mr l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_kPVvP0czBbIA9vZ6rBT6dg.png" class="ff n o fe x ku kv sa sb" width="538" height="91"></div><img class="om on ff n o fe x fb" width="538" height="91" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_kPVvP0czBbIA9vZ6rBT6dg(1).png"><noscript><img src="https://miro.medium.com/max/1076/1*kPVvP0czBbIA9vZ6rBT6dg.png" class="ff n o fe x" width="538" height="91"/></noscript></div></div></div></figure><p id="168a" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph=""><strong class="jt ld">多維度的範例1:</strong></p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w ms"><div class="kr l dg ks"><div class="mt l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_6Zmb1wh7IKoWcNbak19ubQ.png" class="ff n o fe x ku kv sa sb" width="700" height="239"></div><img class="om on ff n o fe x fb" width="700" height="239" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_6Zmb1wh7IKoWcNbak19ubQ(1).png"><noscript><img src="https://miro.medium.com/max/1400/1*6Zmb1wh7IKoWcNbak19ubQ.png" class="ff n o fe x" width="700" height="239"/></noscript></div></div></div></figure><p id="cfd2" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph=""><strong class="jt ld">多維度的範例2:</strong></p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w ms"><div class="kr l dg ks"><div class="mu l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_N9jrA8m7wkczNbVX13nleg.png" class="ff n o fe x ku kv sa sb" width="700" height="512"></div><img class="om on ff n o fe x fb" width="700" height="512" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_N9jrA8m7wkczNbVX13nleg(1).png"><noscript><img src="https://miro.medium.com/max/1400/1*N9jrA8m7wkczNbVX13nleg.png" class="ff n o fe x" width="700" height="512"/></noscript></div></div></div></figure><p id="1af4" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">從一開始的純量的微分到多維度的梯度，大家應該知道梯度怎麼算了。</p><h2 id="6df3" class="mv lf fg bs br fz mw mx my mz na nb nc nd ne nf ng" data-selectable-paragraph="">那算出來的梯度跟梯度下降法有什麼關係?</h2><p id="79ad" class="jr js fg bs jt b ju lr jw ls jy lt ka lu kc lv ke" data-selectable-paragraph="">在機器學習，通常有一個損失函數(loss function或稱為cost function，在最佳化理論我們會稱為目標函數objection function)，我們通常是希望這個函數越小越好(也就是找極小值)，這邊可以參考<a class="bb cn kf kg kh ki" target="_blank" href="https://medium.com/@chih.sheng.huang821/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8-linear-regression-3a271a7453e">回歸分析</a>或是<a class="bb cn kf kg kh ki" target="_blank" href="https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-%E5%A4%9A%E5%B1%A4%E6%84%9F%E7%9F%A5%E6%A9%9F-multilayer-perceptron-mlp-%E5%90%AB%E8%A9%B3%E7%B4%B0%E6%8E%A8%E5%B0%8E-ee4f3d5d1b41">MLP</a>描述的目標函數。<br>雖然回歸有唯一解，但我在回歸最後面有寫到，因為回歸有算反矩陣等，計算複雜度相對梯度下降法來的複雜，而且也有可以因為矩陣奇異，反矩陣推估錯誤，導致模型估計錯誤，所以用梯度下降法來做應該比較合適。</p><p id="3eab" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph=""><strong class="jt ld">梯度下降法是一種不斷去更新參數(這邊參數用<em class="lc">x</em>表示)找「解」的方法</strong>，所以一定要先隨機產生一組初始參數的「解」，然後根據這組隨機產生的「解」開始算此「解」的梯度方向大小，然後將這個「解」去減去梯度方向，很饒舌，公式如下:</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w nh"><div class="kr l dg ks"><div class="ni l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_cGNuS-tDLAdY_P9fcia7qQ.png" class="ff n o fe x ku kv sa sb" width="446" height="73"></div><img class="om on ff n o fe x fb" width="446" height="73" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_cGNuS-tDLAdY_P9fcia7qQ(1).png"><noscript><img src="https://miro.medium.com/max/892/1*cGNuS-tDLAdY_P9fcia7qQ.png" class="ff n o fe x" width="446" height="73"/></noscript></div></div></div></figure><p id="b96a" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這邊的t是第幾次更新參數，γ是學習率(Learning rate)。<br>梯度的方向我們知道了，但找「解」的時候公式是往梯度的方向更新，一次要更新多少，就是由學習率來控制的，後面會有範例說這個學習率影響的程度。</p></div></section><hr class="jj dt ga jk jl gw jm jn jo jp jq"><section class="id ie if ig ih"><div class="y ii x cs cq cr"><h2 id="e0af" class="mv lf fg bs br fz mw mx my mz na nb nc nd ne nf ng" data-selectable-paragraph="">範例1</h2><p id="70f9" class="jr js fg bs jt b ju lr jw ls jy lt ka lu kc lv ke" data-selectable-paragraph="">我這邊用下面這個函數(雖然它有唯一解)當例子來做梯度下降法，多維度基本上差不多</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w nj"><div class="kr l dg ks"><div class="nk l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_4Lyw_bUByHDuFTAIMl8IHg.png" class="ff n o fe x ku kv sa sb" width="700" height="197"></div><img class="om on ff n o fe x fb" width="700" height="197" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_4Lyw_bUByHDuFTAIMl8IHg(1).png"><noscript><img src="https://miro.medium.com/max/1400/1*4Lyw_bUByHDuFTAIMl8IHg.png" class="ff n o fe x" width="700" height="197"/></noscript></div></div></div></figure><p id="0729" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">此例子基本上學習率可以不用太小，就可以很快就找到解，我後面有跑不同學習率看幾次可以跑到近似解。</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w nl"><div class="kr l dg ks"><div class="nm l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_WYEjI4VaAHWv0JEqnyf3QA.png" class="ff n o fe x ku kv sa sb" width="561" height="420"></div><img class="om on ff n o fe x fb" width="561" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_WYEjI4VaAHWv0JEqnyf3QA(1).png"><noscript><img src="https://miro.medium.com/max/1122/1*WYEjI4VaAHWv0JEqnyf3QA.png" class="ff n o fe x" width="561" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">f(x)=x²-10x+1</figcaption></figure><p id="b5d7" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">Note: 我這邊列出切線和法線公式，主要是我範例用的圖有畫出這兩條線。</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w nr"><div class="kr l dg ks"><div class="ns l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_Qm6tVOo_MJbwFtDJb1hMCQ.png" class="ff n o fe x ku kv sa sb" width="700" height="174"></div><img class="om on ff n o fe x fb" width="700" height="174" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_Qm6tVOo_MJbwFtDJb1hMCQ(1).png"><noscript><img src="https://miro.medium.com/max/1400/1*Qm6tVOo_MJbwFtDJb1hMCQ.png" class="ff n o fe x" width="700" height="174"/></noscript></div></div></div></figure><p id="e360" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">剛有提到我們需要先設定一個初始化的「解」，此例我設定x(0)=20(故意跟最佳值有差距)</p><blockquote class="lw"><div id="3f4f" class="lx ly lz bs il b ma mb mc md me mf ke" data-selectable-paragraph=""><p class="il b mg mh bw">紅色的點是每一次更新找到的解</p></div><div id="14f4" class="lx ly lz bs il b ma nt nu nv nw nx ke" data-selectable-paragraph=""><p class="il b mg mh bw">紅色線是法線，藍色線是切線，法線和切線這兩條線是垂直的，但因為x軸和y軸scale不一樣，所以看不出來它是垂直的。</p></div></blockquote><figure class="ny nz oa ob oc dw v w paragraph-image"><div class="v w od"><div class="kr l dg ks"><div class="oe l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_PyXvVaaz4OSA_J6VdXlAJw.gif" class="ff n o fe x ku kv sa sb" width="560" height="420"></div><img class="om on ff n o fe x fb" width="560" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_PyXvVaaz4OSA_J6VdXlAJw(1).gif"><noscript><img src="https://miro.medium.com/max/1120/1*PyXvVaaz4OSA_J6VdXlAJw.gif" class="ff n o fe x" width="560" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">學習率是0.01</figcaption></figure><figure class="of dw v w paragraph-image"><div class="v w od"><div class="kr l dg ks"><div class="oe l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_HoYoC5wDbhGwoQsl7yWDhw.gif" class="ff n o fe x ku kv sa sb" width="560" height="420"></div><img class="om on ff n o fe x fb" width="560" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_HoYoC5wDbhGwoQsl7yWDhw(1).gif"><noscript><img src="https://miro.medium.com/max/1120/1*HoYoC5wDbhGwoQsl7yWDhw.gif" class="ff n o fe x" width="560" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">學習率是0.1</figcaption></figure><figure class="of dw v w paragraph-image"><div class="v w od"><div class="kr l dg ks"><div class="oe l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_-36NUUMhBq7J1rL8agmEgw.gif" class="ff n o fe x ku kv sa sb" width="560" height="420"></div><img class="om on ff n o fe x fb" width="560" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_-36NUUMhBq7J1rL8agmEgw(1).gif"><noscript><img src="https://miro.medium.com/max/1120/1*-36NUUMhBq7J1rL8agmEgw.gif" class="ff n o fe x" width="560" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">學習率是0.9</figcaption></figure><figure class="of dw v w paragraph-image"><div class="v w od"><div class="kr l dg ks"><div class="oe l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_StvoG20bZY6rAbVKGcxWnw.gif" class="ff n o fe x ku kv sa sb" width="560" height="420"></div><img class="om on ff n o fe x fb" width="560" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_StvoG20bZY6rAbVKGcxWnw(1).gif"><noscript><img src="https://miro.medium.com/max/1120/1*StvoG20bZY6rAbVKGcxWnw.gif" class="ff n o fe x" width="560" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">學習率是1</figcaption></figure><p id="dc33" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">由上圖我們可以發現學習率對找解影響很大，學習率太低，需要更新很多次才能到最佳解，學習率太高，有可能會造成梯度走不進去局部極值(但也可以擺脫局部極值的問題，等等有範例)。這邊尤其是當學習率是1的時候，基本上梯度下降法根本走不到局部極小值，一直在左右對跳，所以最佳化理論有很多衍生的方式或更先進的方式去解決這些問題(這邊先不介紹)。</p></div></section><hr class="jj dt ga jk jl gw jm jn jo jp jq"><section class="id ie if ig ih"><div class="y ii x cs cq cr"><h2 id="b4d6" class="mv lf fg bs br fz mw mx my mz na nb nc nd ne nf ng" data-selectable-paragraph="">範例2</h2><p id="d995" class="jr js fg bs jt b ju lr jw ls jy lt ka lu kc lv ke" data-selectable-paragraph="">我設計一個有局部極小值和全域極小值的函數，到四次方，但我是亂打的，所以<em class="lc">x</em>=10，函數的值就超大的。</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w og"><div class="kr l dg ks"><div class="oh l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_E82CWULL7J2qNy-8ab6ZyA.png" class="ff n o fe x ku kv sa sb" width="700" height="270"></div><img class="om on ff n o fe x fb" width="700" height="270" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_E82CWULL7J2qNy-8ab6ZyA(1).png"><noscript><img src="https://miro.medium.com/max/1400/1*E82CWULL7J2qNy-8ab6ZyA.png" class="ff n o fe x" width="700" height="270"/></noscript></div></div></div></figure><p id="41f2" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">我們需要先設定一個初始化的「解」，此例我設定x(0)=-20(故意跟最佳值有差距)</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w od"><div class="kr l dg ks"><div class="oe l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_QkG6kdDJ1p6M62sdUX6brQ.gif" class="ff n o fe x ku kv sa sb" width="560" height="420"></div><img class="om on ff n o fe x fb" width="560" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_QkG6kdDJ1p6M62sdUX6brQ(1).gif"><noscript><img src="https://miro.medium.com/max/1120/1*QkG6kdDJ1p6M62sdUX6brQ.gif" class="ff n o fe x" width="560" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">學習率是0.00001</figcaption></figure><p id="4c9a" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">所以這個學習率太小，初始值不好，解就會掉到局部極小值。</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w od"><div class="kr l dg ks"><div class="oe l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_gt1aMVhydotP2I7urp-Z0A.gif" class="ff n o fe x ku kv sa sb" width="560" height="420"></div><img class="om on ff n o fe x fb" width="560" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_gt1aMVhydotP2I7urp-Z0A(1).gif"><noscript><img src="https://miro.medium.com/max/1120/1*gt1aMVhydotP2I7urp-Z0A.gif" class="ff n o fe x" width="560" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">學習率是0.0004</figcaption></figure><p id="76f9" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這個學習率(0.0004)對此例子來說，雖然步伐夠大跳出了局部極值，但到全域極值時，因為步伐太大，所以走不到最好的值。</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w od"><div class="kr l dg ks"><div class="oe l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_yDhjLYUAX8l-yrVC1thDOA.gif" class="ff n o fe x ku kv sa sb" width="560" height="420"></div><img class="om on ff n o fe x fb" width="560" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_yDhjLYUAX8l-yrVC1thDOA(1).gif"><noscript><img src="https://miro.medium.com/max/1120/1*yDhjLYUAX8l-yrVC1thDOA.gif" class="ff n o fe x" width="560" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">學習率是0.0003</figcaption></figure><p id="dc1f" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這個學習率(0.0003)對此例子來說就夠了，可以走到全域極值。</p></div></section><hr class="jj dt ga jk jl gw jm jn jo jp jq"><section class="id ie if ig ih"><div class="y ii x cs cq cr"><h2 id="f1e9" class="mv lf fg bs br fz mw mx my mz na nb nc nd ne nf ng" data-selectable-paragraph="">補充說明沒有極值的狀況</h2><p id="b73c" class="jr js fg bs jt b ju lr jw ls jy lt ka lu kc lv ke" data-selectable-paragraph="">雖然說微分可以找極值，但很多函數既無最大值，也無最小值，因為函數的長像彎彎曲曲很多次，有局部極值或鞍部，所以一次維分等於0求得的可能是極值，也可以是相對極值。</p><p id="41cb" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">上面舉的某一個例子，就發生這種情況</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w ms"><div class="kr l dg ks"><div class="oi l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_KpbAyEz4ISnYlx4nLwAEvg.png" class="ff n o fe x ku kv sa sb" width="700" height="316"></div><img class="om on ff n o fe x fb" width="700" height="316" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_KpbAyEz4ISnYlx4nLwAEvg(1).png"><noscript><img src="https://miro.medium.com/max/1400/1*KpbAyEz4ISnYlx4nLwAEvg.png" class="ff n o fe x" width="700" height="316"/></noscript></div></div></div></figure><p id="7bf8" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這個方程式可以找到極值「解」讓<em class="lc">f</em>(<em class="lc">x</em>)最小(<em class="lc">f</em>(<em class="lc">x</em>)=16)，但這個值真的是最小嗎?<br>我找個點隨便帶入</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w oj"><div class="kr l dg ks"><div class="ok l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_RBk8s9zQ4X4fBTJKJ7O7Og.png" class="ff n o fe x ku kv sa sb" width="544" height="91"></div><img class="om on ff n o fe x fb" width="544" height="91" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_RBk8s9zQ4X4fBTJKJ7O7Og(1).png"><noscript><img src="https://miro.medium.com/max/1088/1*RBk8s9zQ4X4fBTJKJ7O7Og.png" class="ff n o fe x" width="544" height="91"/></noscript></div></div></div></figure><blockquote class="lw"><div id="e5ed" class="lx ly lz bs il b ma mb mc md me mf ke" data-selectable-paragraph=""><p class="il b mg mh bw">這個值比微分的最佳解還要小，所以可以得知微分等於0找到的不一定是最佳解，所以用梯度下降法，可以找到更好的解。</p></div></blockquote><p id="4f92" class="jr js fg bs jt b ju mj jw mk jy ml ka mm kc mn ke" data-selectable-paragraph="">下圖我將上式子畫出來它的坐標跟微分解還有梯度法如何讓解更新。</p><figure class="kj kk kl km kn dw v w paragraph-image"><div class="v w od"><div class="kr l dg ks"><div class="oe l"><div class="cu kp ff n o fe x ja t kq"><img src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_ohVPiStlsbMP0XL1_X-fkQ.gif" class="ff n o fe x ku kv sa sb" width="560" height="420"></div><img class="om on ff n o fe x fb" width="560" height="420" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_ohVPiStlsbMP0XL1_X-fkQ(1).gif"><noscript><img src="https://miro.medium.com/max/1120/1*ohVPiStlsbMP0XL1_X-fkQ.gif" class="ff n o fe x" width="560" height="420"/></noscript></div></div></div><figcaption class="bw du nn no gw cs v w np nq br dt" data-selectable-paragraph="">紅色點是微分解，藍色點是梯度法不斷更新找解(學習率設定在0.01，主要是為了讓解跑慢一點，動畫才好看)。</figcaption></figure><p id="10fd" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">這邊我只跑100次，因為解在無窮大的地方，但可以看到loss值不斷在減少中。</p></div></section><hr class="jj dt ga jk jl gw jm jn jo jp jq"><section class="id ie if ig ih"><div class="y ii x cs cq cr"><p id="90e9" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">當然還有很多手法(比如牛頓法， momentum或是Adam)可以避免上述問題，或是讓解找的更快，但此篇文章只在說明，梯度下降法是什麼，跟它怎麼運作的，未來有時間可以在將這些補上。</p><p id="ca19" class="jr js fg bs jt b ju jv jw jx jy jz ka kb kc kd ke" data-selectable-paragraph="">坦白說這篇內容雖然很好寫，但作圖很花時間和腦力的，喜歡這篇的可以多拍幾下手給個獎勵吧。</p></div></section></div></article><div class="cu cv cw m cx cy cz da db e" data-test-id="post-sidebar"><div class="ar ct"><div class="dc dd de ar"><div class="ar as"><div class="df l dg"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_sidebar-----406e1fd001f---------------------clap_sidebar-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><div class="bi dh di dj dk dl dm dn do dp dq"><svg width="29" height="29"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></div><div class="dr l"><div class="ds"><h4 class="br dt du bt bw"><button class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq">2.5K </button></h4></div></div></div></div><div><div class="cm"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_sidebar--------------------------bookmark_sidebar-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div></div><div><div class="dv dw ar ct dx"><div class="ar dx"><div class="dy dz ea eb ec ed x"><div class="ar ee"></div><div class="ar as ee"></div><div class="ef l"><ul class="bi bj"></ul></div><div class="eg ar eh u"><div class="ar as"><div class="ei l dg"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_actions_footer-----406e1fd001f---------------------clap_footer-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><div class="c ej ek ar as el dg em en eo ep eq er es et eu ev ew ex ey ez"><div class="bi dh di dj dk dl fa dn as fb ek ar dx fc fd o fe ff n x do dp dq"><svg width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></div></div></a></div><div class="dr l"><div class="ds"><h4 class="br dt du bt fg"><button class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq">2.5K claps</button></h4></div></div></div><div class="ar as"><div class="fh l ba g"><a href="https://medium.com/p/406e1fd001f/share/twitter?source=follow_footer--------------------------follow_footer-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="29" height="29" class="ax"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></a></div><div class="fh l ba g"><a href="https://medium.com/p/406e1fd001f/share/facebook?source=follow_footer--------------------------follow_footer-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="29" height="29" class="ax"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></a></div><div class="fh aw az"><div class="cm"><button class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="25" height="25" class="ax"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="fh l ba"><div><div class="cm"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_actions_footer--------------------------bookmark_sidebar-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div><div class="cm"><div class="l ba"><button class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="ax"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div><div class="fi fj fk ef l u"><div class="fl fm l dg"><span class="l fn au fo"><div class="l ff fp fq"><a href="https://medium.com/@chih.sheng.huang821?source=follow_footer--------------------------follow_footer-"><img alt="Tommy Huang" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_d_eKs6OyA07h7e8tXxj5OA(1).jpeg" class="l ek fr fs" width="80" height="80"></a></div><span class="l"><div class="ft l fu"><p class="br dt fv bt bw fw fx">Written by</p></div><div class="ft fy ar fu"><div class="x ar as eh"><h2 class="br fz ga gb fg"><a class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq" href="https://medium.com/@chih.sheng.huang821?source=follow_footer--------------------------follow_footer-">Tommy Huang</a></h2><div class="l g"><button class="gc fg ax cg gd ge gf gg bk bp gh gi gj gk gl gm cj br b bs bt bu bv ck cl y cm cn bn">Follow</button></div></div></div></span></span><div class="ft gn l fu az"><div class="go l"><h4 class="br dt gp gq bw">怕老了忘記這些吃飯的知識，開始寫文章記錄機器/深度學習相關內容。黃志勝 Chih-Sheng Huang (Tommy), mail: chih.sheng.huang821@gmail.com</h4></div><div class="aw gr az"><button class="gc fg ax cg gd ge gf gg bk bp gh gi gj gk gl gm cj br b bs bt bu bv ck cl y cm cn bn">Follow</button></div></div></div></div><div class="gs fj l u"><a href="https://medium.com/p/406e1fd001f/responses/show?source=follow_footer--------------------------follow_footer-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><div class="gt gu gv l gw az"><span class="bz">See responses (4)</span></div></a></div></div></div><div class="gx l gy u"><div class="ar dx"><div class="dy dz ea eb ec gz x"><div class="oo l op"><div class="hv oq fl l"><h2 class="br fz or os fg">More From Medium</h2></div><div class="ot ar ou ee ov ow ox oy oz pa pb pc pd pe pf pg ph pi pj"><div class="pk pl pm pn po pp pq pr ps pt pu pv pw px py pz qa qb qc qd qe"><div class="x fe"><div class="l qf"><div class="qg qh ov ow ox qi qj oy oz pa qk ql pb pc pd qm qn pe pf pg qo qp ph pi pj ar ee"><div class="pk pl pm pn po pp qq qr ps pt qs qt pw px qu qv qa qb qw qx qe"><div class="qy l qz f"><h4 class="br dt du bt bw">Related reads</h4></div><div class="ra l rb op"><a class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq l" href="https://medium.com/pcmag-access/why-teaching-ai-to-play-games-is-important-acf04bb8f54a?source=post_recirc---------0------------------"><div class="rc dg"><div class="fe ff x"><div class="rd l re rf fe x rg rh"></div></div></div></a></div></div><div class="pk pl pm pn po pp qq qr ps pt qs qt pw px qu qv qa qb qw qx qe"><div class="ra l"><div class="ri aw h rj"><h4 class="br dt du bt bw">Related reads</h4></div><a href="https://medium.com/pcmag-access/why-teaching-ai-to-play-games-is-important-acf04bb8f54a?source=post_recirc---------0------------------"><h3 class="fg ax il rk bs ma rl rm">Why Teaching AI to Play Games Is Important</h3></a></div><div class="ar as eh"><div class="rn l ro"><div class="as ar"><div><a href="https://medium.com/@pcmagazine?source=post_recirc---------0------------------"><div class="dg rp rq"><svg width="46" height="50" viewBox="0 0 46 50" class="ca ff rr rs rt ru cv"><path d="M1.45 15.22C5.43 7.07 13.59 1.5 23 1.5v-1C13.18.5 4.69 6.32.55 14.78l.9.44zM23 1.5c9.4 0 17.57 5.57 21.55 13.72l.9-.44C41.3 6.32 32.82.5 23 .5v1zm21.55 33.28C40.57 42.93 32.41 48.5 23 48.5v1c9.82 0 18.31-5.82 22.45-14.28l-.9-.44zM23 48.5c-9.4 0-17.57-5.57-21.55-13.72l-.9.44C4.7 43.68 13.18 49.5 23 49.5v-1z"></path></svg><img alt="PCMag" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_SLQXwWGHQ9WmCqtmk4Er4g.jpeg" class="l ek rq rp" width="40" height="40"></div></a></div><div class="ix x l"><div class="ar"><div style="flex: 1 1 0%;"><span class="br b bs bt bu bv l fg ax"><div class="co ar as iz"><span class="br dt du bt ja jb jc jd je jf fg"><a class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq" href="https://medium.com/@pcmagazine?source=post_recirc---------0------------------">PCMag</a><span> in <a href="https://medium.com/pcmag-access?source=post_recirc---------0------------------" class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq">PC Magazine</a></span></span></div></span></div></div><span class="br b bs bt bu bv l bw bx"><span class="br dt du bt ja jb jc jd je jf bw"><div><a class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq" href="https://medium.com/pcmag-access/why-teaching-ai-to-play-games-is-important-acf04bb8f54a?source=post_recirc---------0------------------">Aug 7, 2018</a> · 5 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="ar as"><div class="ar as"><div class="df l dg"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_recirc-----acf04bb8f54a----0-----------------clap_preview-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><div class="bi dh di dj dk dl dm ol do dp dq"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></div><div class="dr l"><div class="ds"><h4 class="br dt du bt bw">198 </h4></div></div></div><div class="rv ix rn rw rx l"></div><div><div class="cm"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_recirc---------0-----------------bookmark_sidebar-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div></div></div></div></div></div></div><div class="pk pl pm pn po pp pq pr ps pt pu pv pw px py pz qa qb qc qd qe"><div class="x fe"><div class="l qf"><div class="qg qh ov ow ox qi qj oy oz pa qk ql pb pc pd qm qn pe pf pg qo qp ph pi pj ar ee"><div class="pk pl pm pn po pp qq qr ps pt qs qt pw px qu qv qa qb qw qx qe"><div class="qy l qz f"><h4 class="br dt du bt bw">Related reads</h4></div><div class="ra l rb op"><a class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq l" href="https://medium.com/libreai/draw-me-an-electric-sheep-9a3e0b5fe7d5?source=post_recirc---------1------------------"><div class="rc dg"><div class="fe ff x"><div class="ry l re rf fe x rg rh"></div></div></div></a></div></div><div class="pk pl pm pn po pp qq qr ps pt qs qt pw px qu qv qa qb qw qx qe"><div class="ra l"><div class="ri aw h rj"><h4 class="br dt du bt bw">Related reads</h4></div><a href="https://medium.com/libreai/draw-me-an-electric-sheep-9a3e0b5fe7d5?source=post_recirc---------1------------------"><h3 class="fg ax il rk bs ma rl rm">Draw Me an Electric Sheep</h3></a></div><div class="ar as eh"><div class="rn l ro"><div class="as ar"><div><a href="https://medium.com/@libreai?source=post_recirc---------1------------------"><img alt="Libre AI" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/1_WcCRRTLKKmT52r7DRNE9iA.png" class="l ek rq rp" width="40" height="40"></a></div><div class="ix x l"><div class="ar"><div style="flex: 1 1 0%;"><span class="br b bs bt bu bv l fg ax"><div class="co ar as iz"><span class="br dt du bt ja jb jc jd je jf fg"><a class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq" href="https://medium.com/@libreai?source=post_recirc---------1------------------">Libre AI</a><span> in <a href="https://medium.com/libreai?source=post_recirc---------1------------------" class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq">Libre AI</a></span></span></div></span></div></div><span class="br b bs bt bu bv l bw bx"><span class="br dt du bt ja jb jc jd je jf bw"><div><a class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq" href="https://medium.com/libreai/draw-me-an-electric-sheep-9a3e0b5fe7d5?source=post_recirc---------1------------------">Nov 18, 2018</a> · 5 min read</div></span></span></div></div></div><div class="ar as"><div class="ar as"><div class="df l dg"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_recirc-----9a3e0b5fe7d5----1-----------------clap_preview-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><div class="bi dh di dj dk dl dm ol do dp dq"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></div><div class="dr l"><div class="ds"><h4 class="br dt du bt bw">152 </h4></div></div></div><div class="rv ix rn rw rx l"></div><div><div class="cm"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_recirc---------1-----------------bookmark_sidebar-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div></div></div></div></div></div></div><div class="pk pl pm pn po pp pq pr ps pt pu pv pw px py pz qa qb qc qd qe"><div class="x fe"><div class="l qf"><div class="qg qh ov ow ox qi qj oy oz pa qk ql pb pc pd qm qn pe pf pg qo qp ph pi pj ar ee"><div class="pk pl pm pn po pp qq qr ps pt qs qt pw px qu qv qa qb qw qx qe"><div class="qy l qz f"><h4 class="br dt du bt bw">Related reads</h4></div><div class="ra l rb op"><a class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq l" href="https://medium.com/ai-enigma/predicting-pokemon-battle-winner-using-machine-learning-d1ed055ac50?source=post_recirc---------2------------------"><div class="rc dg"><div class="fe ff x"><div class="rz l re rf fe x rg rh"></div></div></div></a></div></div><div class="pk pl pm pn po pp qq qr ps pt qs qt pw px qu qv qa qb qw qx qe"><div class="ra l"><div class="ri aw h rj"><h4 class="br dt du bt bw">Related reads</h4></div><a href="https://medium.com/ai-enigma/predicting-pokemon-battle-winner-using-machine-learning-d1ed055ac50?source=post_recirc---------2------------------"><h3 class="fg ax il rk bs ma rl rm">Predicting Pokemon Battle Winner using Machine Learning</h3></a></div><div class="ar as eh"><div class="rn l ro"><div class="as ar"><div><a href="https://medium.com/@csaurabh17?source=post_recirc---------2------------------"><img alt="Saurabh Charde" src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/2_sGP6ytRBap7Sw16zixx2ag.jpeg" class="l ek rq rp" width="40" height="40"></a></div><div class="ix x l"><div class="ar"><div style="flex: 1 1 0%;"><span class="br b bs bt bu bv l fg ax"><div class="co ar as iz"><span class="br dt du bt ja jb jc jd je jf fg"><a class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq" href="https://medium.com/@csaurabh17?source=post_recirc---------2------------------">Saurabh Charde</a><span> in <a href="https://medium.com/ai-enigma?source=post_recirc---------2------------------" class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq">AI Enigma</a></span></span></div></span></div></div><span class="br b bs bt bu bv l bw bx"><span class="br dt du bt ja jb jc jd je jf bw"><div><a class="bb bc bd be bf bg bh bi bj bk hz bn bo bp bq" href="https://medium.com/ai-enigma/predicting-pokemon-battle-winner-using-machine-learning-d1ed055ac50?source=post_recirc---------2------------------">Jun 24, 2018</a> · 6 min read</div></span></span></div></div></div><div class="ar as"><div class="ar as"><div class="df l dg"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_recirc-----d1ed055ac50----2-----------------clap_preview-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><div class="bi dh di dj dk dl dm ol do dp dq"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></div><div class="dr l"><div class="ds"><h4 class="br dt du bt bw">216 </h4></div></div></div><div class="rv ix rn rw rx l"></div><div><div class="cm"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40chih.sheng.huang821%2F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f&amp;source=post_recirc---------2-----------------bookmark_sidebar-" class="bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="ha l hb hc"><section class="v w x y l z ab ac ae af ag ah ai aj ak al am an ao ap"><div class="hd he fl ar eh g"><div class="hf ar eh"><div class="hg l hh"><div class="hi l"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk hj hk bn bo hl hm"><h4 class="hn ho hp br fz bs gq hq hr l">Discover <!-- -->Medium</h4></a></div><span class="br b bs bt bu bv l hs ht">Welcome to a place where words matter. On <!-- -->Medium<!-- -->, smart voices and original ideas take center stage - with no ads in sight.<!-- --> <a href="https://medium.com/about?autoplay=1&amp;source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk bn bo hl hm hu">Watch</a></span></div><div class="hg l hh"><div class="hv l"><a href="https://medium.com/topics?source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk hj hk bn bo hl hm"><h4 class="hn ho hp br fz bs gq hq hr l">Make <!-- -->Medium<!-- --> yours</h4></a></div><span class="br b bs bt bu bv l hs ht">Follow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox.<!-- --> <a href="https://medium.com/topics?source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk bn bo hl hm hu">Explore</a></span></div><div class="hg l hh"><div class="hi l"><a href="https://medium.com/membership?source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk hj hk bn bo hl hm"><h4 class="hn ho hp br fz bs gq hq hr l">Become a member</h4></a></div><span class="br b bs bt bu bv l hs ht">Get unlimited access to the best stories on <!-- -->Medium<!-- --> — and support writers while you’re at it. Just $5/month.<!-- --> <a href="https://medium.com/membership?source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk bn bo hl hm hu">Upgrade</a></span></div></div></div><div class="ar as eh"><a href="https://medium.com/?source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk hj hk bn bo hl hm"><svg height="22" width="112" viewBox="0 0 111.5 22" class="ho"><path d="M56.3 19.5c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5V19c-.7 1.8-2.4 3-4.3 3-3.3 0-5.8-2.6-5.8-7.5 0-4.5 2.6-7.6 6.3-7.6 1.6-.1 3.1.8 3.8 2.4V3.2c0-.3-.1-.6-.3-.7l-1.4-1.4V1l6.5-.8v19.3zm-4.8-.8V9.5c-.5-.6-1.2-.9-1.9-.9-1.6 0-3.1 1.4-3.1 5.7 0 4 1.3 5.4 3 5.4.8.1 1.6-.3 2-1zm9.1 3.1V9.4c0-.3-.1-.6-.3-.7l-1.4-1.5v-.1h6.5v12.5c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5zm-.2-19.2C60.4 1.2 61.5 0 63 0c1.4 0 2.6 1.2 2.6 2.6S64.4 5.3 63 5.3a2.6 2.6 0 0 1-2.6-2.7zm22.5 16.9c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5v-3.2c-.6 2-2.4 3.4-4.5 3.4-2.9 0-4.4-2.1-4.4-6.2 0-1.9 0-4.1.1-6.5 0-.3-.1-.5-.3-.7L67.7 7v.1H74v8c0 2.6.4 4.4 2 4.4.9-.1 1.7-.6 2.1-1.3V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v12.4zm22 2.3c0-.5.1-6.5.1-7.9 0-2.6-.4-4.5-2.2-4.5-.9 0-1.8.5-2.3 1.3.2.8.3 1.7.3 2.5 0 1.8-.1 4.2-.1 6.5 0 .3.1.5.3.7l1.5 1.4v.1H96c0-.4.1-6.5.1-7.9 0-2.7-.4-4.5-2.2-4.5-.9 0-1.7.5-2.2 1.3v9c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v3.1a4.6 4.6 0 0 1 4.6-3.4c2.2 0 3.6 1.2 4.2 3.5.7-2.1 2.7-3.6 4.9-3.5 2.9 0 4.5 2.2 4.5 6.2 0 1.9-.1 4.2-.1 6.5-.1.3.1.6.3.7l1.4 1.4v.1h-6.6zm-81.4-2l1.9 1.9v.1h-9.8v-.1l2-1.9c.2-.2.3-.4.3-.7V7.3c0-.5 0-1.2.1-1.8L11.4 22h-.1L4.5 6.8c-.1-.4-.2-.4-.3-.6v10c-.1.7 0 1.3.3 1.9l2.7 3.6v.1H0v-.1L2.7 18c.3-.6.4-1.3.3-1.9v-11c0-.5-.1-1.1-.5-1.5L.7 1.1V1h7l5.8 12.9L18.6 1h6.8v.1l-1.9 2.2c-.2.2-.3.5-.3.7v15.2c0 .2.1.5.3.6zm7.6-5.9c0 3.8 1.9 5.3 4.2 5.3 1.9.1 3.6-1 4.4-2.7h.1c-.8 3.7-3.1 5.5-6.5 5.5-3.7 0-7.2-2.2-7.2-7.4 0-5.5 3.5-7.6 7.3-7.6 3.1 0 6.4 1.5 6.4 6.2v.8h-8.7zm0-.8h4.3v-.8c0-3.9-.8-4.9-2-4.9-1.4.1-2.3 1.6-2.3 5.7z"></path></svg></a><span class="br b bs bt bu bv l hs ht"><div class="hw hx ar eh hy au"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk hz bn bo hl hm">About</a><a href="https://help.medium.com/?source=post_page-----406e1fd001f----------------------" class="bb bc bd be bf bg bh bi bj bk hz bn bo hl hm">Help</a><a class="bb bc bd be bf bg bh bi bj bk hz bn bo hl hm" href="https://medium.com/policy/9db0094a1e0f?source=post_page-----406e1fd001f----------------------">Legal</a></div></span></div></section></div></div></div><script>window.__BUILD_ID__ = "development"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"config":{"nodeEnv":"production","version":"master-20190819-223611-34e1f3021a","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","iTunesAppId":"828256236","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"collector-medium.lightstep.com","token":"ce5be895bef60919541332990ac9fef2","appVersion":"master-20190819-223611-34e1f3021a"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","sentry":{"dsn":"https:\u002F\u002F589e367c28ca47b195ce200d1507d18b@sentry.io\u002F1423575","environment":"production"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"]},"debug":{"requestId":"2d96f582-cf83-4ca9-95a7-7af0e1bed5c0","originalSpanCarrier":{"ot-tracer-spanid":"289d34b421e8c3d4","ot-tracer-traceid":"16a97b5531509e68","ot-tracer-sampled":"true"}},"session":{"user":{"id":"lo_dnt_b0oJcgW3ziXr"},"xsrf":""},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"showBranchBanner":null,"hideGoogleOneTap":false,"currentLocation":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F機器學習-基礎數學-二-梯度下降法-gradient-descent-406e1fd001f","host":"medium.com","hostname":"medium.com","currentHash":""},"client":{"isBot":false,"isDnt":true,"isEu":false,"isNativeMedium":false,"isCustomDomain":false},"multiVote":{"clapsPerPost":{}},"metadata":{"faviconImageId":null}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY.variantFlags.0":{"name":"allow_access","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.0.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.0.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.1":{"name":"allow_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.1.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.1.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.2":{"name":"allow_test_auth","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.2.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.2.valueType":{"__typename":"VariantFlagString","value":"disallow"},"ROOT_QUERY.variantFlags.3":{"name":"available_annual_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.3.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.3.valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"},"ROOT_QUERY.variantFlags.4":{"name":"available_monthly_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.4.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.4.valueType":{"__typename":"VariantFlagString","value":"60e220181034"},"ROOT_QUERY.variantFlags.5":{"name":"browsable_stream_config_bucket","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.5.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.5.valueType":{"__typename":"VariantFlagString","value":"curated-topics"},"ROOT_QUERY.variantFlags.6":{"name":"disable_gosocial_followers_that_you_follow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.6.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.6.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.7":{"name":"disable_ios_resume_reading_toast","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.7.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.7.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.8":{"name":"disable_mobile_featured_chunk","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.8.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.8.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.9":{"name":"enable_annual_renewal_reminder_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.9.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.9.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.10":{"name":"enable_automated_mission_control_triggers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.10.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.10.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.11":{"name":"enable_branch_io","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.11.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.11.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.12":{"name":"enable_branding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.12.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.12.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.13":{"name":"enable_branding_fonts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.13.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.13.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.14":{"name":"enable_daily_read_digest_promo","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.14.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.14.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.15":{"name":"enable_dedicated_series_tab_api_ios","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.15.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.15.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.16":{"name":"enable_disregard_trunc_state_for_footer","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.16.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.16.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.17":{"name":"enable_edit_alt_text","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.17.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.17.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.18":{"name":"enable_embedding_based_diversification","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.18.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.18.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.19":{"name":"enable_google_one_tap","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.19.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.19.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.20":{"name":"enable_inline_search_lite","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.20.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.20.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.21":{"name":"enable_ios_post_stats","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.21.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.21.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.22":{"name":"enable_janky_spam_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.22.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.22.valueType":{"__typename":"VariantFlagString","value":"users,posts"},"ROOT_QUERY.variantFlags.23":{"name":"enable_lite_notifications","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.23.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.23.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.24":{"name":"enable_lite_post","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.24.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.24.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.25":{"name":"enable_lite_post_cd","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.25.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.25.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.26":{"name":"enable_lite_post_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.26.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.26.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.27":{"name":"enable_lite_post_highlights_view_only","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.27.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.27.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.28":{"name":"enable_lite_profile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.28.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.28.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.29":{"name":"enable_lite_pub_header_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.29.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.29.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.30":{"name":"enable_lite_stories","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.30.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.30.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.31":{"name":"enable_lite_thanks_to","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.31.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.31.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.32":{"name":"enable_lite_topics","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.32.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.32.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.33":{"name":"enable_lite_twitter_text_shots","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.33.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.33.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.34":{"name":"enable_lite_unread_notification_count_mutation","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.34.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.34.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.35":{"name":"enable_live_user_post_scoring","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.35.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.35.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.36":{"name":"enable_logged_out_homepage_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.36.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.36.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.37":{"name":"enable_marketing_emails","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.37.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.37.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.38":{"name":"enable_media_resource_try_catch","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.38.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.38.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.39":{"name":"enable_more_branch_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.39.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.39.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.40":{"name":"enable_new_collaborative_filtering_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.40.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.40.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.41":{"name":"enable_parsely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.41.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.41.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.42":{"name":"enable_patronus_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.42.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.42.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.43":{"name":"enable_post_import","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.43.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.43.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.44":{"name":"enable_primary_topic_for_mobile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.44.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.44.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.45":{"name":"enable_quarantine_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.45.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.45.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.46":{"name":"enable_rank_service_newsletters","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.46.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.46.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.47":{"name":"enable_serve_recs_from_ml_rank_app_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.47.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.47.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.48":{"name":"enable_serve_recs_from_ml_rank_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.48.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.48.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.49":{"name":"enable_serve_recs_from_ml_rank_homepage","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.49.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.49.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.50":{"name":"enable_tick_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.50.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.50.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.51":{"name":"enable_ticks_digest_promo","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.51.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.51.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.52":{"name":"enable_tipalti_onboarding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.52.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.52.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.53":{"name":"enable_trumpland_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.53.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.53.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.54":{"name":"glyph_font_set","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.54.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.54.valueType":{"__typename":"VariantFlagString","value":"m2"},"ROOT_QUERY.variantFlags.55":{"name":"google_sign_in_android","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.55.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.55.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.56":{"name":"is_not_medium_subscriber","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.56.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.56.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.57":{"name":"pub_sidebar","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.57.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.57.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.58":{"name":"rank_model","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.58.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.58.valueType":{"__typename":"VariantFlagString","value":"default"},"ROOT_QUERY.variantFlags.59":{"name":"redis_read_write_splitting","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.59.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.59.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.60":{"name":"remove_social_proof_on_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.60.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.60.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.61":{"name":"signin_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.61.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.61.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap"},"ROOT_QUERY.variantFlags.62":{"name":"signup_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.62.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.62.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap"},"ROOT_QUERY.variantFlags.63":{"name":"use_new_admin_topic_backend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.63.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.63.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY":{"variantFlags":[{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.0","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.1","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.2","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.3","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.4","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.5","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.6","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.7","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.8","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.9","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.10","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.11","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.12","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.13","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.14","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.15","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.16","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.17","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.18","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.19","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.20","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.21","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.22","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.23","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.24","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.25","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.26","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.27","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.28","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.29","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.30","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.31","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.32","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.33","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.34","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.35","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.36","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.37","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.38","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.39","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.40","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.41","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.42","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.43","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.44","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.45","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.46","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.47","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.48","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.49","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.50","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.51","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.52","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.53","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.54","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.55","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.56","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.57","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.58","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.59","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.60","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.61","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.62","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.63","typename":"VariantFlag"}],"viewer":null,"meterPost({\"postId\":\"406e1fd001f\",\"postMeteringOptions\":{}})":{"type":"id","generated":false,"id":"MeteringInfo:singleton","typename":"MeteringInfo"},"postResult({\"id\":\"406e1fd001f\"})":{"type":"id","generated":false,"id":"Post:406e1fd001f","typename":"Post"}},"MeteringInfo:singleton":{"__typename":"MeteringInfo","postIds":{"type":"json","json":[]},"maxUnlockCount":3,"unlocksRemaining":3},"Post:406e1fd001f":{"__typename":"Post","visibility":"PUBLIC","latestPublishedVersion":"f60694733c2d","collection":null,"id":"406e1fd001f","creator":{"type":"id","generated":false,"id":"User:193b10120c87","typename":"User"},"isLocked":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","sequence":null,"mediumUrl":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f","canonicalUrl":"","content({\"postMeteringOptions\":{}})":{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}})","typename":"PostContent"},"firstPublishedAt":1532512396952,"isPublished":true,"layerCake":0,"primaryTopic":null,"title":"機器\u002F深度學習-基礎數學(二):梯度下降法(gradient descent)","pendingCollection":null,"statusForCollection":null,"readingTime":6.869999999999999,"license":"ALL_RIGHTS_RESERVED","allowResponses":true,"tags":[],"viewerClapCount":null,"readingList":"READING_LIST_NONE","clapCount":2532,"voterCount":242,"recommenders":[],"responsesCount":4,"collaborators":[],"translationSourcePost":null,"inResponseToPostResult":null,"inResponseToMediaResource":null,"curationEligibleAt":0,"audioVersionUrl":null,"socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1555574951949,"previewContent":{"type":"id","generated":true,"id":"$Post:406e1fd001f.previewContent","typename":"PreviewContent"},"previewImage":{"type":"id","generated":false,"id":"ImageMetadata:1*ohVPiStlsbMP0XL1_X-fkQ.gif","typename":"ImageMetadata"},"updatedAt":1555574951949,"topics":[],"isSuspended":false},"User:193b10120c87":{"id":"193b10120c87","__typename":"User","isSuspended":false,"allowNotes":true,"name":"Tommy Huang","isFollowing":false,"username":"chih.sheng.huang821","bio":"怕老了忘記這些吃飯的知識，開始寫文章記錄機器\u002F深度學習相關內容。黃志勝 Chih-Sheng Huang (Tommy), mail: chih.sheng.huang821@gmail.com","imageId":"1*d_eKs6OyA07h7e8tXxj5OA.jpeg","mediumMemberAt":0,"isBlocking":false,"isPartnerProgramEnrolled":false,"twitterScreenName":""},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}})":{"isLockedPreviewOnly":false,"validatedShareKey":"","__typename":"PostContent","bodyModel":{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel","typename":"RichText"}},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.0":{"name":"7fa6","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.1":{"name":"1e01","startIndex":1,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.2":{"name":"ef5a","startIndex":3,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.3":{"name":"9a39","startIndex":15,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.4":{"name":"d66a","startIndex":35,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.5":{"name":"7e5d","startIndex":50,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.6":{"name":"6743","startIndex":60,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.7":{"name":"f353","startIndex":70,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel":{"sections":[{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.0","typename":"Section"},{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.1","typename":"Section"},{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.2","typename":"Section"},{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.3","typename":"Section"},{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.4","typename":"Section"},{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.5","typename":"Section"},{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.6","typename":"Section"},{"type":"id","generated":true,"id":"$Post:406e1fd001f.content({\"postMeteringOptions\":{}}).bodyModel.sections.7","typename":"Section"}],"paragraphs":[{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_0","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_1","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_2","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_3","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_4","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_5","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_6","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_7","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_8","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_9","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_10","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_11","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_12","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_13","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_14","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_15","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_16","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_17","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_18","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_19","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_20","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_21","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_22","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_23","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_24","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_25","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_26","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_27","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_28","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_29","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_30","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_31","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_32","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_33","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_34","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_35","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_36","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_37","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_38","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_39","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_40","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_41","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_42","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_43","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_44","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_45","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_46","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_47","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_48","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_49","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_50","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_51","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_52","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_53","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_54","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_55","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_56","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_57","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_58","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_59","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_60","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_61","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_62","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_63","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_64","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_65","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_66","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_67","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_68","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_69","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_70","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f60694733c2d_71","typename":"Paragraph"}],"__typename":"RichText"},"Paragraph:f60694733c2d_0":{"id":"f60694733c2d_0","name":"347b","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"機器\u002F深度學習-基礎數學(二):梯度下降法(gradient descent)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_1":{"id":"f60694733c2d_1","name":"018d","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"其他相關連結","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_2":{"id":"f60694733c2d_2","name":"11a4","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"機器\u002F深度學習-基礎數學篇(一):純量、向量、矩陣、矩陣運算、逆矩陣、矩陣轉置介紹\n機器\u002F深度學習-基礎數學(二):梯度下降法(gradient descent)\n機器\u002F深度學習-基礎數學(三):梯度最佳解相關算法(gradient descent optimization algorithms)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_2.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_2.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_2.markups.2","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_2.markups.0":{"type":"A","start":0,"end":41,"href":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8%E7%AF%87-%E4%B8%80-1c8337179ad6","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_2.markups.1":{"type":"A","start":42,"end":82,"href":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%BA%8C-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-gradient-descent-406e1fd001f","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_2.markups.2":{"type":"A","start":82,"end":149,"href":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%B8%89-%E6%A2%AF%E5%BA%A6%E6%9C%80%E4%BD%B3%E8%A7%A3%E7%9B%B8%E9%97%9C%E7%AE%97%E6%B3%95-gradient-descent-optimization-algorithms-b61ed1478bd7","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_3":{"id":"f60694733c2d_3","name":"081d","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"微積分找極值方式:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_4":{"id":"f60694733c2d_4","name":"d10a","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"一般微積分說將要找極大值或極小值的式子做微分等於0找解，找到的不是極大值，就是極小值，是極大還是極小就看二階微分帶入找出來的解，看結果是大於0，還是小於0。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_5":{"id":"f60694733c2d_5","name":"c75c","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這邊舉個範例","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_6":{"id":"f60694733c2d_6","name":"10c8","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*phk6yUULlWuub2EsFNX6Qw.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*phk6yUULlWuub2EsFNX6Qw.png":{"id":"1*phk6yUULlWuub2EsFNX6Qw.png","originalHeight":68,"originalWidth":378,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_7":{"id":"f60694733c2d_7","name":"a23f","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"微分很簡單","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_8":{"id":"f60694733c2d_8","name":"5c12","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*p5hZPjcr5j_BdFZEgwh6-A.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*p5hZPjcr5j_BdFZEgwh6-A.png":{"id":"1*p5hZPjcr5j_BdFZEgwh6-A.png","originalHeight":103,"originalWidth":450,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_9":{"id":"f60694733c2d_9","name":"d9c4","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"微分等於0","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_10":{"id":"f60694733c2d_10","name":"799e","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*3M9cY-HoWK84xUoXP6Ybjw.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*3M9cY-HoWK84xUoXP6Ybjw.png":{"id":"1*3M9cY-HoWK84xUoXP6Ybjw.png","originalHeight":148,"originalWidth":526,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_11":{"id":"f60694733c2d_11","name":"d70d","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"二階微分","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_12":{"id":"f60694733c2d_12","name":"2211","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*fo5vuij88sB-595BSGkLQg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*fo5vuij88sB-595BSGkLQg.png":{"id":"1*fo5vuij88sB-595BSGkLQg.png","originalHeight":103,"originalWidth":444,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_13":{"id":"f60694733c2d_13","name":"65a0","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"所以剛剛的式子找到的極值是極小值，當x=5，有極小值-24。","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_13.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_13.markups.0":{"type":"EM","start":18,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_14":{"id":"f60694733c2d_14","name":"490b","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這個範例是可以找的到唯一解的式子，但在實際應用根本不可能向微積分考試這麼理想一定找得到唯一解，這時候就必須要靠找近似解的方式去逼近極值，也就是這篇要說的梯度下降法(gradient descent)。","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_14.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_14.markups.0":{"type":"STRONG","start":19,"end":46,"href":"","anchorType":"LINK","userId":"","linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_15":{"id":"f60694733c2d_15","name":"04f6","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"梯度下降法(gradient descent)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_16":{"id":"f60694733c2d_16","name":"ff7b","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"梯度下降法(gradient descent)是最佳化理論裡面的一個一階找最佳解的一種方法，主要是希望用梯度下降法找到函數(剛剛舉例的式子)的局部最小值，因為梯度的方向是走向局部最大的方向，所以在梯度下降法中是往梯度的反方向走。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_17":{"id":"f60694733c2d_17","name":"7953","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這邊我們先大概說一下梯度， 要算一個函數f(x)的梯度有一個前提，就是這個函數要是任意可微分函數，這也是深度學習為什麼都要找可微分函數出來當激活函數(activation function)。","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_17.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_17.markups.1","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_17.markups.0":{"type":"EM","start":20,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_17.markups.1":{"type":"EM","start":22,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_18":{"id":"f60694733c2d_18","name":"f46c","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"一維度的純量x的梯度，通常用f'(x)表示。\n 多維度的向量x的梯度，通常用∇f(x)表示。","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_18.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_18.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_18.markups.2","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_18.markups.3","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_18.markups.4","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_18.markups.5","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_18.markups.6","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_18.markups.7","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_18.markups.0":{"type":"STRONG","start":30,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_18.markups.1":{"type":"STRONG","start":41,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_18.markups.2":{"type":"EM","start":6,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_18.markups.3":{"type":"EM","start":14,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_18.markups.4":{"type":"EM","start":17,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_18.markups.5":{"type":"EM","start":30,"end":31,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_18.markups.6":{"type":"EM","start":39,"end":40,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_18.markups.7":{"type":"EM","start":41,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19":{"id":"f60694733c2d_19","name":"8a3d","__typename":"Paragraph","type":"PQ","href":null,"layout":null,"metadata":null,"text":"白話一點，一維度的純量x的梯度就是算f(x)對x的微分，多維度的向量x的梯度就是算f(x)對x所有元素的偏微分","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.2","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.3","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.4","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.5","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.6","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.7","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.8","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.9","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_19.markups.10","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_19.markups.0":{"type":"STRONG","start":34,"end":35,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.1":{"type":"STRONG","start":43,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.2":{"type":"STRONG","start":46,"end":47,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.3":{"type":"EM","start":11,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.4":{"type":"EM","start":18,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.5":{"type":"EM","start":20,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.6":{"type":"EM","start":23,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.7":{"type":"EM","start":34,"end":35,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.8":{"type":"EM","start":41,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.9":{"type":"EM","start":43,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_19.markups.10":{"type":"EM","start":46,"end":47,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_20":{"id":"f60694733c2d_20","name":"5250","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"一維度的容易理解，上面也有範例。多維度的梯度，一般公式寫的是","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_21":{"id":"f60694733c2d_21","name":"a64d","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*ySkxwxuRSZ8bWqUm3bp3-Q.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*ySkxwxuRSZ8bWqUm3bp3-Q.png":{"id":"1*ySkxwxuRSZ8bWqUm3bp3-Q.png","originalHeight":352,"originalWidth":472,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_22":{"id":"f60694733c2d_22","name":"999f","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這邊可能有人看不懂，我舉一個實際的例子","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_23":{"id":"f60694733c2d_23","name":"cb21","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"假設我們的x有兩個維度的參數，梯度就分別需要對不同維度的參數做偏微分","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_23.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_23.markups.1","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_23.markups.0":{"type":"STRONG","start":5,"end":6,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_23.markups.1":{"type":"EM","start":5,"end":6,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_24":{"id":"f60694733c2d_24","name":"a5cf","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*kPVvP0czBbIA9vZ6rBT6dg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*kPVvP0czBbIA9vZ6rBT6dg.png":{"id":"1*kPVvP0czBbIA9vZ6rBT6dg.png","originalHeight":91,"originalWidth":538,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_25":{"id":"f60694733c2d_25","name":"168a","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"多維度的範例1:","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_25.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_25.markups.0":{"type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_26":{"id":"f60694733c2d_26","name":"e2f1","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*6Zmb1wh7IKoWcNbak19ubQ.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*6Zmb1wh7IKoWcNbak19ubQ.png":{"id":"1*6Zmb1wh7IKoWcNbak19ubQ.png","originalHeight":341,"originalWidth":1000,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_27":{"id":"f60694733c2d_27","name":"cfd2","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"多維度的範例2:","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_27.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_27.markups.0":{"type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_28":{"id":"f60694733c2d_28","name":"80b3","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*N9jrA8m7wkczNbVX13nleg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*N9jrA8m7wkczNbVX13nleg.png":{"id":"1*N9jrA8m7wkczNbVX13nleg.png","originalHeight":732,"originalWidth":1000,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_29":{"id":"f60694733c2d_29","name":"1af4","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"從一開始的純量的微分到多維度的梯度，大家應該知道梯度怎麼算了。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_30":{"id":"f60694733c2d_30","name":"6df3","__typename":"Paragraph","type":"H4","href":null,"layout":null,"metadata":null,"text":"那算出來的梯度跟梯度下降法有什麼關係?","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_31":{"id":"f60694733c2d_31","name":"79ad","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"在機器學習，通常有一個損失函數(loss function或稱為cost function，在最佳化理論我們會稱為目標函數objection function)，我們通常是希望這個函數越小越好(也就是找極小值)，這邊可以參考回歸分析或是MLP描述的目標函數。\n雖然回歸有唯一解，但我在回歸最後面有寫到，因為回歸有算反矩陣等，計算複雜度相對梯度下降法來的複雜，而且也有可以因為矩陣奇異，反矩陣推估錯誤，導致模型估計錯誤，所以用梯度下降法來做應該比較合適。","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_31.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_31.markups.1","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_31.markups.0":{"type":"A","start":112,"end":116,"href":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8-linear-regression-3a271a7453e","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_31.markups.1":{"type":"A","start":118,"end":121,"href":"https:\u002F\u002Fmedium.com\u002F@chih.sheng.huang821\u002F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF-%E5%A4%9A%E5%B1%A4%E6%84%9F%E7%9F%A5%E6%A9%9F-multilayer-perceptron-mlp-%E5%90%AB%E8%A9%B3%E7%B4%B0%E6%8E%A8%E5%B0%8E-ee4f3d5d1b41","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_32":{"id":"f60694733c2d_32","name":"3eab","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"梯度下降法是一種不斷去更新參數(這邊參數用x表示)找「解」的方法，所以一定要先隨機產生一組初始參數的「解」，然後根據這組隨機產生的「解」開始算此「解」的梯度方向大小，然後將這個「解」去減去梯度方向，很饒舌，公式如下:","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_32.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_32.markups.1","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_32.markups.0":{"type":"STRONG","start":0,"end":32,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_32.markups.1":{"type":"EM","start":21,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_33":{"id":"f60694733c2d_33","name":"790b","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*cGNuS-tDLAdY_P9fcia7qQ.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*cGNuS-tDLAdY_P9fcia7qQ.png":{"id":"1*cGNuS-tDLAdY_P9fcia7qQ.png","originalHeight":73,"originalWidth":446,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_34":{"id":"f60694733c2d_34","name":"b96a","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這邊的t是第幾次更新參數，γ是學習率(Learning rate)。\n梯度的方向我們知道了，但找「解」的時候公式是往梯度的方向更新，一次要更新多少，就是由學習率來控制的，後面會有範例說這個學習率影響的程度。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_35":{"id":"f60694733c2d_35","name":"e0af","__typename":"Paragraph","type":"H4","href":null,"layout":null,"metadata":null,"text":"範例1","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_36":{"id":"f60694733c2d_36","name":"70f9","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"我這邊用下面這個函數(雖然它有唯一解)當例子來做梯度下降法，多維度基本上差不多","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_37":{"id":"f60694733c2d_37","name":"8d31","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*4Lyw_bUByHDuFTAIMl8IHg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*4Lyw_bUByHDuFTAIMl8IHg.png":{"id":"1*4Lyw_bUByHDuFTAIMl8IHg.png","originalHeight":203,"originalWidth":720,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_38":{"id":"f60694733c2d_38","name":"0729","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"此例子基本上學習率可以不用太小，就可以很快就找到解，我後面有跑不同學習率看幾次可以跑到近似解。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_39":{"id":"f60694733c2d_39","name":"a038","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*WYEjI4VaAHWv0JEqnyf3QA.png","typename":"ImageMetadata"},"text":"f(x)=x²-10x+1","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*WYEjI4VaAHWv0JEqnyf3QA.png":{"id":"1*WYEjI4VaAHWv0JEqnyf3QA.png","originalHeight":420,"originalWidth":561,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_40":{"id":"f60694733c2d_40","name":"b5d7","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Note: 我這邊列出切線和法線公式，主要是我範例用的圖有畫出這兩條線。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_41":{"id":"f60694733c2d_41","name":"ab2b","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*Qm6tVOo_MJbwFtDJb1hMCQ.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*Qm6tVOo_MJbwFtDJb1hMCQ.png":{"id":"1*Qm6tVOo_MJbwFtDJb1hMCQ.png","originalHeight":250,"originalWidth":1008,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_42":{"id":"f60694733c2d_42","name":"e360","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"剛有提到我們需要先設定一個初始化的「解」，此例我設定x(0)=20(故意跟最佳值有差距)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_43":{"id":"f60694733c2d_43","name":"3f4f","__typename":"Paragraph","type":"PQ","href":null,"layout":null,"metadata":null,"text":"紅色的點是每一次更新找到的解","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_44":{"id":"f60694733c2d_44","name":"14f4","__typename":"Paragraph","type":"PQ","href":null,"layout":null,"metadata":null,"text":"紅色線是法線，藍色線是切線，法線和切線這兩條線是垂直的，但因為x軸和y軸scale不一樣，所以看不出來它是垂直的。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_45":{"id":"f60694733c2d_45","name":"dd1e","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*PyXvVaaz4OSA_J6VdXlAJw.gif","typename":"ImageMetadata"},"text":"學習率是0.01","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*PyXvVaaz4OSA_J6VdXlAJw.gif":{"id":"1*PyXvVaaz4OSA_J6VdXlAJw.gif","originalHeight":420,"originalWidth":560,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_46":{"id":"f60694733c2d_46","name":"e781","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*HoYoC5wDbhGwoQsl7yWDhw.gif","typename":"ImageMetadata"},"text":"學習率是0.1","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*HoYoC5wDbhGwoQsl7yWDhw.gif":{"id":"1*HoYoC5wDbhGwoQsl7yWDhw.gif","originalHeight":420,"originalWidth":560,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_47":{"id":"f60694733c2d_47","name":"b8a2","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*-36NUUMhBq7J1rL8agmEgw.gif","typename":"ImageMetadata"},"text":"學習率是0.9","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*-36NUUMhBq7J1rL8agmEgw.gif":{"id":"1*-36NUUMhBq7J1rL8agmEgw.gif","originalHeight":420,"originalWidth":560,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_48":{"id":"f60694733c2d_48","name":"3488","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*StvoG20bZY6rAbVKGcxWnw.gif","typename":"ImageMetadata"},"text":"學習率是1","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*StvoG20bZY6rAbVKGcxWnw.gif":{"id":"1*StvoG20bZY6rAbVKGcxWnw.gif","originalHeight":420,"originalWidth":560,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_49":{"id":"f60694733c2d_49","name":"dc33","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"由上圖我們可以發現學習率對找解影響很大，學習率太低，需要更新很多次才能到最佳解，學習率太高，有可能會造成梯度走不進去局部極值(但也可以擺脫局部極值的問題，等等有範例)。這邊尤其是當學習率是1的時候，基本上梯度下降法根本走不到局部極小值，一直在左右對跳，所以最佳化理論有很多衍生的方式或更先進的方式去解決這些問題(這邊先不介紹)。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_50":{"id":"f60694733c2d_50","name":"b4d6","__typename":"Paragraph","type":"H4","href":null,"layout":null,"metadata":null,"text":"範例2","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_51":{"id":"f60694733c2d_51","name":"d995","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"我設計一個有局部極小值和全域極小值的函數，到四次方，但我是亂打的，所以x=10，函數的值就超大的。","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_51.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_51.markups.0":{"type":"EM","start":35,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_52":{"id":"f60694733c2d_52","name":"b312","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*E82CWULL7J2qNy-8ab6ZyA.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*E82CWULL7J2qNy-8ab6ZyA.png":{"id":"1*E82CWULL7J2qNy-8ab6ZyA.png","originalHeight":330,"originalWidth":856,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_53":{"id":"f60694733c2d_53","name":"41f2","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"我們需要先設定一個初始化的「解」，此例我設定x(0)=-20(故意跟最佳值有差距)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_54":{"id":"f60694733c2d_54","name":"99ec","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*QkG6kdDJ1p6M62sdUX6brQ.gif","typename":"ImageMetadata"},"text":"學習率是0.00001","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*QkG6kdDJ1p6M62sdUX6brQ.gif":{"id":"1*QkG6kdDJ1p6M62sdUX6brQ.gif","originalHeight":420,"originalWidth":560,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_55":{"id":"f60694733c2d_55","name":"4c9a","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"所以這個學習率太小，初始值不好，解就會掉到局部極小值。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_56":{"id":"f60694733c2d_56","name":"2db9","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*gt1aMVhydotP2I7urp-Z0A.gif","typename":"ImageMetadata"},"text":"學習率是0.0004","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*gt1aMVhydotP2I7urp-Z0A.gif":{"id":"1*gt1aMVhydotP2I7urp-Z0A.gif","originalHeight":420,"originalWidth":560,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_57":{"id":"f60694733c2d_57","name":"76f9","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這個學習率(0.0004)對此例子來說，雖然步伐夠大跳出了局部極值，但到全域極值時，因為步伐太大，所以走不到最好的值。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_58":{"id":"f60694733c2d_58","name":"4f91","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*yDhjLYUAX8l-yrVC1thDOA.gif","typename":"ImageMetadata"},"text":"學習率是0.0003","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*yDhjLYUAX8l-yrVC1thDOA.gif":{"id":"1*yDhjLYUAX8l-yrVC1thDOA.gif","originalHeight":420,"originalWidth":560,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_59":{"id":"f60694733c2d_59","name":"dc1f","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這個學習率(0.0003)對此例子來說就夠了，可以走到全域極值。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_60":{"id":"f60694733c2d_60","name":"f1e9","__typename":"Paragraph","type":"H4","href":null,"layout":null,"metadata":null,"text":"補充說明沒有極值的狀況","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_61":{"id":"f60694733c2d_61","name":"b73c","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"雖然說微分可以找極值，但很多函數既無最大值，也無最小值，因為函數的長像彎彎曲曲很多次，有局部極值或鞍部，所以一次維分等於0求得的可能是極值，也可以是相對極值。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_62":{"id":"f60694733c2d_62","name":"41cb","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"上面舉的某一個例子，就發生這種情況","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_63":{"id":"f60694733c2d_63","name":"1034","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*KpbAyEz4ISnYlx4nLwAEvg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*KpbAyEz4ISnYlx4nLwAEvg.png":{"id":"1*KpbAyEz4ISnYlx4nLwAEvg.png","originalHeight":452,"originalWidth":1000,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_64":{"id":"f60694733c2d_64","name":"7bf8","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這個方程式可以找到極值「解」讓f(x)最小(f(x)=16)，但這個值真的是最小嗎?\n我找個點隨便帶入","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_64.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_64.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_64.markups.2","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f60694733c2d_64.markups.3","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_64.markups.0":{"type":"EM","start":15,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_64.markups.1":{"type":"EM","start":17,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_64.markups.2":{"type":"EM","start":22,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_64.markups.3":{"type":"EM","start":24,"end":25,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f60694733c2d_65":{"id":"f60694733c2d_65","name":"8e0c","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*RBk8s9zQ4X4fBTJKJ7O7Og.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*RBk8s9zQ4X4fBTJKJ7O7Og.png":{"id":"1*RBk8s9zQ4X4fBTJKJ7O7Og.png","originalHeight":91,"originalWidth":544,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_66":{"id":"f60694733c2d_66","name":"e5ed","__typename":"Paragraph","type":"PQ","href":null,"layout":null,"metadata":null,"text":"這個值比微分的最佳解還要小，所以可以得知微分等於0找到的不一定是最佳解，所以用梯度下降法，可以找到更好的解。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_67":{"id":"f60694733c2d_67","name":"4f92","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"下圖我將上式子畫出來它的坐標跟微分解還有梯度法如何讓解更新。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_68":{"id":"f60694733c2d_68","name":"e2fe","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*ohVPiStlsbMP0XL1_X-fkQ.gif","typename":"ImageMetadata"},"text":"紅色點是微分解，藍色點是梯度法不斷更新找解(學習率設定在0.01，主要是為了讓解跑慢一點，動畫才好看)。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*ohVPiStlsbMP0XL1_X-fkQ.gif":{"id":"1*ohVPiStlsbMP0XL1_X-fkQ.gif","originalHeight":420,"originalWidth":560,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f60694733c2d_69":{"id":"f60694733c2d_69","name":"10fd","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"這邊我只跑100次，因為解在無窮大的地方，但可以看到loss值不斷在減少中。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_70":{"id":"f60694733c2d_70","name":"90e9","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"當然還有很多手法(比如牛頓法， momentum或是Adam)可以避免上述問題，或是讓解找的更快，但此篇文章只在說明，梯度下降法是什麼，跟它怎麼運作的，未來有時間可以在將這些補上。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:f60694733c2d_71":{"id":"f60694733c2d_71","name":"ca19","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"坦白說這篇內容雖然很好寫，但作圖很花時間和腦力的，喜歡這篇的可以多拍幾下手給個獎勵吧。","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"$Post:406e1fd001f.previewContent":{"subtitle":"其他相關連結","__typename":"PreviewContent"}}</script><script src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/manifest.f8d151fa.js.下載"></script><script src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/vendors_main.93cb1e58.chunk.js.下載"></script><script src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/main.8e5648c2.chunk.js.下載"></script><script src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/vendors_screen.landingpages.trumpland_screen.post_screen.post.amp_screen.post.series_screen.profile__b319665e.f2be28a6.chunk.js.下載"></script>
<script src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/screen.post_screen.post.amp_screen.post.series_screen.profile_screen.sequence.library_screen.sequenc_036c6b37.3d229283.chunk.js.下載"></script>
<script src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/screen.landingpages.trumpland_screen.post_screen.post.amp_screen.post.series_screen.profile_screen.s_5e114ebe.ba9427b7.chunk.js.下載"></script>
<script src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/screen.post_screen.post.amp_screen.sequence.post.cc1a8b41.chunk.js.下載"></script>
<script src="./機器_深度學習-基礎數學(二)_梯度下降法(gradient descent) - Tommy Huang - Medium_files/screen.post.9cb242a3.chunk.js.下載"></script><script>window.main();</script></body></html>