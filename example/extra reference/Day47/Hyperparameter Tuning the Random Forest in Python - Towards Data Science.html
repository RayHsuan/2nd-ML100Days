<!DOCTYPE html>
<!-- saved from url=(0112)https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/branch-latest.min.js.下載"></script><script>!function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a="pointerup",u="pointercancel";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;"pointerdown"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)}}function w(e){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(n){e(n,l,r)})}w(c),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){e.push(n),s()}}(addEventListener,removeEventListener)</script><title>Hyperparameter Tuning the Random Forest in Python - Towards Data Science</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-01-10T15:14:58.001Z"><meta data-rh="true" name="title" content="Hyperparameter Tuning the Random Forest in Python - Towards Data Science"><meta data-rh="true" property="og:title" content="Hyperparameter Tuning the Random Forest in Python"><meta data-rh="true" property="twitter:title" content="Hyperparameter Tuning the Random Forest in Python"><meta data-rh="true" name="twitter:site" content="@TDataScience"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/28d2aa77dd74"><meta data-rh="true" property="al:android:url" content="medium://p/28d2aa77dd74"><meta data-rh="true" property="al:ios:url" content="medium://p/28d2aa77dd74"><meta data-rh="true" name="apple-itunes-app" content="app-id=828256236,app-argument=medium://p/28d2aa77dd74"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="So we’ve built a random forest model to solve our machine learning problem (perhaps by following this end-to-end guide) but we’re not too impressed by the results. What are our options? As we saw in…"><meta data-rh="true" property="og:description" content="Improving the Random Forest Part Two"><meta data-rh="true" property="twitter:description" content="Improving the Random Forest Part Two"><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/1*mTBEiGR_W-cYMw8cIWQh0w.jpeg"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/1*mTBEiGR_W-cYMw8cIWQh0w.jpeg"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="/@williamkoehrsen"><meta data-rh="true" name="twitter:creator" content="@koehrsen_will"><meta data-rh="true" name="author" content="Will Koehrsen"><meta data-rh="true" name="robots" content="index,follow"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" value="Reading time"><meta data-rh="true" name="twitter:data1" value="12 min read"><meta data-rh="true" name="parsely-post-id" content="28d2aa77dd74"><link data-rh="true" rel="publisher" href="https://plus.google.com/103654360130207659246"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/m2.css"><link data-rh="true" rel="author" href="https://towardsdatascience.com/@williamkoehrsen"><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/28d2aa77dd74"><style type="text/css" data-fela-rehydration="421" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@-moz-keyframes k1{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@keyframes k1{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:fixed}.n{top:0}.o{left:0}.p{right:0}.q{z-index:500}.r{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.s{transition:transform 300ms ease}.t{will-change:transform}.v{padding-left:24px}.w{padding-right:24px}.x{margin-left:auto}.y{margin-right:auto}.z{height:65px}.ab{width:100%}.ac{max-width:1080px}.ae{box-sizing:border-box}.af{display:flex}.ag{align-items:center}.aj{flex:1 0 auto}.ak{margin-left:-6px}.al{fill:rgba(0, 0, 0, 0.84)}.am{flex:0 0 auto}.an{margin-left:16px}.ao{font-family:medium-content-sans-serif-font, "Lucida Grande", "Lucida Sans Unicode", "Lucida Sans", Geneva, Arial, sans-serif}.ap{font-style:normal}.aq{line-height:20px}.ar{font-size:15.8px}.as{letter-spacing:0px}.at{color:rgba(0, 0, 0, 0.54)}.au{fill:rgba(0, 0, 0, 0.54)}.av{color:rgba(90, 118, 144, 1)}.aw{fill:rgba(102, 138, 170, 1)}.ax{font-size:inherit}.ay{border:inherit}.az{font-family:inherit}.ba{letter-spacing:inherit}.bb{font-weight:inherit}.bc{padding:0}.bd{margin:0}.be:hover{cursor:pointer}.bf:hover{color:rgba(84, 108, 131, 1)}.bg:hover{fill:rgba(90, 118, 144, 1)}.bh:focus{outline:none}.bi:disabled{cursor:default}.bj:disabled{color:rgba(3, 168, 124, 0.5)}.bk:disabled{fill:rgba(3, 168, 124, 0.5)}.bl{padding:8px 16px}.bm{background:0}.bn{border-color:rgba(102, 138, 170, 1)}.bo:hover{border-color:rgba(90, 118, 144, 1)}.bp{border-radius:4px}.bq{border-width:1px}.br{border-style:solid}.bs{display:inline-block}.bt{text-decoration:none}.bu{border-top:none}.bv{background-color:rgba(53, 88, 118, 1)}.bx{height:54px}.by{overflow:hidden}.bz{margin-right:40px}.ca{height:36px}.cb{width:97px}.cc{overflow:auto}.cd{flex:0 1 auto}.ce{list-style-type:none}.cf{line-height:40px}.cg{white-space:nowrap}.ch{overflow-x:auto}.ci{align-items:flex-start}.cj{margin-top:20px}.ck{padding-top:20px}.cl{height:80px}.cm{height:20px}.cn{margin-right:15px}.co{margin-left:15px}.cp:first-child{margin-left:0}.cq{min-width:1px}.cr{background-color:rgba(197, 210, 225, 1)}.cs{font-weight:300}.ct{font-size:15px}.cu{line-height:21px}.cv{color:rgba(197, 210, 225, 1)}.cw{text-transform:uppercase}.cx{letter-spacing:1px}.cy{color:inherit}.cz{fill:inherit}.da:hover{color:rgba(251, 255, 255, 1)}.db:hover{fill:rgba(233, 241, 250, 1)}.dc:disabled{color:rgba(150, 171, 191, 1)}.dd:disabled{fill:rgba(150, 171, 191, 1)}.de{margin-bottom:0px}.df{height:119px}.di{max-width:728px}.dj{flex-direction:column}.dk{opacity:0}.dl{pointer-events:none}.dm{will-change:opacity}.dn{transition:opacity 200ms}.do{width:131px}.dp{left:50%}.dq{transform:translateX(-516px)}.dr{top:calc(65px + 54px + 40px)}.ds{padding-bottom:28px}.dt{border-bottom:1px solid rgba(0, 0, 0, 0.1)}.du:hover{color:rgba(0, 0, 0, 0.9)}.dv:hover{fill:rgba(0, 0, 0, 0.9)}.dw:disabled{color:rgba(0, 0, 0, 0.54)}.dx:disabled{fill:rgba(0, 0, 0, 0.54)}.dy{font-weight:600}.dz{font-size:18px}.ea{color:rgba(0, 0, 0, 0.84)}.eb{padding-bottom:20px}.ec{padding-top:2px}.ed{font-size:16px}.ee{max-height:120px}.ef{text-overflow:ellipsis}.eg{display:-webkit-box}.eh{-webkit-line-clamp:6}.ei{-webkit-box-orient:vertical}.ej{padding:4px 12px}.ek{padding-top:28px}.el{margin-bottom:19px}.em{margin-left:-5px}.en{margin-right:5px}.eo{position:relative}.ep{outline:0}.eq{border:0}.er{user-select:none}.es{cursor:pointer}.et> svg{pointer-events:none}.eu:active{border-style:none}.ev{-webkit-user-select:none}.ew:focus{fill:rgba(90, 118, 144, 1)}.ex{margin-top:5px}.ey button{text-align:left}.ez{margin-top:40px}.fa{clear:both}.fb{justify-content:center}.fh{max-width:680px}.fi{flex-wrap:wrap}.fj{margin-top:25px}.fk{margin-right:8px}.fl{margin-bottom:8px}.fm{border-radius:3px}.fn{padding:5px 10px}.fo{background:rgba(0, 0, 0, 0.05)}.fp{line-height:22px}.fq{margin-top:15px}.fr{justify-content:space-between}.fs{margin-right:16px}.ft{border:1px solid rgba(0, 0, 0, 0.1)}.fu{border-radius:50%}.fv{height:60px}.fw{transition:border-color 150ms ease}.fx{width:60px}.fy::before{background:
      radial-gradient(circle, rgba(90, 118, 144, 1) 60%, transparent 70%)
    }.fz::before{border-radius:50%}.ga::before{content:""}.gb::before{display:block}.gc::before{z-index:0}.gd::before{left:0}.ge::before{height:100%}.gf::before{position:absolute}.gg::before{top:0}.gh::before{width:100%}.gi:hover::before{animation:k1 2000ms infinite cubic-bezier(.1,.12,.25,1)}.gj:active{border-style:solid}.gk{background:rgba(255, 255, 255, 1)}.gl{transition:fill 200ms ease}.gm{z-index:2}.gn{height:100%}.go{position:absolute}.gp{padding-right:8px}.gq{display:none}.gr{padding-top:32px}.gs{border-top:1px solid rgba(0, 0, 0, 0.1)}.gt{margin-bottom:25px}.gu{margin-bottom:32px}.gv{min-height:80px}.ha{width:80px}.hb{padding-left:102px}.hd{letter-spacing:0.05em}.he{margin-bottom:6px}.hf{font-size:28px}.hg{line-height:36px}.hh{max-width:555px}.hi{max-width:450px}.hj{line-height:24px}.hl{max-width:550px}.hm{padding-top:25px}.hn{padding:20px}.ho{border:1px solid rgba(102, 138, 170, 1)}.hp{text-align:center}.hq{margin-top:64px}.hr{background-color:rgba(0, 0, 0, 0.02)}.hs{max-width:1032px}.ht{padding:60px 0}.hu{background-color:rgba(0, 0, 0, 0.9)}.il{padding-bottom:48px}.im{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.in{margin:0 -12px}.io{margin:0 12px}.ip{flex:1 1 0}.iq{padding-bottom:12px}.ir:hover{color:rgba(255, 255, 255, 0.99)}.is:hover{fill:rgba(255, 255, 255, 0.99)}.it:disabled{color:rgba(255, 255, 255, 0.7)}.iu:disabled{fill:rgba(255, 255, 255, 0.7)}.iv{color:rgba(255, 255, 255, 0.98)}.iw{fill:rgba(255, 255, 255, 0.98)}.ix{text-align:inherit}.iy{font-size:21.6px}.iz{letter-spacing:-0.32px}.ja{color:rgba(255, 255, 255, 0.7)}.jb{fill:rgba(255, 255, 255, 0.7)}.jc{text-decoration:underline}.jd{padding-bottom:8px}.je{padding-top:8px}.jf{width:200px}.jh:hover{text-decoration:underline}.ji{top:calc(100vh + 100px)}.jj{bottom:calc(100vh + 100px)}.jk{width:10px}.jl{word-break:break-word}.jm{word-wrap:break-word}.jn:after{display:block}.jo:after{content:""}.jp:after{clear:both}.jq{margin:0 auto}.jw{max-width:5472px}.jx{transition:opacity 100ms 400ms}.jy{transform:translateZ(0)}.jz{margin:auto}.ka{background-color:rgba(0, 0, 0, 0.05)}.kb{padding-bottom:56.28654970760234%}.kc{filter:blur(20px)}.kd{transform:scale(1.1)}.ke{visibility:visible}.kf{line-height:1.23}.kg{letter-spacing:0}.kh{font-family:medium-content-title-font, Georgia, Cambria, "Times New Roman", Times, serif}.ki{font-size:40px}.ko{margin-bottom:-0.27em}.kp{line-height:48px}.kq{margin-top:32px}.kr{height:48px}.ks{width:48px}.kt{margin-left:12px}.ku{margin-bottom:2px}.kw{max-height:20px}.kx{-webkit-line-clamp:1}.ky{margin-left:8px}.kz{padding:0px 8px}.la{border-color:rgba(0, 0, 0, 0.54)}.lb:hover{color:rgba(0, 0, 0, 0.97)}.lc:hover{fill:rgba(0, 0, 0, 0.97)}.ld:hover{border-color:rgba(0, 0, 0, 0.84)}.le:disabled{fill:rgba(0, 0, 0, 0.76)}.lf:disabled{border-color:rgba(0, 0, 0, 0.2)}.lg:disabled{cursor:inherit}.lh:disabled:hover{color:rgba(0, 0, 0, 0.54)}.li:disabled:hover{fill:rgba(0, 0, 0, 0.76)}.lj:disabled:hover{border-color:rgba(0, 0, 0, 0.2)}.lk{line-height:18px}.ll{line-height:1.58}.lm{letter-spacing:-0.004em}.ln{font-family:medium-content-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.ly{margin-bottom:-0.46em}.lz{font-weight:700}.ma{background-repeat:repeat-x}.mb{background-image:linear-gradient(to right,rgba(0, 0, 0, 0.84) 100%,rgba(0, 0, 0, 0.84) 0);background-image:url('data:image/svg+xml;utf8,<svg preserveAspectRatio="none" viewBox="0 0 1 1" xmlns="http://www.w3.org/2000/svg"><line x1="0" y1="0" x2="1" y2="1" stroke="rgba(0, 0, 0, 0.84)" /></svg>')}.mc{background-size:1px 1px}.md{background-position:0 1.05em;background-position:0 calc(1em + 1px)}.mr{max-width:11093px}.ms{padding-bottom:18.236725863156945%}.mt{line-height:1.4}.mu{margin-top:10px}.mx{line-height:1.12}.my{letter-spacing:-0.022em}.nj{margin-bottom:-0.28em}.np{font-style:italic}.nq{max-width:425px}.nr{padding-bottom:94.11764705882354%}.ns{max-width:1000px}.nt{padding-bottom:30.2%}.nu{max-width:469px}.nv{padding-bottom:52.45202558635395%}.nw{list-style-type:disc}.nx{margin-left:30px}.ny{padding-left:0px}.oe{line-height:1.18}.of{font-family:Menlo, Monaco, "Courier New", Courier, monospace}.og{margin-top:-0.09em}.oh{margin-bottom:-0.09em}.oi{white-space:pre-wrap}.oy{margin-bottom:-0.31em}.oz{padding-bottom:55.14705882352941%}.pa{max-width:686px}.pb{padding-bottom:69.24198250728864%}.pc{max-width:633px}.pd{padding-bottom:52.76461295418641%}.pe{max-width:645px}.pf{padding-bottom:51.78294573643411%}.pg{-webkit-user-select:none}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.fg{margin:0 24px}.ii{padding-left:24px}.ij{padding-right:24px}.ik{max-width:1080px}.jv{margin-top:32px}.kn{margin-top:0.78em}.lw{font-size:21px}.lx{margin-top:2em}.ml{max-width:1032px}.mq{margin-top:56px}.nh{font-size:34px}.ni{margin-top:1.95em}.no{margin-top:0.86em}.od{margin-top:1.05em}.on{margin-top:1.91em}.ow{font-size:26px}.ox{margin-top:1.72em}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.if{padding-left:24px}.ig{padding-right:24px}.ih{max-width:1080px}.mv{margin-left:auto}.mw{text-align:center}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.ic{padding-left:24px}.id{padding-right:24px}.ie{max-width:904px}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.ah{height:56px}.ai{display:flex}.bw{display:block}.dg{margin-bottom:0px}.dh{height:110px}.gw{margin-bottom:24px}.gx{align-items:center}.gy{width:102px}.gz{position:relative}.hc{padding-left:0}.hk{margin-top:24px}.hv{padding:32px 0}.hz{padding-left:24px}.ia{padding-right:24px}.ib{max-width:728px}.jg{width:140px}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.fc{margin:0 24px}.hw{padding-left:24px}.hx{padding-right:24px}.hy{max-width:552px}.jr{margin-top:24px}.kj{margin-top:0.39em}.kv{margin-bottom:0px}.lo{font-size:18px}.lp{margin-top:1.56em}.me{margin:0}.mf{max-width:100%}.mm{margin-top:40px}.mz{font-size:30px}.na{margin-top:1.2em}.nk{margin-top:0.67em}.nz{margin-top:1.34em}.oj{margin-top:1.41em}.oo{font-size:24px}.op{margin-top:1.23em}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.ff{margin:0 24px}.ju{margin-top:32px}.km{margin-top:0.78em}.lu{font-size:21px}.lv{margin-top:2em}.mk{max-width:1032px}.mp{margin-top:56px}.nf{font-size:34px}.ng{margin-top:1.95em}.nn{margin-top:0.86em}.oc{margin-top:1.05em}.om{margin-top:1.91em}.ou{font-size:26px}.ov{margin-top:1.72em}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.fe{margin:0 24px}.jt{margin-top:32px}.kl{margin-top:0.78em}.ls{font-size:21px}.lt{margin-top:2em}.mi{margin:0}.mj{max-width:100%}.mo{margin-top:56px}.nd{font-size:34px}.ne{margin-top:1.95em}.nm{margin-top:0.86em}.ob{margin-top:1.05em}.ol{margin-top:1.91em}.os{font-size:26px}.ot{margin-top:1.72em}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.fd{margin:0 24px}.js{margin-top:24px}.kk{margin-top:0.39em}.lq{font-size:18px}.lr{margin-top:1.56em}.mg{margin:0}.mh{max-width:100%}.mn{margin-top:40px}.nb{font-size:30px}.nc{margin-top:1.2em}.nl{margin-top:0.67em}.oa{margin-top:1.34em}.ok{margin-top:1.41em}.oq{font-size:24px}.or{margin-top:1.23em}</style><style type="text/css" data-fela-rehydration="421" data-fela-type="RULE" media="print">.u{display:none}</style><script charset="utf-8" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/vendors_tracing.eaae9f79.chunk.js.下載"></script><script charset="utf-8" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/tracing.8a1ef8a7.chunk.js.下載"></script><link rel="icon" href="https://miro.medium.com/fit/c/128/128/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg" data-rh="true"><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*mTBEiGR_W-cYMw8cIWQh0w.jpeg"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74","dateCreated":"2018-01-10T03:48:51.666Z","datePublished":"2018-01-10T03:48:51.666Z","dateModified":"2018-06-18T08:19:01.885Z","headline":"Hyperparameter Tuning the Random Forest in Python","name":"Hyperparameter Tuning the Random Forest in Python","description":"So we’ve built a random forest model to solve our machine learning problem (perhaps by following this end-to-end guide) but we’re not too impressed by the results. What are our options? As we saw in…","identifier":"28d2aa77dd74","keywords":["Lite:true","Tag:Machine Learning","Tag:Python","Tag:Data Science","Tag:Data","Topic:Data Science","Publication:towards-data-science","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:0"],"author":{"@type":"Person","name":"Will Koehrsen","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@williamkoehrsen"},"creator":["Will Koehrsen"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":161,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F161\u002F1*5EUO1kUYBthpOCPzRj_l2g.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"}</script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><nav class="l m n o p c q r s t u"><div class="branch-journeys-top"><div class="l c"><section class="v w x y z ab ac ae af ag ah ai"><div class="af ag aj q"><div class="ak l"><a href="https://medium.com/?source=post_page-----28d2aa77dd74----------------------" aria-label="Homepage"><svg width="45" height="45" viewBox="0 0 45 45" class="al"><path d="M5 40V5h35v35H5zm8.56-12.63c0 .56-.03.69-.32 1.03L10.8 31.4v.4h6.97v-.4L15.3 28.4c-.29-.34-.34-.5-.34-1.03v-8.95l6.13 13.36h.71l5.26-13.36v10.64c0 .3 0 .35-.19.53l-1.85 1.8v.4h9.2v-.4l-1.83-1.8c-.18-.18-.2-.24-.2-.53V15.94c0-.3.02-.35.2-.53l1.82-1.8v-.4h-6.47l-4.62 11.55-5.2-11.54h-6.8v.4l2.15 2.63c.24.3.29.37.29.77v10.35z"></path></svg></a></div></div><div class="l am q"><div class="af ag"><div class="af g"><div class="an l"><span class="ao b ap aq ar as l at au"><a href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_page-----28d2aa77dd74---------------------nav_reg-" class="av aw ax ay az ba bb bc bd be bf bg bh bi bj bk">Sign in</a></span></div></div><div class="an l"><button class="bl bm av aw bn bf bg bo be bp ao b ap aq ar as bq br ae bs bt bh">Get started</button></div></div></div></section></div><div class="bu l bv bw"><section class="v w x y bx ab ac ae by af ag"><div class="bz l am"><a href="https://towardsdatascience.com/?source=post_page-----28d2aa77dd74----------------------"><div class="ca cb l"><img alt="Towards Data Science" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_5EUO1kUYBthpOCPzRj_l2g.png" class="" width="97" height="36"></div></a></div><div class="cc l cd"><ul class="ce bd cf cg ch af ci g cj ck cl"><li class="af ag cm cn co cp"><span class="ao cs ct cu cv cw cx"><a href="https://towardsdatascience.com/data-science/home?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be da db bh bi dc dd">Data Science</a></span></li><li class="af ag cm cn co cp"><span class="ao cs ct cu cv cw cx"><a href="https://towardsdatascience.com/machine-learning/home?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be da db bh bi dc dd">Machine Learning</a></span></li><li class="af ag cm cn co cp"><span class="ao cs ct cu cv cw cx"><a href="https://towardsdatascience.com/programming/home?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be da db bh bi dc dd">Programming</a></span></li><li class="af ag cm cn co cp"><span class="ao cs ct cu cv cw cx"><a href="https://towardsdatascience.com/data-visualization/home?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be da db bh bi dc dd">Visualization</a></span></li><li class="af ag cm cn co cp"><span class="ao cs ct cu cv cw cx"><a href="https://towardsdatascience.com/artificial-intelligence/home?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be da db bh bi dc dd">AI</a></span></li><li class="af ag cm cn co cp"><span class="ao cs ct cu cv cw cx"><a href="https://towardsdatascience.com/data-journalism/home?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be da db bh bi dc dd">Journalism</a></span></li><li class="af ag cm cn co cp"><span class="ao cs ct cu cv cw cx"><a class="cy cz ax ay az ba bb bc bd be da db bh bi dc dd" href="https://towardsdatascience.com/toronto-machine-learning-summit-8bae371d4bb1?source=post_page-----28d2aa77dd74----------------------">Events</a></span></li><span class="cm cq cr"></span><li class="af ag cm cn co cp"><span class="ao cs ct cu cv cw cx"><a href="https://towardsdatascience.com/contribute/home?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be da db bh bi dc dd">Submit</a></span></li></ul></div></section></div></div></nav><div class="de df l dg dh"></div><article><section class="v w x y ab di ae af dj"></section><span class="l"></span><div><div class="go o ji jj jk dl"></div><div class="x y di eo"><div class="l h g f e"><aside class="pj go n" style="width: 572.5px;"><div class="pm pn go po cg ab"><h4 class="ao cs ct aq at"><span class="bs pn cg by ef">Top highlight</span></h4></div></aside></div></div><section class="jl jm jn jo jp"><div class="ae jq ab di v w"><figure class="jr js jt ju jv fa x y paragraph-image"><div class="x y jw"><div class="jz l eo ka"><div class="kb l"><div class="dk jx go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_mTBEiGR_W-cYMw8cIWQh0w.jpeg" class="go n o gn ab kc kd sy sz" width="700" height="394"></div><img class="ph pi go n o gn ab gk" width="700" height="394" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_mTBEiGR_W-cYMw8cIWQh0w(1).jpeg"><noscript><img src="https://miro.medium.com/max/1400/1*mTBEiGR_W-cYMw8cIWQh0w.jpeg" class="go n o gn ab" width="700" height="394"/></noscript></div></div></div></figure><div><div id="c73f" class="kf kg ea ap kh b ki kj kk kl km kn ko"><h1 class="kh b ki kp ea">Hyperparameter Tuning the Random Forest in Python</h1></div><div class="kq"><div class="ag af"><div><a href="https://towardsdatascience.com/@williamkoehrsen?source=post_page-----28d2aa77dd74----------------------"><img alt="Will Koehrsen" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_SckxdIFfjlR-cWXkL5ya-g.jpeg" class="l fu kr ks" width="48" height="48"></a></div><div class="kt ab l"><div class="af"><div style="flex:1"><span class="ao b ap aq ar as l ea al"><div class="ku af ag kv"><span class="ao cs ed aq by kw ef eg kx ei ea"><a href="https://towardsdatascience.com/@williamkoehrsen?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx">Will Koehrsen</a></span><div class="ky l am h"><button class="kz ea al bm la lb lc ld be dw le lf lg lh li lj bp ao b ap lk ct as bq br ae bs bt bh">Follow</button></div></div></span></div></div><span class="ao b ap aq ar as l at au"><span class="ao cs ed aq by kw ef eg kx ei at"><div><a class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx" href="https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74?source=post_page-----28d2aa77dd74----------------------">Jan 10, 2018</a> <!-- -->·<!-- --> <!-- -->12<!-- --> min read</div></span></span></div></div></div></div><p id="7725" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph=""><strong class="ln lz">Improving the Random Forest Part Two</strong></p><p id="a292" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">So we’ve built a random forest model to solve our machine learning problem (perhaps by following this <a class="cy bt ma mb mc md" target="_blank" href="https://towardsdatascience.com/random-forest-in-python-24d0893d51c0">end-to-end guide</a>) but we’re not too impressed by the results. What are our options? As we saw in the <a class="cy bt ma mb mc md" target="_blank" href="https://towardsdatascience.com/improving-random-forest-in-python-part-1-893916666cd">first part of this series</a>, our first step should be to gather more data and perform feature engineering. Gathering more data and feature engineering usually has the greatest payoff in terms of time invested versus improved performance, but when we have exhausted all data sources, it’s time to move on to model hyperparameter tuning. This post will focus on optimizing the random forest model in Python using Scikit-Learn tools. Although this article builds on part one, it fully stands on its own, and we will cover many widely-applicable machine learning concepts.</p></div><div class="fa"><div class="af fb"><div class="me mf mg mh mi mj ff mk fg ml ab"><figure class="mm mn mo mp mq fa paragraph-image"><div class="x y mr"><div class="jz l eo ka"><div class="ms l"><div class="dk jx go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_G1_rf6QQBIs_vO_d98WfAQ.png" class="go n o gn ab kc kd sy sz" width="1000" height="182"></div><img class="ph pi go n o gn ab gk" width="1000" height="182" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_G1_rf6QQBIs_vO_d98WfAQ(1).png"><noscript><img src="https://miro.medium.com/max/2000/1*G1_rf6QQBIs_vO_d98WfAQ.png" class="go n o gn ab" width="1000" height="182"/></noscript></div></div></div><figcaption class="at ed mt mu hp di x y mv mw ao cs" data-selectable-paragraph="">One Tree in a Random Forest</figcaption></figure></div></div></div><div class="ae jq ab di v w"><p id="792b" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">I have included Python code in this article where it is most instructive. Full code and data to follow along can be found on the project <a href="https://github.com/WillKoehrsen/Machine-Learning-Projects/tree/master/random_forest_explained" class="cy bt ma mb mc md" target="_blank">Github page</a>.</p><h1 id="0cfc" class="mx my ea ap ao dy mz na nb nc nd ne nf ng nh ni nj" data-selectable-paragraph="">A Brief Explanation of Hyperparameter Tuning</h1><p id="f0cc" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">The best way to think about hyperparameters is like the settings of an algorithm that can be adjusted to optimize performance, just as we might turn the knobs of <a href="https://electronics.howstuffworks.com/radio8.htm" class="cy bt ma mb mc md" target="_blank">an AM radio to get a clear signal</a> (or your parents might have!). While model <em class="np">parameters </em>are learned during training — such as the slope and intercept in a linear regression — <em class="np">hyperparameters</em> must be set by the data scientist before<em class="np"> </em>training. In the case of a random forest, hyperparameters include the number of decision trees in the forest and the number of features considered by each tree when splitting a node. (The parameters of a random forest are the variables and thresholds used to split each node learned during training). Scikit-Learn implements a set of <a href="https://arxiv.org/abs/1309.0238" class="cy bt ma mb mc md" target="_blank">sensible default hyperparameters </a>for all models, but these are not guaranteed to be optimal for a problem. The best hyperparameters are usually impossible to determine ahead of time, and tuning a model is where machine learning turns from a science into trial-and-error based engineering.</p><figure class="mm mn mo mp mq fa x y paragraph-image"><div class="x y nq"><div class="jz l eo ka"><div class="nr l"><div class="dk jx go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_0215Gzmw56XvORtB7-Torw.png" class="go n o gn ab kc kd sy sz" width="425" height="400"></div><img class="ph pi go n o gn ab gk" width="425" height="400" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_0215Gzmw56XvORtB7-Torw(1).png"><noscript><img src="https://miro.medium.com/max/850/1*0215Gzmw56XvORtB7-Torw.png" class="go n o gn ab" width="425" height="400"/></noscript></div></div></div><figcaption class="at ed mt mu hp di x y mv mw ao cs" data-selectable-paragraph="">Hyperparameters and Parameters</figcaption></figure><p id="87c2" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">Hyperparameter tuning relies more on experimental results than theory, and thus the best method to determine the optimal settings is to try many different combinations evaluate the performance of each model. However, evaluating each model only on the training set can lead to one of the most fundamental problems in machine learning: <a href="https://elitedatascience.com/overfitting-in-machine-learning" class="cy bt ma mb mc md" target="_blank">overfitting</a>.</p><p id="04bb" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">If we optimize the model for the training data, then our model will score very well on the training set, but will not be able to generalize to new data, such as in a test set. When a model performs highly on the training set but poorly on the test set, this is known as overfitting, or essentially creating a model that knows the training set very well but cannot be applied to new problems. It’s like a student who has memorized the simple problems in the textbook but has no idea how to apply concepts in the messy real world.</p><p id="1a60" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">An overfit model may look impressive on the training set, but will be useless in a real application. Therefore, the standard procedure for hyperparameter optimization accounts for overfitting through <a href="http://scikit-learn.org/stable/modules/cross_validation.html" class="cy bt ma mb mc md" target="_blank">cross validation</a>.</p><h1 id="5157" class="mx my ea ap ao dy mz na nb nc nd ne nf ng nh ni nj" data-selectable-paragraph="">Cross Validation</h1><p id="f5a4" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">The technique of cross validation (CV) is best explained by example using the most common method, <a href="http://statweb.stanford.edu/~tibs/sta306bfiles/cvwrong.pdf" class="cy bt ma mb mc md" target="_blank">K-Fold CV.</a> When we approach a machine learning problem, we make sure to split our data into a training and a testing set. In K-Fold CV, we further split our training set into K number of subsets, called folds. We then iteratively fit the model K times, each time training the data on K-1 of the folds and evaluating on the Kth fold (called the validation data). As an example, consider fitting a model with K = 5. The first iteration we train on the first four folds and evaluate on the fifth. The second time we train on the first, second, third, and fifth fold and evaluate on the fourth. We repeat this procedure 3 more times, each time evaluating on a different fold. At the very end of training, we average the performance on each of the folds to come up with final validation metrics for the model.</p><figure class="mm mn mo mp mq fa x y paragraph-image"><div class="x y ns"><div class="jz l eo ka"><div class="nt l"><div class="dk jx go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/0_KH3dnbGNcmyV_ODL.png" class="go n o gn ab kc kd sy sz" width="700" height="211"></div><img class="ph pi go n o gn ab gk" width="700" height="211" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/0_KH3dnbGNcmyV_ODL(1).png"><noscript><img src="https://miro.medium.com/max/1400/0*KH3dnbGNcmyV_ODL.png" class="go n o gn ab" width="700" height="211"/></noscript></div></div></div><figcaption class="at ed mt mu hp di x y mv mw ao cs" data-selectable-paragraph="">5 Fold Cross Validation (<a href="https://stackoverflow.com/questions/31947183/how-to-implement-walk-forward-testing-in-sklearn" class="cy bt ma mb mc md" target="_blank">Source</a>)</figcaption></figure><p id="0f63" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">For hyperparameter tuning, we perform many iterations of the entire K-Fold CV process, each time using different model settings. We then compare all of the models, select the best one, train it on the full training set, and then evaluate on the testing set. This sounds like an awfully tedious process! Each time we want to assess a different set of hyperparameters, we have to split our training data into K fold and train and evaluate K times. If we have 10 sets of hyperparameters and are using 5-Fold CV, that represents 50 training loops. Fortunately, as with most problems in machine learning, someone has solved our problem and model tuning with K-Fold CV can be automatically implemented in Scikit-Learn.</p><h1 id="f804" class="mx my ea ap ao dy mz na nb nc nd ne nf ng nh ni nj" data-selectable-paragraph="">Random Search Cross Validation in Scikit-Learn</h1><p id="453d" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">Usually, we only have a vague idea of the best hyperparameters and thus the best approach to narrow our search is to evaluate a wide range of values for each hyperparameter. <mark class="pk pl es">Using Scikit-Learn’s RandomizedSearchCV method, we can define a grid of hyperparameter ranges, and randomly sample from the grid, performing K-Fold CV with each combination of values.</mark></p><p id="dfa9" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">As a brief recap before we get into model tuning, we are dealing with a supervised regression machine learning problem. We are trying to predict the temperature tomorrow in our city (Seattle, WA) using past historical weather data. We have 4.5 years of training data, 1.5 years of test data, and are using 6 different features (variables) to make our predictions. (To see the full code for data preparation, see the <a href="https://github.com/WillKoehrsen/Machine-Learning-Projects/blob/master/random_forest_explained/Improving%20Random%20Forest%20Part%202.ipynb" class="cy bt ma mb mc md" target="_blank">notebook</a>).</p><p id="041b" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">Let’s examine the features quickly.</p><figure class="mm mn mo mp mq fa x y paragraph-image"><div class="x y nu"><div class="jz l eo ka"><div class="nv l"><div class="dk jx go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_Gr3BUzeZjEeS8q3G6b1pkg.png" class="go n o gn ab kc kd sy sz" width="469" height="246"></div><img class="ph pi go n o gn ab gk" width="469" height="246" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_Gr3BUzeZjEeS8q3G6b1pkg(1).png"><noscript><img src="https://miro.medium.com/max/938/1*Gr3BUzeZjEeS8q3G6b1pkg.png" class="go n o gn ab" width="469" height="246"/></noscript></div></div></div><figcaption class="at ed mt mu hp di x y mv mw ao cs" data-selectable-paragraph="">Features for Temperature Prediction</figcaption></figure><ul class=""><li id="ffab" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly nw nx ny" data-selectable-paragraph="">temp_1 = max temperature (in F) one day prior</li><li id="7df2" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">average = historical average max temperature</li><li id="3053" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">ws_1 = average wind speed one day prior</li><li id="107c" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">temp_2 = max temperature two days prior</li><li id="436b" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">friend = prediction from our “trusty” friend</li><li id="b4a5" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">year = calendar year</li></ul><p id="364f" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">In previous posts, we checked the data to check for anomalies and we know our data is clean. Therefore, we can skip the data cleaning and jump straight into hyperparameter tuning.</p><p id="2a58" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">To look at the available hyperparameters, we can create a random forest and examine the default values.</p><pre class="mm mn mo mp mq hn fo ch"><span id="db88" class="oe my ea ap of b ed og oh l oi" data-selectable-paragraph="">from sklearn.ensemble import RandomForestRegressor</span><span id="4adc" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">rf = RandomForestRegressor(random_state = 42)</span><span id="6dd4" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">from pprint import pprint</span><span id="8517" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""># Look at parameters used by our current forest<br>print('Parameters currently in use:\n')<br>pprint(rf.get_params())</span><span id="b8ef" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">Parameters currently in use:<br><br>{'bootstrap': True,<br> 'criterion': 'mse',<br> 'max_depth': None,<br> 'max_features': 'auto',<br> 'max_leaf_nodes': None,<br> 'min_impurity_decrease': 0.0,<br> 'min_impurity_split': None,<br> 'min_samples_leaf': 1,<br> 'min_samples_split': 2,<br> 'min_weight_fraction_leaf': 0.0,<br> 'n_estimators': 10,<br> 'n_jobs': 1,<br> 'oob_score': False,<br> 'random_state': 42,<br> 'verbose': 0,<br> 'warm_start': False}</strong></span></pre><p id="fb34" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">Wow, that is quite an overwhelming list! How do we know where to start? A good place is the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" class="cy bt ma mb mc md" target="_blank">documentation on the random forest in Scikit-Learn</a>. This tells us the most important settings are the number of trees in the forest (n_estimators) and the number of features considered for splitting at each leaf node (max_features). We could go read the <a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf" class="cy bt ma mb mc md" target="_blank">research papers on the random forest </a>and try to theorize the best hyperparameters, but a more efficient use of our time is just to try out a wide range of values and see what works! We will try adjusting the following set of hyperparameters:</p><ul class=""><li id="800d" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly nw nx ny" data-selectable-paragraph="">n_estimators = number of trees in the foreset</li><li id="fecf" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">max_features = max number of features considered for splitting a node</li><li id="1cdc" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">max_depth = max number of levels in each decision tree</li><li id="c398" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">min_samples_split = min number of data points placed in a node before the node is split</li><li id="50bb" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">min_samples_leaf = min number of data points allowed in a leaf node</li><li id="7fed" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">bootstrap = method for sampling data points (with or without replacement)</li></ul><h2 id="3f48" class="oe my ea ap ao dy oo op oq or os ot ou ov ow ox oy" data-selectable-paragraph="">Random Hyperparameter Grid</h2><p id="397d" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">To use RandomizedSearchCV, we first need to create a parameter grid to sample from during fitting:</p><pre class="mm mn mo mp mq hn fo ch"><span id="5166" class="oe my ea ap of b ed og oh l oi" data-selectable-paragraph="">from sklearn.model_selection import RandomizedSearchCV</span><span id="eb53" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""># Number of trees in random forest<br>n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]<br># Number of features to consider at every split<br>max_features = ['auto', 'sqrt']<br># Maximum number of levels in tree<br>max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]<br>max_depth.append(None)<br># Minimum number of samples required to split a node<br>min_samples_split = [2, 5, 10]<br># Minimum number of samples required at each leaf node<br>min_samples_leaf = [1, 2, 4]<br># Method of selecting samples for training each tree<br>bootstrap = [True, False]</span><span id="3dbd" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""># Create the random grid<br>random_grid = {'n_estimators': n_estimators,<br>               'max_features': max_features,<br>               'max_depth': max_depth,<br>               'min_samples_split': min_samples_split,<br>               'min_samples_leaf': min_samples_leaf,<br>               'bootstrap': bootstrap}</span><span id="cd54" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">pprint(random_grid)</span><span id="1bc1" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">{'bootstrap': [True, False],<br> 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],<br> 'max_features': ['auto', 'sqrt'],<br> 'min_samples_leaf': [1, 2, 4],<br> 'min_samples_split': [2, 5, 10],<br> 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}</strong></span></pre><p id="2b8e" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">On each iteration, the algorithm will choose a difference combination of the features. Altogether, there are 2 * 12 * 2 * 3 * 3 * 10 = 4320 settings! However, the benefit of a random search is that we are not trying every combination, but selecting at random to sample a wide range of values.</p><h2 id="06b1" class="oe my ea ap ao dy oo op oq or os ot ou ov ow ox oy" data-selectable-paragraph="">Random Search Training</h2><p id="d5b3" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">Now, we instantiate the random search and fit it like any Scikit-Learn model:</p><pre class="mm mn mo mp mq hn fo ch"><span id="d322" class="oe my ea ap of b ed og oh l oi" data-selectable-paragraph=""># Use the random grid to search for best hyperparameters<br># First create the base model to tune<br>rf = RandomForestRegressor()<br># Random search of parameters, using 3 fold cross validation, <br># search across 100 different combinations, and use all available cores<br>rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)</span><span id="02ea" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""># Fit the random search model<br>rf_random.fit(train_features, train_labels)</span></pre><p id="c328" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">The most important arguments in RandomizedSearchCV are n_iter, which controls the number of different combinations to try, and cv which is the number of folds to use for cross validation (we use 100 and 3 respectively). More iterations will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time. Machine learning is a field of trade-offs, and performance vs time is one of the most fundamental.</p><p id="b1fa" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">We can view the best parameters from fitting the random search:</p><pre class="mm mn mo mp mq hn fo ch"><span id="7ac2" class="oe my ea ap of b ed og oh l oi" data-selectable-paragraph="">rf_random.best_params_</span><span id="3c19" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">{'bootstrap': True,<br> 'max_depth': 70,<br> 'max_features': 'auto',<br> 'min_samples_leaf': 4,<br> 'min_samples_split': 10,<br> 'n_estimators': 400}</strong></span></pre><p id="047b" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">From these results, we should be able to narrow the range of values for each hyperparameter.</p><h2 id="6958" class="oe my ea ap ao dy oo op oq or os ot ou ov ow ox oy" data-selectable-paragraph="">Evaluate Random Search</h2><p id="0a6a" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">To determine if random search yielded a better model, we compare the base model with the best random search model.</p><pre class="mm mn mo mp mq hn fo ch"><span id="01c7" class="oe my ea ap of b ed og oh l oi" data-selectable-paragraph="">def evaluate(model, test_features, test_labels):<br>    predictions = model.predict(test_features)<br>    errors = abs(predictions - test_labels)<br>    mape = 100 * np.mean(errors / test_labels)<br>    accuracy = 100 - mape<br>    print('Model Performance')<br>    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))<br>    print('Accuracy = {:0.2f}%.'.format(accuracy))<br>    <br>    return accuracy</span><span id="beee" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)<br>base_model.fit(train_features, train_labels)<br>base_accuracy = evaluate(base_model, test_features, test_labels)</span><span id="9a7f" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">Model Performance<br>Average Error: 3.9199 degrees.<br>Accuracy = 93.36%.</strong></span><span id="b973" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">best_random = rf_random.best_estimator_<br>random_accuracy = evaluate(best_random, test_features, test_labels)</span><span id="6b3a" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">Model Performance<br>Average Error: 3.7152 degrees.<br>Accuracy = 93.73%.</strong></span><span id="59ed" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))</span><span id="a144" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">Improvement of 0.40%.</strong></span></pre><p id="deae" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">We achieved an unspectacular improvement in accuracy of 0.4%. Depending on the application though, this could be a significant benefit. We can further improve our results by using grid search to focus on the most promising hyperparameters ranges found in the random search.</p><h1 id="f5f7" class="mx my ea ap ao dy mz na nb nc nd ne nf ng nh ni nj" data-selectable-paragraph="">Grid Search with Cross Validation</h1><p id="6cb3" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">Random search allowed us to narrow down the range for each hyperparameter. Now that we know where to concentrate our search, we can explicitly specify every combination of settings to try. We do this with GridSearchCV, a method that, instead of sampling randomly from a distribution, evaluates all combinations we define. To use Grid Search, we make another grid based on the best values provided by random search:</p><pre class="mm mn mo mp mq hn fo ch"><span id="3178" class="oe my ea ap of b ed og oh l oi" data-selectable-paragraph="">from sklearn.model_selection import GridSearchCV</span><span id="ec31" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""># Create the parameter grid based on the results of random search <br>param_grid = {<br>    'bootstrap': [True],<br>    'max_depth': [80, 90, 100, 110],<br>    'max_features': [2, 3],<br>    'min_samples_leaf': [3, 4, 5],<br>    'min_samples_split': [8, 10, 12],<br>    'n_estimators': [100, 200, 300, 1000]<br>}</span><span id="6423" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""># Create a based model<br>rf = RandomForestRegressor()</span><span id="45fc" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""># Instantiate the grid search model<br>grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, <br>                          cv = 3, n_jobs = -1, verbose = 2)</span></pre><p id="39b2" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">This will try out 1 * 4 * 2 * 3 * 3 * 4 = 288 combinations of settings. We can fit the model, display the best hyperparameters, and evaluate performance:</p><pre class="mm mn mo mp mq hn fo ch"><span id="97d2" class="oe my ea ap of b ed og oh l oi" data-selectable-paragraph=""># Fit the grid search to the data<br>grid_search.fit(train_features, train_labels)</span><span id="1f33" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">grid_search.best_params_</span><span id="4928" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">{'bootstrap': True,<br> 'max_depth': 80,<br> 'max_features': 3,<br> 'min_samples_leaf': 5,<br> 'min_samples_split': 12,<br> 'n_estimators': 100}</strong></span><span id="2b93" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">best_grid = grid_search.best_estimator_<br>grid_accuracy = evaluate(best_grid, test_features, test_labels)</span><span id="4737" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">Model Performance<br>Average Error: 3.6561 degrees.<br>Accuracy = 93.83%.</strong></span><span id="ade6" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph="">print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))</span><span id="c438" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">Improvement of 0.50%.</strong></span></pre><p id="38be" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">It seems we have about maxed out performance, but we can give it one more try with a grid further refined from our previous results. The code is the same as before just with a different grid so I only present the results:</p><pre class="mm mn mo mp mq hn fo ch"><span id="7b53" class="oe my ea ap of b ed og oh l oi" data-selectable-paragraph=""><strong class="of lz">Model Performance<br>Average Error: 3.6602 degrees.<br>Accuracy = 93.82%.</strong></span><span id="795e" class="oe my ea ap of b ed oj ok ol om on oh l oi" data-selectable-paragraph=""><strong class="of lz">Improvement of 0.49%.</strong></span></pre><p id="465b" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">A small decrease in performance indicates we have reached diminishing returns for hyperparameter tuning. We could continue, but the returns would be minimal at best.</p><h1 id="80cf" class="mx my ea ap ao dy mz na nb nc nd ne nf ng nh ni nj" data-selectable-paragraph="">Comparisons</h1><p id="fa47" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">We can make some quick comparisons between the different approaches used to improve performance showing the returns on each. The following table shows the final results from all the improvements we made (including those from the first part):</p><figure class="mm mn mo mp mq fa x y paragraph-image"><div class="x y fh"><div class="jz l eo ka"><div class="oz l"><div class="ph pi go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_vBCSIIIxyTLKzcJMiV5lKg.png" class="go n o gn ab kc kd ke" width="680" height="375"></div><img class="dk jx go n o gn ab gk" width="680" height="375"><noscript><img src="https://miro.medium.com/max/1360/1*vBCSIIIxyTLKzcJMiV5lKg.png" class="go n o gn ab" width="680" height="375"/></noscript></div></div></div><figcaption class="at ed mt mu hp di x y mv mw ao cs" data-selectable-paragraph="">Comparison of All Models</figcaption></figure><p id="b230" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">Model is the (very unimaginative) names for the models, accuracy is the percentage accuracy, error is the average absolute error in degrees, n_features is the number of features in the dataset, n_trees is the number of decision trees in the forest, and time is the training and predicting time in seconds.</p><p id="873f" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">The models are as follows:</p><ul class=""><li id="e158" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly nw nx ny" data-selectable-paragraph="">average: original baseline computed by predicting historical average max temperature for each day in test set</li><li id="4f9e" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">one_year: model trained using a single year of data</li><li id="7b96" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">four_years_all: model trained using 4.5 years of data and expanded features (see Part One for details)</li><li id="a791" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">four_years_red: model trained using 4.5 years of data and subset of most important features</li><li id="8275" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">best_random: best model from random search with cross validation</li><li id="0393" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">first_grid: best model from first grid search with cross validation (selected as the final model)</li><li id="1a2f" class="ll lm ea ap ln b lo nz lq oa ls ob lu oc lw od ly nw nx ny" data-selectable-paragraph="">second_grid: best model from second grid search</li></ul><p id="cc37" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph=""><strong class="ln lz">Overall, gathering more data and feature selection reduced the error by 17.69% while hyperparameter further reduced the error by 6.73%.</strong></p><figure class="mm mn mo mp mq fa x y paragraph-image"><div class="x y pa"><div class="jz l eo ka"><div class="pb l"><div class="ph pi go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_6gpuSFyshQ-shuvnOjYeGg.png" class="go n o gn ab kc kd ke" width="686" height="475"></div><img class="dk jx go n o gn ab gk" width="686" height="475"><noscript><img src="https://miro.medium.com/max/1372/1*6gpuSFyshQ-shuvnOjYeGg.png" class="go n o gn ab" width="686" height="475"/></noscript></div></div></div><figcaption class="at ed mt mu hp di x y mv mw ao cs" data-selectable-paragraph="">Model Comparison (see Notebook for code)</figcaption></figure><p id="97ab" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">In terms of programmer-hours, gathering data took about 6 hours while hyperparameter tuning took about 3 hours. As with any pursuit in life, there is a point at which pursuing further optimization is not worth the effort and knowing when to stop can be just as important as being able to keep going (sorry for getting all philosophical). Moreover, in any data problem, there is what is called the <a href="https://en.wikipedia.org/wiki/Bayes_error_rate" class="cy bt ma mb mc md" target="_blank">Bayes error rate</a>, which is the absolute minimum possible error in a problem. Bayes error, also called reproducible error, is a combination of latent variables, the factors affecting a problem which we cannot measure, and inherent noise in any physical process. Creating a perfect model is therefore not possible. Nonetheless, in this example, we were able to significantly improve our model with hyperparameter tuning and we covered numerous machine learning topics which are broadly applicable.</p><h1 id="f4be" class="mx my ea ap ao dy mz na nb nc nd ne nf ng nh ni nj" data-selectable-paragraph=""><strong class="bb">Training Visualizations</strong></h1><p id="ddb4" class="ll lm ea ap ln b lo nk lq nl ls nm lu nn lw no ly" data-selectable-paragraph="">To further analyze the process of hyperparameter optimization, we can change one setting at a time and see the effect on the model performance (essentially conducting a controlled experiment). For example, we can create a grid with a range of number of trees, perform grid search CV, and then plot the results. Plotting the training and testing error and the training time will allow us to inspect how changing one hyperparameter impacts the model.</p><p id="74fd" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">First we can look at the effect of changing the number of trees in the forest. (see notebook for training and plotting code)</p><figure class="mm mn mo mp mq fa x y paragraph-image"><div class="x y pc"><div class="jz l eo ka"><div class="pd l"><div class="ph pi go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_mDQtEHIojnUuqiNJc0Na7w.png" class="go n o gn ab kc kd ke" width="633" height="334"></div><img class="dk jx go n o gn ab gk" width="633" height="334"><noscript><img src="https://miro.medium.com/max/1266/1*mDQtEHIojnUuqiNJc0Na7w.png" class="go n o gn ab" width="633" height="334"/></noscript></div></div></div><figcaption class="at ed mt mu hp di x y mv mw ao cs" data-selectable-paragraph="">Number of Trees Training Curves</figcaption></figure><p id="2b9e" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">As the number of trees increases, our error decreases up to a point. There is not much benefit in accuracy to increasing the number of trees beyond 20 (our final model had 100) and the training time rises consistently.</p><p id="310b" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">We can also examine curves for the number of features to split a node:</p><figure class="mm mn mo mp mq fa x y paragraph-image"><div class="x y pe"><div class="jz l eo ka"><div class="pf l"><div class="ph pi go n o gn ab by t jy"><img src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_ZDd5Bs7ed5bZEL93xDwflA.png" class="go n o gn ab kc kd ke" width="645" height="334"></div><img class="dk jx go n o gn ab gk" width="645" height="334"><noscript><img src="https://miro.medium.com/max/1290/1*ZDd5Bs7ed5bZEL93xDwflA.png" class="go n o gn ab" width="645" height="334"/></noscript></div></div></div><figcaption class="at ed mt mu hp di x y mv mw ao cs" data-selectable-paragraph="">Number of Features Training Curves</figcaption></figure><p id="d33f" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">As we increase the number of features retained, the model accuracy increases as expected. The training time also increases although not significantly.</p><p id="f7ef" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">Together with the quantitative stats, these visuals can give us a good idea of the trade-offs we make with different combinations of hyperparameters. Although there is usually no way to know ahead of time what settings will work the best, this example has demonstrated the simple tools in Python that allow us to optimize our machine learning model.</p><p id="6513" class="ll lm ea ap ln b lo lp lq lr ls lt lu lv lw lx ly" data-selectable-paragraph="">As always, I welcome feedback and constructive criticism. I can be reached at wjk68@case.edu</p></div></section></div></article><div class="ph ta dm m dn do dp dq dr e" data-test-id="post-sidebar"><div class="af dj"><div class="ds dt l"><a href="https://towardsdatascience.com/?source=post_sidebar--------------------------post_sidebar-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><h2 class="ao dy dz aq ea">Towards Data Science</h2></a><div class="eb ec l"><h4 class="ao cs ed aq by ee ef eg eh ei at">Sharing concepts, ideas, and codes.</h4></div><div class="bs"><button class="ej bm av aw bn bf bg bo be bp ao b ap aq ar as bq br ae bs bt bh">Follow</button></div></div><div class="ek el em af"><div class="af ag"><div class="en l eo"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_sidebar-----28d2aa77dd74---------------------clap_sidebar-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><div class="bc ep eq er es et eu ev aw ew bg"><svg width="29" height="29"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></div><div class="ex l"><div class="ey"><h4 class="ao cs ed aq at"><button class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx">3.3K </button></h4></div></div></div></div><div><div class="bs"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_sidebar--------------------------bookmark_sidebar-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div></div><div><div class="ez fa af dj fb"><div class="af fb"><div class="fc fd fe ff fg fh ab"><div class="af fi"></div><div class="af ag fi"></div><div class="fj l"><ul class="bc bd"><li class="bs ce fk fl"><a href="https://towardsdatascience.com/tag/machine-learning" class="fm fn bt at l fo fp a b ct">Machine Learning</a></li><li class="bs ce fk fl"><a href="https://towardsdatascience.com/tag/python" class="fm fn bt at l fo fp a b ct">Python</a></li><li class="bs ce fk fl"><a href="https://towardsdatascience.com/tag/data-science" class="fm fn bt at l fo fp a b ct">Data Science</a></li><li class="bs ce fk fl"><a href="https://towardsdatascience.com/tag/data" class="fm fn bt at l fo fp a b ct">Data</a></li></ul></div><div class="fq af fr u"><div class="af ag"><div class="fs l eo"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_actions_footer-----28d2aa77dd74---------------------clap_footer-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><div class="c ft fu af ag fv eo fw fx bo fy fz ga gb gc gd ge gf gg gh gi"><div class="bc ep eq er es et gj ev ag gk fu af fb gl gm o gn go n ab aw ew bg"><svg width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></div></div></a></div><div class="ex l"><div class="ey"><h4 class="ao cs ed aq ea"><button class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx">3.3K claps</button></h4></div></div></div><div class="af ag"><div class="gp l am g"><a href="https://medium.com/p/28d2aa77dd74/share/twitter?source=follow_footer--------------------------follow_footer-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="29" height="29" class="al"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></a></div><div class="gp l am g"><a href="https://medium.com/p/28d2aa77dd74/share/facebook?source=follow_footer--------------------------follow_footer-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="29" height="29" class="al"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></a></div><div class="gp gq bw"><div class="bs"><button class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="25" height="25" class="al"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div><div class="gp l am"><div><div class="bs"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_actions_footer--------------------------bookmark_sidebar-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div><div class="bs"><div class="bs"><div class="l am"><button class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="al"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div></div><div class="gr gs gt fj l u"><div class="gu gv l eo"><span class="l gw ai gx"><div class="l go gy gz"><a href="https://towardsdatascience.com/@williamkoehrsen?source=follow_footer--------------------------follow_footer-"><img alt="Will Koehrsen" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_SckxdIFfjlR-cWXkL5ya-g(1).jpeg" class="l fu cl ha" width="80" height="80"></a></div><span class="l"><div class="hb l hc"><p class="ao cs ct aq at cw hd">Written by</p></div><div class="hb he af hc"><div class="ab af ag fr"><h2 class="ao dy hf hg ea"><a href="https://towardsdatascience.com/@williamkoehrsen?source=follow_footer--------------------------follow_footer-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx">Will Koehrsen</a></h2><div class="l g"><button class="ej bm av aw bn bf bg bo be bp ao b ap aq ar as bq br ae bs bt bh">Follow</button></div></div></div></span></span><div class="hb hh l hc bw"><div class="hi l"><h4 class="ao cs dz hj at">Data Scientist at Cortex Intel, Data Science Communicator</h4></div><div class="gq hk bw"><button class="ej bm av aw bn bf bg bo be bp ao b ap aq ar as bq br ae bs bt bh">Follow</button></div></div></div><div class="gr l"></div><div class="gu gv l eo"><span class="l gw ai gx"><div class="l go gy gz"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-"><img alt="Towards Data Science" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="bp ha cl" width="80" height="80"></a></div><span class="l"><div class="hb he af hc"><div class="ab af ag fr"><h2 class="ao dy hf hg ea"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx">Towards Data Science</a></h2><div class="l g"><div class="bs"><button class="ej bm av aw bn bf bg bo be bp ao b ap aq ar as bq br ae bs bt bh">Follow</button></div></div></div></div></span></span><div class="hb hl l hc bw"><div class="hi l"><h4 class="ao cs dz hj at">Sharing concepts, ideas, and codes.</h4></div><div class="gq hk bw"><div class="bs"><button class="ej bm av aw bn bf bg bo be bp ao b ap aq ar as bq br ae bs bt bh">Follow</button></div></div></div></div></div><div class="hm gs l u"><a href="https://medium.com/p/28d2aa77dd74/responses/show?source=follow_footer--------------------------follow_footer-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><div class="hn ho fm l hp bw"><span class="av">See responses (26)</span></div></a></div></div></div><div class="hq l hr u"><div class="af fb"><div class="fc fd fe ff fg hs ab"><div class="pp l pq"><div class="jd dt gu l"><h2 class="ao dy pr ps ea">More From Medium</h2></div><div class="ci af pt fi pu pv pw px py pz qa qb qc qd qe qf qg qh qi"><div class="qj qk ql mf qm qn qo mh qp qq qr mj qs qt qu qv qw qx qy qz ra"><div class="ab gn"><div class="l rb"><div class="rc rd pu pv pw re rf px py pz rg rh qa qb qc ri rj qd qe qf rk rl qg qh qi af fi"><div class="qj qk ql mf qm qn rm rn qp qq ro rp qs qt rq rr qw qx rs rt ra"><div class="ru l rv f"><h4 class="ao cs ed aq at">More from Towards Data Science</h4></div><div class="rw l rx pq"><a class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx l" href="https://towardsdatascience.com/5-bad-habits-of-absolutely-ineffective-programmers-e74b74add9ca?source=post_recirc---------0------------------"><div class="ry eo"><div class="gn go ab"><div class="rz l sa sb gn ab sc pn"></div></div></div></a></div></div><div class="qj qk ql mf qm qn rm rn qp qq ro rp qs qt rq rr qw qx rs rt ra"><div class="rw l"><div class="sd gq h se"><h4 class="ao cs ed aq at">More from Towards Data Science</h4></div><a href="https://towardsdatascience.com/5-bad-habits-of-absolutely-ineffective-programmers-e74b74add9ca?source=post_recirc---------0------------------"><h3 class="ea al kh sf ap sg sh si">5 Bad Habits of Absolutely Ineffective Programmers.</h3></a></div><div class="af ag fr"><div class="sj l cd"><div class="ag af"><div><a href="https://towardsdatascience.com/@rsrajan1?source=post_recirc---------0------------------"><div class="eo sk sl"><svg width="46" height="50" viewBox="0 0 46 50" class="sm go sn so sp sq dl"><path d="M1.45 15.22C5.43 7.07 13.59 1.5 23 1.5v-1C13.18.5 4.69 6.32.55 14.78l.9.44zM23 1.5c9.4 0 17.57 5.57 21.55 13.72l.9-.44C41.3 6.32 32.82.5 23 .5v1zm21.55 33.28C40.57 42.93 32.41 48.5 23 48.5v1c9.82 0 18.31-5.82 22.45-14.28l-.9-.44zM23 48.5c-9.4 0-17.57-5.57-21.55-13.72l-.9.44C4.7 43.68 13.18 49.5 23 49.5v-1z"></path></svg><img alt="Ravi Shankar Rajan" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_bp7umkeEtcAD6ysmZkxr0w.jpeg" class="l fu sl sk" width="40" height="40"></div></a></div><div class="kt ab l"><div class="af"><div style="flex: 1 1 0%;"><span class="ao b ap aq ar as l ea al"><div class="de af ag kv"><span class="ao cs ed aq by kw ef eg kx ei ea"><a href="https://towardsdatascience.com/@rsrajan1?source=post_recirc---------0------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx">Ravi Shankar Rajan</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------0------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx">Towards Data Science</a></span></span></div></span></div></div><span class="ao b ap aq ar as l at au"><span class="ao cs ed aq by kw ef eg kx ei at"><div><a class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx" href="https://towardsdatascience.com/5-bad-habits-of-absolutely-ineffective-programmers-e74b74add9ca?source=post_recirc---------0------------------">Aug 7</a> · 5 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="af ag"><div class="af ag"><div class="en l eo"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_recirc-----e74b74add9ca----0-----------------clap_preview-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><div class="bc ep eq er es et eu pg sr ss st"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></div><div class="ex l"><div class="ey"><h4 class="ao cs ed aq at">5.5K </h4></div></div></div><div class="su kt sj cm sv l"></div><div><div class="bs"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_recirc---------0-----------------bookmark_sidebar-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div></div></div></div></div></div></div><div class="qj qk ql mf qm qn qo mh qp qq qr mj qs qt qu qv qw qx qy qz ra"><div class="ab gn"><div class="l rb"><div class="rc rd pu pv pw re rf px py pz rg rh qa qb qc ri rj qd qe qf rk rl qg qh qi af fi"><div class="qj qk ql mf qm qn rm rn qp qq ro rp qs qt rq rr qw qx rs rt ra"><div class="ru l rv f"><h4 class="ao cs ed aq at">More from Towards Data Science</h4></div><div class="rw l rx pq"><a class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx l" href="https://towardsdatascience.com/6-techniques-which-help-me-study-machine-learning-five-days-per-week-fb3e889fad80?source=post_recirc---------1------------------"><div class="ry eo"><div class="gn go ab"><div class="sw l sa sb gn ab sc pn"></div></div></div></a></div></div><div class="qj qk ql mf qm qn rm rn qp qq ro rp qs qt rq rr qw qx rs rt ra"><div class="rw l"><div class="sd gq h se"><h4 class="ao cs ed aq at">More from Towards Data Science</h4></div><a href="https://towardsdatascience.com/6-techniques-which-help-me-study-machine-learning-five-days-per-week-fb3e889fad80?source=post_recirc---------1------------------"><h3 class="ea al kh sf ap sg sh si">6 Techniques Which Help Me Study Machine Learning Five Days Per Week</h3></a></div><div class="af ag fr"><div class="sj l cd"><div class="ag af"><div><a href="https://towardsdatascience.com/@mrdbourke?source=post_recirc---------1------------------"><div class="eo sk sl"><svg width="46" height="50" viewBox="0 0 46 50" class="sm go sn so sp sq dl"><path d="M1.45 15.22C5.43 7.07 13.59 1.5 23 1.5v-1C13.18.5 4.69 6.32.55 14.78l.9.44zM23 1.5c9.4 0 17.57 5.57 21.55 13.72l.9-.44C41.3 6.32 32.82.5 23 .5v1zm21.55 33.28C40.57 42.93 32.41 48.5 23 48.5v1c9.82 0 18.31-5.82 22.45-14.28l-.9-.44zM23 48.5c-9.4 0-17.57-5.57-21.55-13.72l-.9.44C4.7 43.68 13.18 49.5 23 49.5v-1z"></path></svg><img alt="Daniel Bourke" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_Rmq5dGAMlFDSSm6ZuZE9sg.png" class="l fu sl sk" width="40" height="40"></div></a></div><div class="kt ab l"><div class="af"><div style="flex: 1 1 0%;"><span class="ao b ap aq ar as l ea al"><div class="de af ag kv"><span class="ao cs ed aq by kw ef eg kx ei ea"><a href="https://towardsdatascience.com/@mrdbourke?source=post_recirc---------1------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx">Daniel Bourke</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------1------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx">Towards Data Science</a></span></span></div></span></div></div><span class="ao b ap aq ar as l at au"><span class="ao cs ed aq by kw ef eg kx ei at"><div><a class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx" href="https://towardsdatascience.com/6-techniques-which-help-me-study-machine-learning-five-days-per-week-fb3e889fad80?source=post_recirc---------1------------------">Aug 3</a> · 8 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="af ag"><div class="af ag"><div class="en l eo"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_recirc-----fb3e889fad80----1-----------------clap_preview-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><div class="bc ep eq er es et eu pg sr ss st"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></div><div class="ex l"><div class="ey"><h4 class="ao cs ed aq at">9.3K </h4></div></div></div><div class="su kt sj cm sv l"></div><div><div class="bs"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_recirc---------1-----------------bookmark_sidebar-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div></div></div></div></div></div></div><div class="qj qk ql mf qm qn qo mh qp qq qr mj qs qt qu qv qw qx qy qz ra"><div class="ab gn"><div class="l rb"><div class="rc rd pu pv pw re rf px py pz rg rh qa qb qc ri rj qd qe qf rk rl qg qh qi af fi"><div class="qj qk ql mf qm qn rm rn qp qq ro rp qs qt rq rr qw qx rs rt ra"><div class="ru l rv f"><h4 class="ao cs ed aq at">More from Towards Data Science</h4></div><div class="rw l rx pq"><a class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx l" href="https://towardsdatascience.com/3-strategies-to-guarantee-a-data-science-job-with-no-experience-68d85b345f21?source=post_recirc---------2------------------"><div class="ry eo"><div class="gn go ab"><div class="sx l sa sb gn ab sc pn"></div></div></div></a></div></div><div class="qj qk ql mf qm qn rm rn qp qq ro rp qs qt rq rr qw qx rs rt ra"><div class="rw l"><div class="sd gq h se"><h4 class="ao cs ed aq at">More from Towards Data Science</h4></div><a href="https://towardsdatascience.com/3-strategies-to-guarantee-a-data-science-job-with-no-experience-68d85b345f21?source=post_recirc---------2------------------"><h3 class="ea al kh sf ap sg sh si">3 Strategies to Guarantee a Data Science Job with No Experience</h3></a></div><div class="af ag fr"><div class="sj l cd"><div class="ag af"><div><a href="https://towardsdatascience.com/@haebichan?source=post_recirc---------2------------------"><div class="eo sk sl"><svg width="46" height="50" viewBox="0 0 46 50" class="sm go sn so sp sq dl"><path d="M1.45 15.22C5.43 7.07 13.59 1.5 23 1.5v-1C13.18.5 4.69 6.32.55 14.78l.9.44zM23 1.5c9.4 0 17.57 5.57 21.55 13.72l.9-.44C41.3 6.32 32.82.5 23 .5v1zm21.55 33.28C40.57 42.93 32.41 48.5 23 48.5v1c9.82 0 18.31-5.82 22.45-14.28l-.9-.44zM23 48.5c-9.4 0-17.57-5.57-21.55-13.72l-.9.44C4.7 43.68 13.18 49.5 23 49.5v-1z"></path></svg><img alt="Haebichan Jung" src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/1_9k1IxUME-gk9_t_0-NmzxA.jpeg" class="l fu sl sk" width="40" height="40"></div></a></div><div class="kt ab l"><div class="af"><div style="flex: 1 1 0%;"><span class="ao b ap aq ar as l ea al"><div class="de af ag kv"><span class="ao cs ed aq by kw ef eg kx ei ea"><a href="https://towardsdatascience.com/@haebichan?source=post_recirc---------2------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx">Haebichan Jung</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------2------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx">Towards Data Science</a></span></span></div></span></div></div><span class="ao b ap aq ar as l at au"><span class="ao cs ed aq by kw ef eg kx ei at"><div><a class="cy cz ax ay az ba bb bc bd be jh bh bi dw dx" href="https://towardsdatascience.com/3-strategies-to-guarantee-a-data-science-job-with-no-experience-68d85b345f21?source=post_recirc---------2------------------">Aug 16</a> · 12 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="af ag"><div class="af ag"><div class="en l eo"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_recirc-----68d85b345f21----2-----------------clap_preview-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><div class="bc ep eq er es et eu pg sr ss st"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></div><div class="ex l"><div class="ey"><h4 class="ao cs ed aq at">371 </h4></div></div></div><div class="su kt sj cm sv l"></div><div><div class="bs"><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74&amp;source=post_recirc---------2-----------------bookmark_sidebar-" class="cy cz ax ay az ba bb bc bd be du dv bh bi dw dx"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="ht l hu hv"><section class="x y ab ae l hw hx hy hz ia ib ic id ie if ig ih ii ij ik"><div class="il im gu af fr g"><div class="in af fr"><div class="io l ip"><div class="iq l"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be ir is bh bi it iu"><h4 class="iv iw ix ao dy ap hj iy iz l">Discover <!-- -->Medium</h4></a></div><span class="ao b ap aq ar as l ja jb">Welcome to a place where words matter. On <!-- -->Medium<!-- -->, smart voices and original ideas take center stage - with no ads in sight.<!-- --> <a href="https://medium.com/about?autoplay=1&amp;source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be bh bi it iu jc">Watch</a></span></div><div class="io l ip"><div class="jd l"><a href="https://medium.com/topics?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be ir is bh bi it iu"><h4 class="iv iw ix ao dy ap hj iy iz l">Make <!-- -->Medium<!-- --> yours</h4></a></div><span class="ao b ap aq ar as l ja jb">Follow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox.<!-- --> <a href="https://medium.com/topics?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be bh bi it iu jc">Explore</a></span></div><div class="io l ip"><div class="iq l"><a href="https://medium.com/membership?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be ir is bh bi it iu"><h4 class="iv iw ix ao dy ap hj iy iz l">Become a member</h4></a></div><span class="ao b ap aq ar as l ja jb">Get unlimited access to the best stories on <!-- -->Medium<!-- --> — and support writers while you’re at it. Just $5/month.<!-- --> <a href="https://medium.com/membership?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be bh bi it iu jc">Upgrade</a></span></div></div></div><div class="af ag fr"><a href="https://medium.com/?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be ir is bh bi it iu"><svg height="22" width="112" viewBox="0 0 111.5 22" class="iw"><path d="M56.3 19.5c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5V19c-.7 1.8-2.4 3-4.3 3-3.3 0-5.8-2.6-5.8-7.5 0-4.5 2.6-7.6 6.3-7.6 1.6-.1 3.1.8 3.8 2.4V3.2c0-.3-.1-.6-.3-.7l-1.4-1.4V1l6.5-.8v19.3zm-4.8-.8V9.5c-.5-.6-1.2-.9-1.9-.9-1.6 0-3.1 1.4-3.1 5.7 0 4 1.3 5.4 3 5.4.8.1 1.6-.3 2-1zm9.1 3.1V9.4c0-.3-.1-.6-.3-.7l-1.4-1.5v-.1h6.5v12.5c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5zm-.2-19.2C60.4 1.2 61.5 0 63 0c1.4 0 2.6 1.2 2.6 2.6S64.4 5.3 63 5.3a2.6 2.6 0 0 1-2.6-2.7zm22.5 16.9c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5v-3.2c-.6 2-2.4 3.4-4.5 3.4-2.9 0-4.4-2.1-4.4-6.2 0-1.9 0-4.1.1-6.5 0-.3-.1-.5-.3-.7L67.7 7v.1H74v8c0 2.6.4 4.4 2 4.4.9-.1 1.7-.6 2.1-1.3V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v12.4zm22 2.3c0-.5.1-6.5.1-7.9 0-2.6-.4-4.5-2.2-4.5-.9 0-1.8.5-2.3 1.3.2.8.3 1.7.3 2.5 0 1.8-.1 4.2-.1 6.5 0 .3.1.5.3.7l1.5 1.4v.1H96c0-.4.1-6.5.1-7.9 0-2.7-.4-4.5-2.2-4.5-.9 0-1.7.5-2.2 1.3v9c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v3.1a4.6 4.6 0 0 1 4.6-3.4c2.2 0 3.6 1.2 4.2 3.5.7-2.1 2.7-3.6 4.9-3.5 2.9 0 4.5 2.2 4.5 6.2 0 1.9-.1 4.2-.1 6.5-.1.3.1.6.3.7l1.4 1.4v.1h-6.6zm-81.4-2l1.9 1.9v.1h-9.8v-.1l2-1.9c.2-.2.3-.4.3-.7V7.3c0-.5 0-1.2.1-1.8L11.4 22h-.1L4.5 6.8c-.1-.4-.2-.4-.3-.6v10c-.1.7 0 1.3.3 1.9l2.7 3.6v.1H0v-.1L2.7 18c.3-.6.4-1.3.3-1.9v-11c0-.5-.1-1.1-.5-1.5L.7 1.1V1h7l5.8 12.9L18.6 1h6.8v.1l-1.9 2.2c-.2.2-.3.5-.3.7v15.2c0 .2.1.5.3.6zm7.6-5.9c0 3.8 1.9 5.3 4.2 5.3 1.9.1 3.6-1 4.4-2.7h.1c-.8 3.7-3.1 5.5-6.5 5.5-3.7 0-7.2-2.2-7.2-7.4 0-5.5 3.5-7.6 7.3-7.6 3.1 0 6.4 1.5 6.4 6.2v.8h-8.7zm0-.8h4.3v-.8c0-3.9-.8-4.9-2-4.9-1.4.1-2.3 1.6-2.3 5.7z"></path></svg></a><span class="ao b ap aq ar as l ja jb"><div class="je jf af fr jg ai"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi it iu">About</a><a href="https://help.medium.com/?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi it iu">Help</a><a href="https://medium.com/policy/9db0094a1e0f?source=post_page-----28d2aa77dd74----------------------" class="cy cz ax ay az ba bb bc bd be jh bh bi it iu">Legal</a></div></span></div></section></div></div></div><script>window.__BUILD_ID__ = "development"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"config":{"nodeEnv":"production","version":"master-20190820-220006-2d0998cf1c","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","iTunesAppId":"828256236","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"collector-medium.lightstep.com","token":"ce5be895bef60919541332990ac9fef2","appVersion":"master-20190820-220006-2d0998cf1c"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","sentry":{"dsn":"https:\u002F\u002F589e367c28ca47b195ce200d1507d18b@sentry.io\u002F1423575","environment":"production"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"]},"debug":{"requestId":"190c5279-7b23-42d2-bc73-a43f8fb503c1","originalSpanCarrier":{"ot-tracer-spanid":"5bbeca923df12145","ot-tracer-traceid":"618cdddd4b3083f8","ot-tracer-sampled":"true"}},"session":{"user":{"id":"lo_dnt_b0oJcgW3ziXr"},"xsrf":""},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"showBranchBanner":null,"hideGoogleOneTap":false,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47","currentHash":""},"client":{"isBot":false,"isDnt":true,"isEu":false,"isNativeMedium":false,"isCustomDomain":true},"multiVote":{"clapsPerPost":{}},"metadata":{"faviconImageId":null}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY.variantFlags.0":{"name":"allow_access","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.0.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.0.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.1":{"name":"allow_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.1.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.1.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.2":{"name":"allow_test_auth","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.2.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.2.valueType":{"__typename":"VariantFlagString","value":"disallow"},"ROOT_QUERY.variantFlags.3":{"name":"available_annual_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.3.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.3.valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"},"ROOT_QUERY.variantFlags.4":{"name":"available_monthly_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.4.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.4.valueType":{"__typename":"VariantFlagString","value":"60e220181034"},"ROOT_QUERY.variantFlags.5":{"name":"browsable_stream_config_bucket","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.5.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.5.valueType":{"__typename":"VariantFlagString","value":"curated-topics"},"ROOT_QUERY.variantFlags.6":{"name":"disable_gosocial_followers_that_you_follow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.6.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.6.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.7":{"name":"disable_ios_resume_reading_toast","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.7.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.7.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.8":{"name":"disable_mobile_featured_chunk","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.8.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.8.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.9":{"name":"enable_annual_renewal_reminder_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.9.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.9.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.10":{"name":"enable_automated_mission_control_triggers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.10.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.10.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.11":{"name":"enable_branch_io","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.11.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.11.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.12":{"name":"enable_branding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.12.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.12.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.13":{"name":"enable_branding_fonts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.13.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.13.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.14":{"name":"enable_daily_read_digest_promo","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.14.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.14.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.15":{"name":"enable_dedicated_series_tab_api_ios","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.15.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.15.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.16":{"name":"enable_disregard_trunc_state_for_footer","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.16.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.16.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.17":{"name":"enable_edit_alt_text","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.17.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.17.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.18":{"name":"enable_embedding_based_diversification","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.18.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.18.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.19":{"name":"enable_google_one_tap","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.19.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.19.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.20":{"name":"enable_inline_search_lite","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.20.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.20.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.21":{"name":"enable_ios_post_stats","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.21.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.21.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.22":{"name":"enable_janky_spam_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.22.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.22.valueType":{"__typename":"VariantFlagString","value":"users,posts"},"ROOT_QUERY.variantFlags.23":{"name":"enable_lite_notifications","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.23.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.23.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.24":{"name":"enable_lite_post","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.24.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.24.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.25":{"name":"enable_lite_post_cd","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.25.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.25.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.26":{"name":"enable_lite_post_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.26.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.26.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.27":{"name":"enable_lite_post_highlights_view_only","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.27.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.27.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.28":{"name":"enable_lite_profile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.28.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.28.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.29":{"name":"enable_lite_pub_header_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.29.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.29.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.30":{"name":"enable_lite_stories","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.30.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.30.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.31":{"name":"enable_lite_thanks_to","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.31.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.31.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.32":{"name":"enable_lite_topics","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.32.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.32.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.33":{"name":"enable_lite_twitter_text_shots","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.33.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.33.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.34":{"name":"enable_lite_unread_notification_count_mutation","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.34.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.34.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.35":{"name":"enable_live_user_post_scoring","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.35.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.35.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.36":{"name":"enable_logged_out_homepage_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.36.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.36.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.37":{"name":"enable_marketing_emails","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.37.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.37.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.38":{"name":"enable_media_resource_try_catch","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.38.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.38.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.39":{"name":"enable_more_branch_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.39.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.39.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.40":{"name":"enable_new_collaborative_filtering_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.40.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.40.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.41":{"name":"enable_parsely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.41.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.41.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.42":{"name":"enable_patronus_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.42.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.42.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.43":{"name":"enable_post_import","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.43.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.43.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.44":{"name":"enable_primary_topic_for_mobile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.44.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.44.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.45":{"name":"enable_quarantine_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.45.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.45.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.46":{"name":"enable_rank_service_newsletters","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.46.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.46.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.47":{"name":"enable_serve_recs_from_ml_rank_app_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.47.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.47.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.48":{"name":"enable_serve_recs_from_ml_rank_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.48.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.48.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.49":{"name":"enable_serve_recs_from_ml_rank_homepage","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.49.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.49.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.50":{"name":"enable_tick_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.50.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.50.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.51":{"name":"enable_ticks_digest_promo","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.51.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.51.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.52":{"name":"enable_tipalti_onboarding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.52.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.52.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.53":{"name":"enable_trumpland_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.53.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.53.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.54":{"name":"glyph_font_set","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.54.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.54.valueType":{"__typename":"VariantFlagString","value":"m2"},"ROOT_QUERY.variantFlags.55":{"name":"google_sign_in_android","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.55.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.55.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.56":{"name":"is_not_medium_subscriber","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.56.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.56.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.57":{"name":"pub_sidebar","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.57.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.57.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.58":{"name":"rank_model","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.58.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.58.valueType":{"__typename":"VariantFlagString","value":"default"},"ROOT_QUERY.variantFlags.59":{"name":"redis_read_write_splitting","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.59.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.59.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.60":{"name":"remove_social_proof_on_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.60.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.60.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.61":{"name":"signin_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.61.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.61.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap"},"ROOT_QUERY.variantFlags.62":{"name":"signup_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.62.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.62.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap"},"ROOT_QUERY.variantFlags.63":{"name":"use_new_admin_topic_backend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.63.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.63.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY":{"variantFlags":[{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.0","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.1","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.2","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.3","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.4","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.5","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.6","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.7","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.8","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.9","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.10","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.11","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.12","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.13","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.14","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.15","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.16","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.17","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.18","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.19","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.20","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.21","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.22","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.23","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.24","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.25","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.26","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.27","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.28","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.29","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.30","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.31","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.32","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.33","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.34","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.35","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.36","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.37","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.38","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.39","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.40","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.41","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.42","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.43","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.44","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.45","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.46","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.47","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.48","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.49","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.50","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.51","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.52","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.53","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.54","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.55","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.56","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.57","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.58","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.59","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.60","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.61","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.62","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.63","typename":"VariantFlag"}],"viewer":null,"meterPost({\"postId\":\"28d2aa77dd74\",\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47\"}})":{"type":"id","generated":false,"id":"MeteringInfo:singleton","typename":"MeteringInfo"},"postResult({\"id\":\"28d2aa77dd74\"})":{"type":"id","generated":false,"id":"Post:28d2aa77dd74","typename":"Post"}},"MeteringInfo:singleton":{"__typename":"MeteringInfo","postIds":{"type":"json","json":[]},"maxUnlockCount":3,"unlocksRemaining":3},"Post:28d2aa77dd74":{"__typename":"Post","visibility":"PUBLIC","latestPublishedVersion":"3fbc2866411c","collection":{"type":"id","generated":false,"id":"Collection:7f60cf5620c9","typename":"Collection"},"id":"28d2aa77dd74","creator":{"type":"id","generated":false,"id":"User:e2f299e30cb9","typename":"User"},"isLocked":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","sequence":null,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fhyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74","canonicalUrl":"","content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47\"}})":{"type":"id","generated":true,"id":"$Post:28d2aa77dd74.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47\"}})","typename":"PostContent"},"firstPublishedAt":1515556131666,"isPublished":true,"layerCake":0,"primaryTopic":null,"title":"Hyperparameter Tuning the Random Forest in Python","pendingCollection":null,"statusForCollection":"APPROVED","readingTime":11.735849056603772,"license":"ALL_RIGHTS_RESERVED","allowResponses":true,"tags":[{"type":"id","generated":false,"id":"Tag:machine-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:python","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:data-science","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:data","typename":"Tag"}],"viewerClapCount":null,"readingList":"READING_LIST_NONE","clapCount":3304,"voterCount":667,"recommenders":[],"responsesCount":26,"collaborators":[],"translationSourcePost":null,"inResponseToPostResult":null,"inResponseToMediaResource":null,"curationEligibleAt":0,"audioVersionUrl":null,"socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1515597298001,"previewContent":{"type":"id","generated":true,"id":"$Post:28d2aa77dd74.previewContent","typename":"PreviewContent"},"previewImage":{"type":"id","generated":false,"id":"ImageMetadata:1*mTBEiGR_W-cYMw8cIWQh0w.jpeg","typename":"ImageMetadata"},"updatedAt":1529309941885,"topics":[{"type":"id","generated":false,"id":"data-science","typename":"Topic"}],"isSuspended":false},"Collection:7f60cf5620c9":{"id":"7f60cf5620c9","domain":"towardsdatascience.com","slug":"towards-data-science","__typename":"Collection","googleAnalyticsId":"UA-19707169-24","colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","name":"Towards Data Science","logo":{"type":"id","generated":false,"id":"ImageMetadata:1*5EUO1kUYBthpOCPzRj_l2g.png","typename":"ImageMetadata"},"avatar":{"type":"id","generated":false,"id":"ImageMetadata:1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","typename":"ImageMetadata"},"isEnrolledInHightower":false,"creator":{"type":"id","generated":false,"id":"User:895063a310f4","typename":"User"},"viewerCanManage":false,"navItems":[{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.0","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.1","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.2","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.3","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.4","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.5","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.6","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.7","typename":"NavItem"}],"colorPalette":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette","typename":"ColorPalette"},"viewerCanEditOwnPosts":false,"viewerCanEditPosts":false,"description":"Sharing concepts, ideas, and codes.","viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"mediumNewsletterId":"","isUserSubscribedToMediumNewsletter":false,"ampEnabled":false,"twitterUsername":"TDataScience","facebookPageId":null,"favicon":{"type":"id","generated":false,"id":"ImageMetadata:1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","typename":"ImageMetadata"}},"User:e2f299e30cb9":{"id":"e2f299e30cb9","__typename":"User","isSuspended":false,"allowNotes":true,"name":"Will Koehrsen","isFollowing":false,"username":"williamkoehrsen","bio":"Data Scientist at Cortex Intel, Data Science Communicator","imageId":"1*SckxdIFfjlR-cWXkL5ya-g.jpeg","mediumMemberAt":0,"isBlocking":false,"isPartnerProgramEnrolled":false,"twitterScreenName":"koehrsen_will"},"ImageMetadata:1*5EUO1kUYBthpOCPzRj_l2g.png":{"id":"1*5EUO1kUYBthpOCPzRj_l2g.png","originalWidth":1010,"originalHeight":376,"__typename":"ImageMetadata"},"ImageMetadata:1*F0LADxTtsKOgmPa-_7iUEQ.jpeg":{"id":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","__typename":"ImageMetadata"},"User:895063a310f4":{"id":"895063a310f4","__typename":"User"},"Collection:7f60cf5620c9.navItems.0":{"title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.1":{"title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.2":{"title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.3":{"title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.4":{"title":"AI","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fartificial-intelligence\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.5":{"title":"Journalism","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-journalism\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.6":{"title":"Events","url":"https:\u002F\u002Ftowardsdatascience.com\u002Ftoronto-machine-learning-summit-8bae371d4bb1","type":"POST_NAV_ITEM","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.7":{"title":"Submit","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome","type":"EXTERNAL_LINK_NAV_ITEM","__typename":"NavItem"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum":{"backgroundColor":"#FF355876","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.0":{"color":"#FF355876","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.1":{"color":"#FF4D6C88","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.2":{"color":"#FF637F99","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.3":{"color":"#FF7791A8","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.4":{"color":"#FF8CA2B7","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.5":{"color":"#FF9FB3C6","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.6":{"color":"#FFB2C3D4","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.7":{"color":"#FFC5D2E1","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.8":{"color":"#FFD7E2EE","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.9":{"color":"#FFE9F1FA","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.10":{"color":"#FFFBFFFF","point":1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette":{"tintBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum","typename":"ColorSpectrum"},"__typename":"ColorPalette","defaultBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum","typename":"ColorSpectrum"},"highlightSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum","typename":"ColorSpectrum"}},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.0":{"color":"#FF668AAA","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.1":{"color":"#FF61809D","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.2":{"color":"#FF5A7690","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.3":{"color":"#FF546C83","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.4":{"color":"#FF4D6275","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.5":{"color":"#FF455768","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.6":{"color":"#FF3D4C5A","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.7":{"color":"#FF34414C","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.8":{"color":"#FF2B353E","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.9":{"color":"#FF21282F","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.10":{"color":"#FF161B1F","point":1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.0":{"color":"#FFEDF4FC","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.1":{"color":"#FFE9F2FD","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.2":{"color":"#FFE6F1FD","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.3":{"color":"#FFE2EFFD","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.4":{"color":"#FFDFEEFD","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.5":{"color":"#FFDBECFE","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.6":{"color":"#FFD7EBFE","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.7":{"color":"#FFD4E9FE","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.8":{"color":"#FFD0E7FF","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.9":{"color":"#FFCCE6FF","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.10":{"color":"#FFC8E4FF","point":1,"__typename":"ColorPoint"},"$Post:28d2aa77dd74.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47\"}})":{"isLockedPreviewOnly":false,"validatedShareKey":"","__typename":"PostContent","bodyModel":{"type":"id","generated":true,"id":"$Post:28d2aa77dd74.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47\"}}).bodyModel","typename":"RichText"}},"$Post:28d2aa77dd74.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47\"}}).bodyModel.sections.0":{"name":"eb16","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:28d2aa77dd74.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47\"}}).bodyModel":{"sections":[{"type":"id","generated":true,"id":"$Post:28d2aa77dd74.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fai100-2.cupoy.com\u002Fmission\u002FD47\"}}).bodyModel.sections.0","typename":"Section"}],"paragraphs":[{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_0","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_1","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_2","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_3","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_4","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_5","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_6","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_7","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_8","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_9","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_10","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_11","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_12","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_13","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_14","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_15","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_16","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_17","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_18","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_19","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_20","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_21","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_22","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_23","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_24","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_25","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_26","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_27","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_28","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_29","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_30","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_31","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_32","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_33","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_34","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_35","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_36","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_37","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_38","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_39","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_40","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_41","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_42","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_43","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_44","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_45","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_46","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_47","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_48","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_49","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_50","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_51","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_52","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_53","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_54","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_55","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_56","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_57","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_58","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_59","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_60","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_61","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_62","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_63","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_64","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_65","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_66","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_67","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_68","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_69","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_70","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_71","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_72","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_73","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_74","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_75","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_76","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_77","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_78","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_79","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_80","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_81","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_82","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_83","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_84","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_85","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_86","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_87","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_88","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_89","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_90","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_91","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_92","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_93","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_94","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_95","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_96","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_97","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_98","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_99","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_100","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_101","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_102","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_103","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_104","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_105","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_106","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_107","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_108","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_109","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:3fbc2866411c_110","typename":"Paragraph"}],"__typename":"RichText"},"Paragraph:3fbc2866411c_0":{"id":"3fbc2866411c_0","name":"8fd6","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*mTBEiGR_W-cYMw8cIWQh0w.jpeg","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*mTBEiGR_W-cYMw8cIWQh0w.jpeg":{"id":"1*mTBEiGR_W-cYMw8cIWQh0w.jpeg","originalHeight":3080,"originalWidth":5472,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_1":{"id":"3fbc2866411c_1","name":"c73f","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"Hyperparameter Tuning the Random Forest in Python","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_2":{"id":"3fbc2866411c_2","name":"7725","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Improving the Random Forest Part Two","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_2.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_2.markups.0":{"type":"STRONG","start":0,"end":36,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_3":{"id":"3fbc2866411c_3","name":"a292","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"So we’ve built a random forest model to solve our machine learning problem (perhaps by following this end-to-end guide) but we’re not too impressed by the results. What are our options? As we saw in the first part of this series, our first step should be to gather more data and perform feature engineering. Gathering more data and feature engineering usually has the greatest payoff in terms of time invested versus improved performance, but when we have exhausted all data sources, it’s time to move on to model hyperparameter tuning. This post will focus on optimizing the random forest model in Python using Scikit-Learn tools. Although this article builds on part one, it fully stands on its own, and we will cover many widely-applicable machine learning concepts.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_3.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_3.markups.1","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_3.markups.0":{"type":"A","start":102,"end":118,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Frandom-forest-in-python-24d0893d51c0","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_3.markups.1":{"type":"A","start":203,"end":228,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fimproving-random-forest-in-python-part-1-893916666cd","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_4":{"id":"3fbc2866411c_4","name":"df58","__typename":"Paragraph","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*G1_rf6QQBIs_vO_d98WfAQ.png","typename":"ImageMetadata"},"text":"One Tree in a Random Forest","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*G1_rf6QQBIs_vO_d98WfAQ.png":{"id":"1*G1_rf6QQBIs_vO_d98WfAQ.png","originalHeight":2023,"originalWidth":11093,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_5":{"id":"3fbc2866411c_5","name":"792b","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"I have included Python code in this article where it is most instructive. Full code and data to follow along can be found on the project Github page.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_5.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_5.markups.0":{"type":"A","start":137,"end":148,"href":"https:\u002F\u002Fgithub.com\u002FWillKoehrsen\u002FMachine-Learning-Projects\u002Ftree\u002Fmaster\u002Frandom_forest_explained","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_6":{"id":"3fbc2866411c_6","name":"0cfc","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"A Brief Explanation of Hyperparameter Tuning","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_7":{"id":"3fbc2866411c_7","name":"f0cc","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"The best way to think about hyperparameters is like the settings of an algorithm that can be adjusted to optimize performance, just as we might turn the knobs of an AM radio to get a clear signal (or your parents might have!). While model parameters are learned during training — such as the slope and intercept in a linear regression — hyperparameters must be set by the data scientist before training. In the case of a random forest, hyperparameters include the number of decision trees in the forest and the number of features considered by each tree when splitting a node. (The parameters of a random forest are the variables and thresholds used to split each node learned during training). Scikit-Learn implements a set of sensible default hyperparameters for all models, but these are not guaranteed to be optimal for a problem. The best hyperparameters are usually impossible to determine ahead of time, and tuning a model is where machine learning turns from a science into trial-and-error based engineering.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_7.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_7.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_7.markups.2","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_7.markups.3","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_7.markups.4","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_7.markups.0":{"type":"A","start":162,"end":195,"href":"https:\u002F\u002Felectronics.howstuffworks.com\u002Fradio8.htm","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_7.markups.1":{"type":"A","start":728,"end":761,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1309.0238","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_7.markups.2":{"type":"EM","start":239,"end":250,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_7.markups.3":{"type":"EM","start":337,"end":352,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_7.markups.4":{"type":"EM","start":393,"end":394,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_8":{"id":"3fbc2866411c_8","name":"a88f","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*0215Gzmw56XvORtB7-Torw.png","typename":"ImageMetadata"},"text":"Hyperparameters and Parameters","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*0215Gzmw56XvORtB7-Torw.png":{"id":"1*0215Gzmw56XvORtB7-Torw.png","originalHeight":400,"originalWidth":425,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_9":{"id":"3fbc2866411c_9","name":"87c2","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Hyperparameter tuning relies more on experimental results than theory, and thus the best method to determine the optimal settings is to try many different combinations evaluate the performance of each model. However, evaluating each model only on the training set can lead to one of the most fundamental problems in machine learning: overfitting.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_9.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_9.markups.0":{"type":"A","start":334,"end":345,"href":"https:\u002F\u002Felitedatascience.com\u002Foverfitting-in-machine-learning","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_10":{"id":"3fbc2866411c_10","name":"04bb","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"If we optimize the model for the training data, then our model will score very well on the training set, but will not be able to generalize to new data, such as in a test set. When a model performs highly on the training set but poorly on the test set, this is known as overfitting, or essentially creating a model that knows the training set very well but cannot be applied to new problems. It’s like a student who has memorized the simple problems in the textbook but has no idea how to apply concepts in the messy real world.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_11":{"id":"3fbc2866411c_11","name":"1a60","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"An overfit model may look impressive on the training set, but will be useless in a real application. Therefore, the standard procedure for hyperparameter optimization accounts for overfitting through cross validation.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_11.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_11.markups.0":{"type":"A","start":200,"end":216,"href":"http:\u002F\u002Fscikit-learn.org\u002Fstable\u002Fmodules\u002Fcross_validation.html","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_12":{"id":"3fbc2866411c_12","name":"5157","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"Cross Validation","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_13":{"id":"3fbc2866411c_13","name":"f5a4","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"The technique of cross validation (CV) is best explained by example using the most common method, K-Fold CV. When we approach a machine learning problem, we make sure to split our data into a training and a testing set. In K-Fold CV, we further split our training set into K number of subsets, called folds. We then iteratively fit the model K times, each time training the data on K-1 of the folds and evaluating on the Kth fold (called the validation data). As an example, consider fitting a model with K = 5. The first iteration we train on the first four folds and evaluate on the fifth. The second time we train on the first, second, third, and fifth fold and evaluate on the fourth. We repeat this procedure 3 more times, each time evaluating on a different fold. At the very end of training, we average the performance on each of the folds to come up with final validation metrics for the model.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_13.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_13.markups.0":{"type":"A","start":98,"end":108,"href":"http:\u002F\u002Fstatweb.stanford.edu\u002F~tibs\u002Fsta306bfiles\u002Fcvwrong.pdf","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_14":{"id":"3fbc2866411c_14","name":"f240","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:0*KH3dnbGNcmyV_ODL.png","typename":"ImageMetadata"},"text":"5 Fold Cross Validation (Source)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_14.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*KH3dnbGNcmyV_ODL.png":{"id":"0*KH3dnbGNcmyV_ODL.png","originalHeight":302,"originalWidth":1000,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_14.markups.0":{"type":"A","start":25,"end":31,"href":"https:\u002F\u002Fstackoverflow.com\u002Fquestions\u002F31947183\u002Fhow-to-implement-walk-forward-testing-in-sklearn","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_15":{"id":"3fbc2866411c_15","name":"0f63","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"For hyperparameter tuning, we perform many iterations of the entire K-Fold CV process, each time using different model settings. We then compare all of the models, select the best one, train it on the full training set, and then evaluate on the testing set. This sounds like an awfully tedious process! Each time we want to assess a different set of hyperparameters, we have to split our training data into K fold and train and evaluate K times. If we have 10 sets of hyperparameters and are using 5-Fold CV, that represents 50 training loops. Fortunately, as with most problems in machine learning, someone has solved our problem and model tuning with K-Fold CV can be automatically implemented in Scikit-Learn.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_16":{"id":"3fbc2866411c_16","name":"f804","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"Random Search Cross Validation in Scikit-Learn","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_17":{"id":"3fbc2866411c_17","name":"453d","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Usually, we only have a vague idea of the best hyperparameters and thus the best approach to narrow our search is to evaluate a wide range of values for each hyperparameter. Using Scikit-Learn’s RandomizedSearchCV method, we can define a grid of hyperparameter ranges, and randomly sample from the grid, performing K-Fold CV with each combination of values.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_18":{"id":"3fbc2866411c_18","name":"dfa9","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"As a brief recap before we get into model tuning, we are dealing with a supervised regression machine learning problem. We are trying to predict the temperature tomorrow in our city (Seattle, WA) using past historical weather data. We have 4.5 years of training data, 1.5 years of test data, and are using 6 different features (variables) to make our predictions. (To see the full code for data preparation, see the notebook).","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_18.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_18.markups.0":{"type":"A","start":416,"end":424,"href":"https:\u002F\u002Fgithub.com\u002FWillKoehrsen\u002FMachine-Learning-Projects\u002Fblob\u002Fmaster\u002Frandom_forest_explained\u002FImproving%20Random%20Forest%20Part%202.ipynb","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_19":{"id":"3fbc2866411c_19","name":"041b","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s examine the features quickly.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_20":{"id":"3fbc2866411c_20","name":"f9ac","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*Gr3BUzeZjEeS8q3G6b1pkg.png","typename":"ImageMetadata"},"text":"Features for Temperature Prediction","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*Gr3BUzeZjEeS8q3G6b1pkg.png":{"id":"1*Gr3BUzeZjEeS8q3G6b1pkg.png","originalHeight":246,"originalWidth":469,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_21":{"id":"3fbc2866411c_21","name":"ffab","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"temp_1 = max temperature (in F) one day prior","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_22":{"id":"3fbc2866411c_22","name":"7df2","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"average = historical average max temperature","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_23":{"id":"3fbc2866411c_23","name":"3053","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ws_1 = average wind speed one day prior","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_24":{"id":"3fbc2866411c_24","name":"107c","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"temp_2 = max temperature two days prior","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_25":{"id":"3fbc2866411c_25","name":"436b","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"friend = prediction from our “trusty” friend","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_26":{"id":"3fbc2866411c_26","name":"b4a5","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"year = calendar year","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_27":{"id":"3fbc2866411c_27","name":"364f","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"In previous posts, we checked the data to check for anomalies and we know our data is clean. Therefore, we can skip the data cleaning and jump straight into hyperparameter tuning.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_28":{"id":"3fbc2866411c_28","name":"2a58","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"To look at the available hyperparameters, we can create a random forest and examine the default values.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_29":{"id":"3fbc2866411c_29","name":"db88","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from sklearn.ensemble import RandomForestRegressor","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_30":{"id":"3fbc2866411c_30","name":"4adc","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"rf = RandomForestRegressor(random_state = 42)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_31":{"id":"3fbc2866411c_31","name":"6dd4","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from pprint import pprint","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_32":{"id":"3fbc2866411c_32","name":"8517","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rf.get_params())","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_33":{"id":"3fbc2866411c_33","name":"b8ef","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Parameters currently in use:\n\n{'bootstrap': True,\n 'criterion': 'mse',\n 'max_depth': None,\n 'max_features': 'auto',\n 'max_leaf_nodes': None,\n 'min_impurity_decrease': 0.0,\n 'min_impurity_split': None,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 10,\n 'n_jobs': 1,\n 'oob_score': False,\n 'random_state': 42,\n 'verbose': 0,\n 'warm_start': False}","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_33.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_33.markups.0":{"type":"STRONG","start":0,"end":397,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_34":{"id":"3fbc2866411c_34","name":"fb34","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Wow, that is quite an overwhelming list! How do we know where to start? A good place is the documentation on the random forest in Scikit-Learn. This tells us the most important settings are the number of trees in the forest (n_estimators) and the number of features considered for splitting at each leaf node (max_features). We could go read the research papers on the random forest and try to theorize the best hyperparameters, but a more efficient use of our time is just to try out a wide range of values and see what works! We will try adjusting the following set of hyperparameters:","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_34.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_34.markups.1","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_34.markups.0":{"type":"A","start":92,"end":142,"href":"http:\u002F\u002Fscikit-learn.org\u002Fstable\u002Fmodules\u002Fgenerated\u002Fsklearn.ensemble.RandomForestClassifier.html","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_34.markups.1":{"type":"A","start":346,"end":383,"href":"https:\u002F\u002Fwww.stat.berkeley.edu\u002F~breiman\u002Frandomforest2001.pdf","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_35":{"id":"3fbc2866411c_35","name":"800d","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"n_estimators = number of trees in the foreset","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_36":{"id":"3fbc2866411c_36","name":"fecf","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"max_features = max number of features considered for splitting a node","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_37":{"id":"3fbc2866411c_37","name":"1cdc","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"max_depth = max number of levels in each decision tree","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_38":{"id":"3fbc2866411c_38","name":"c398","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"min_samples_split = min number of data points placed in a node before the node is split","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_39":{"id":"3fbc2866411c_39","name":"50bb","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"min_samples_leaf = min number of data points allowed in a leaf node","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_40":{"id":"3fbc2866411c_40","name":"7fed","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"bootstrap = method for sampling data points (with or without replacement)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_41":{"id":"3fbc2866411c_41","name":"3f48","__typename":"Paragraph","type":"H4","href":null,"layout":null,"metadata":null,"text":"Random Hyperparameter Grid","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_42":{"id":"3fbc2866411c_42","name":"397d","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"To use RandomizedSearchCV, we first need to create a parameter grid to sample from during fitting:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_43":{"id":"3fbc2866411c_43","name":"5166","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from sklearn.model_selection import RandomizedSearchCV","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_44":{"id":"3fbc2866411c_44","name":"eb53","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_45":{"id":"3fbc2866411c_45","name":"3dbd","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_46":{"id":"3fbc2866411c_46","name":"cd54","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"pprint(random_grid)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_47":{"id":"3fbc2866411c_47","name":"1bc1","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"{'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_47.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_47.markups.0":{"type":"STRONG","start":0,"end":267,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_48":{"id":"3fbc2866411c_48","name":"2b8e","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"On each iteration, the algorithm will choose a difference combination of the features. Altogether, there are 2 * 12 * 2 * 3 * 3 * 10 = 4320 settings! However, the benefit of a random search is that we are not trying every combination, but selecting at random to sample a wide range of values.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_49":{"id":"3fbc2866411c_49","name":"06b1","__typename":"Paragraph","type":"H4","href":null,"layout":null,"metadata":null,"text":"Random Search Training","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_50":{"id":"3fbc2866411c_50","name":"d5b3","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, we instantiate the random search and fit it like any Scikit-Learn model:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_51":{"id":"3fbc2866411c_51","name":"d322","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestRegressor()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_52":{"id":"3fbc2866411c_52","name":"02ea","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Fit the random search model\nrf_random.fit(train_features, train_labels)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_53":{"id":"3fbc2866411c_53","name":"c328","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"The most important arguments in RandomizedSearchCV are n_iter, which controls the number of different combinations to try, and cv which is the number of folds to use for cross validation (we use 100 and 3 respectively). More iterations will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time. Machine learning is a field of trade-offs, and performance vs time is one of the most fundamental.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_54":{"id":"3fbc2866411c_54","name":"b1fa","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"We can view the best parameters from fitting the random search:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_55":{"id":"3fbc2866411c_55","name":"7ac2","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"rf_random.best_params_","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_56":{"id":"3fbc2866411c_56","name":"3c19","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"{'bootstrap': True,\n 'max_depth': 70,\n 'max_features': 'auto',\n 'min_samples_leaf': 4,\n 'min_samples_split': 10,\n 'n_estimators': 400}","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_56.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_56.markups.0":{"type":"STRONG","start":0,"end":134,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_57":{"id":"3fbc2866411c_57","name":"047b","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"From these results, we should be able to narrow the range of values for each hyperparameter.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_58":{"id":"3fbc2866411c_58","name":"6958","__typename":"Paragraph","type":"H4","href":null,"layout":null,"metadata":null,"text":"Evaluate Random Search","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_59":{"id":"3fbc2866411c_59","name":"0a6a","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"To determine if random search yielded a better model, we compare the base model with the best random search model.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_60":{"id":"3fbc2866411c_60","name":"01c7","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    errors = abs(predictions - test_labels)\n    mape = 100 * np.mean(errors \u002F test_labels)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_61":{"id":"3fbc2866411c_61","name":"beee","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\nbase_model.fit(train_features, train_labels)\nbase_accuracy = evaluate(base_model, test_features, test_labels)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_62":{"id":"3fbc2866411c_62","name":"9a7f","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Model Performance\nAverage Error: 3.9199 degrees.\nAccuracy = 93.36%.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_62.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_62.markups.0":{"type":"STRONG","start":0,"end":67,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_63":{"id":"3fbc2866411c_63","name":"b973","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"best_random = rf_random.best_estimator_\nrandom_accuracy = evaluate(best_random, test_features, test_labels)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_64":{"id":"3fbc2866411c_64","name":"6b3a","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Model Performance\nAverage Error: 3.7152 degrees.\nAccuracy = 93.73%.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_64.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_64.markups.0":{"type":"STRONG","start":0,"end":67,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_65":{"id":"3fbc2866411c_65","name":"59ed","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) \u002F base_accuracy))","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_66":{"id":"3fbc2866411c_66","name":"a144","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Improvement of 0.40%.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_66.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_66.markups.0":{"type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_67":{"id":"3fbc2866411c_67","name":"deae","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"We achieved an unspectacular improvement in accuracy of 0.4%. Depending on the application though, this could be a significant benefit. We can further improve our results by using grid search to focus on the most promising hyperparameters ranges found in the random search.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_68":{"id":"3fbc2866411c_68","name":"f5f7","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"Grid Search with Cross Validation","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_69":{"id":"3fbc2866411c_69","name":"6cb3","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Random search allowed us to narrow down the range for each hyperparameter. Now that we know where to concentrate our search, we can explicitly specify every combination of settings to try. We do this with GridSearchCV, a method that, instead of sampling randomly from a distribution, evaluates all combinations we define. To use Grid Search, we make another grid based on the best values provided by random search:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_70":{"id":"3fbc2866411c_70","name":"3178","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from sklearn.model_selection import GridSearchCV","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_71":{"id":"3fbc2866411c_71","name":"ec31","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Create the parameter grid based on the results of random search \nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_72":{"id":"3fbc2866411c_72","name":"6423","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Create a based model\nrf = RandomForestRegressor()","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_73":{"id":"3fbc2866411c_73","name":"45fc","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_74":{"id":"3fbc2866411c_74","name":"39b2","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"This will try out 1 * 4 * 2 * 3 * 3 * 4 = 288 combinations of settings. We can fit the model, display the best hyperparameters, and evaluate performance:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_75":{"id":"3fbc2866411c_75","name":"97d2","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Fit the grid search to the data\ngrid_search.fit(train_features, train_labels)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_76":{"id":"3fbc2866411c_76","name":"1f33","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"grid_search.best_params_","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_77":{"id":"3fbc2866411c_77","name":"4928","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"{'bootstrap': True,\n 'max_depth': 80,\n 'max_features': 3,\n 'min_samples_leaf': 5,\n 'min_samples_split': 12,\n 'n_estimators': 100}","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_77.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_77.markups.0":{"type":"STRONG","start":0,"end":129,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_78":{"id":"3fbc2866411c_78","name":"2b93","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"best_grid = grid_search.best_estimator_\ngrid_accuracy = evaluate(best_grid, test_features, test_labels)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_79":{"id":"3fbc2866411c_79","name":"4737","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Model Performance\nAverage Error: 3.6561 degrees.\nAccuracy = 93.83%.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_79.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_79.markups.0":{"type":"STRONG","start":0,"end":67,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_80":{"id":"3fbc2866411c_80","name":"ade6","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) \u002F base_accuracy))","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_81":{"id":"3fbc2866411c_81","name":"c438","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Improvement of 0.50%.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_81.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_81.markups.0":{"type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_82":{"id":"3fbc2866411c_82","name":"38be","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"It seems we have about maxed out performance, but we can give it one more try with a grid further refined from our previous results. The code is the same as before just with a different grid so I only present the results:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_83":{"id":"3fbc2866411c_83","name":"7b53","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Model Performance\nAverage Error: 3.6602 degrees.\nAccuracy = 93.82%.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_83.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_83.markups.0":{"type":"STRONG","start":0,"end":67,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_84":{"id":"3fbc2866411c_84","name":"795e","__typename":"Paragraph","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Improvement of 0.49%.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_84.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_84.markups.0":{"type":"STRONG","start":0,"end":21,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_85":{"id":"3fbc2866411c_85","name":"465b","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"A small decrease in performance indicates we have reached diminishing returns for hyperparameter tuning. We could continue, but the returns would be minimal at best.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_86":{"id":"3fbc2866411c_86","name":"80cf","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"Comparisons","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_87":{"id":"3fbc2866411c_87","name":"fa47","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"We can make some quick comparisons between the different approaches used to improve performance showing the returns on each. The following table shows the final results from all the improvements we made (including those from the first part):","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_88":{"id":"3fbc2866411c_88","name":"ab3e","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*vBCSIIIxyTLKzcJMiV5lKg.png","typename":"ImageMetadata"},"text":"Comparison of All Models","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*vBCSIIIxyTLKzcJMiV5lKg.png":{"id":"1*vBCSIIIxyTLKzcJMiV5lKg.png","originalHeight":375,"originalWidth":680,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_89":{"id":"3fbc2866411c_89","name":"b230","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Model is the (very unimaginative) names for the models, accuracy is the percentage accuracy, error is the average absolute error in degrees, n_features is the number of features in the dataset, n_trees is the number of decision trees in the forest, and time is the training and predicting time in seconds.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_90":{"id":"3fbc2866411c_90","name":"873f","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"The models are as follows:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_91":{"id":"3fbc2866411c_91","name":"e158","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"average: original baseline computed by predicting historical average max temperature for each day in test set","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_92":{"id":"3fbc2866411c_92","name":"4f9e","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"one_year: model trained using a single year of data","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_93":{"id":"3fbc2866411c_93","name":"7b96","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"four_years_all: model trained using 4.5 years of data and expanded features (see Part One for details)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_94":{"id":"3fbc2866411c_94","name":"a791","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"four_years_red: model trained using 4.5 years of data and subset of most important features","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_95":{"id":"3fbc2866411c_95","name":"8275","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"best_random: best model from random search with cross validation","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_96":{"id":"3fbc2866411c_96","name":"0393","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"first_grid: best model from first grid search with cross validation (selected as the final model)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_97":{"id":"3fbc2866411c_97","name":"1a2f","__typename":"Paragraph","type":"ULI","href":null,"layout":null,"metadata":null,"text":"second_grid: best model from second grid search","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_98":{"id":"3fbc2866411c_98","name":"cc37","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Overall, gathering more data and feature selection reduced the error by 17.69% while hyperparameter further reduced the error by 6.73%.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_98.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_98.markups.0":{"type":"STRONG","start":0,"end":135,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_99":{"id":"3fbc2866411c_99","name":"afb2","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*6gpuSFyshQ-shuvnOjYeGg.png","typename":"ImageMetadata"},"text":"Model Comparison (see Notebook for code)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*6gpuSFyshQ-shuvnOjYeGg.png":{"id":"1*6gpuSFyshQ-shuvnOjYeGg.png","originalHeight":475,"originalWidth":686,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_100":{"id":"3fbc2866411c_100","name":"97ab","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"In terms of programmer-hours, gathering data took about 6 hours while hyperparameter tuning took about 3 hours. As with any pursuit in life, there is a point at which pursuing further optimization is not worth the effort and knowing when to stop can be just as important as being able to keep going (sorry for getting all philosophical). Moreover, in any data problem, there is what is called the Bayes error rate, which is the absolute minimum possible error in a problem. Bayes error, also called reproducible error, is a combination of latent variables, the factors affecting a problem which we cannot measure, and inherent noise in any physical process. Creating a perfect model is therefore not possible. Nonetheless, in this example, we were able to significantly improve our model with hyperparameter tuning and we covered numerous machine learning topics which are broadly applicable.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_100.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_100.markups.0":{"type":"A","start":397,"end":413,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FBayes_error_rate","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_101":{"id":"3fbc2866411c_101","name":"f4be","__typename":"Paragraph","type":"H3","href":null,"layout":null,"metadata":null,"text":"Training Visualizations","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:3fbc2866411c_101.markups.0","typename":"Markup"}],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_101.markups.0":{"type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:3fbc2866411c_102":{"id":"3fbc2866411c_102","name":"ddb4","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"To further analyze the process of hyperparameter optimization, we can change one setting at a time and see the effect on the model performance (essentially conducting a controlled experiment). For example, we can create a grid with a range of number of trees, perform grid search CV, and then plot the results. Plotting the training and testing error and the training time will allow us to inspect how changing one hyperparameter impacts the model.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_103":{"id":"3fbc2866411c_103","name":"74fd","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"First we can look at the effect of changing the number of trees in the forest. (see notebook for training and plotting code)","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_104":{"id":"3fbc2866411c_104","name":"5679","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*mDQtEHIojnUuqiNJc0Na7w.png","typename":"ImageMetadata"},"text":"Number of Trees Training Curves","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*mDQtEHIojnUuqiNJc0Na7w.png":{"id":"1*mDQtEHIojnUuqiNJc0Na7w.png","originalHeight":334,"originalWidth":633,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_105":{"id":"3fbc2866411c_105","name":"2b9e","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"As the number of trees increases, our error decreases up to a point. There is not much benefit in accuracy to increasing the number of trees beyond 20 (our final model had 100) and the training time rises consistently.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_106":{"id":"3fbc2866411c_106","name":"310b","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"We can also examine curves for the number of features to split a node:","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_107":{"id":"3fbc2866411c_107","name":"41a3","__typename":"Paragraph","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*ZDd5Bs7ed5bZEL93xDwflA.png","typename":"ImageMetadata"},"text":"Number of Features Training Curves","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*ZDd5Bs7ed5bZEL93xDwflA.png":{"id":"1*ZDd5Bs7ed5bZEL93xDwflA.png","originalHeight":334,"originalWidth":645,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:3fbc2866411c_108":{"id":"3fbc2866411c_108","name":"d33f","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"As we increase the number of features retained, the model accuracy increases as expected. The training time also increases although not significantly.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_109":{"id":"3fbc2866411c_109","name":"f7ef","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"Together with the quantitative stats, these visuals can give us a good idea of the trade-offs we make with different combinations of hyperparameters. Although there is usually no way to know ahead of time what settings will work the best, this example has demonstrated the simple tools in Python that allow us to optimize our machine learning model.","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Paragraph:3fbc2866411c_110":{"id":"3fbc2866411c_110","name":"6513","__typename":"Paragraph","type":"P","href":null,"layout":null,"metadata":null,"text":"As always, I welcome feedback and constructive criticism. I can be reached at wjk68@case.edu","hasDropCap":null,"dropCapImage":null,"markups":[],"iframe":null,"mixtapeMetadata":null},"Tag:machine-learning":{"id":"machine-learning","displayTitle":"Machine Learning","__typename":"Tag"},"Tag:python":{"id":"python","displayTitle":"Python","__typename":"Tag"},"Tag:data-science":{"id":"data-science","displayTitle":"Data Science","__typename":"Tag"},"Tag:data":{"id":"data","displayTitle":"Data","__typename":"Tag"},"$Post:28d2aa77dd74.previewContent":{"subtitle":"Improving the Random Forest Part Two","__typename":"PreviewContent"},"data-science":{"name":"Data Science","slug":"data-science","__typename":"Topic"}}</script><script src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/manifest.8e844011.js.下載"></script><script src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/vendors_main.93cb1e58.chunk.js.下載"></script><script src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/main.be126fa7.chunk.js.下載"></script><script src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/vendors_screen.landingpages.trumpland_screen.post_screen.post.amp_screen.post.series_screen.profile__b319665e.f2be28a6.chun.下載"></script>
<script src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/screen.post_screen.post.amp_screen.post.series_screen.profile_screen.sequence.library_screen.sequenc_036c6b37.3d229283.chun.下載"></script>
<script src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/screen.landingpages.trumpland_screen.post_screen.post.amp_screen.post.series_screen.profile_screen.s_5e114ebe.4ce4f11f.chun.下載"></script>
<script src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/screen.post_screen.post.amp_screen.sequence.post.cc1a8b41.chunk.js.下載"></script>
<script src="./Hyperparameter Tuning the Random Forest in Python - Towards Data Science_files/screen.post.9cb242a3.chunk.js.下載"></script><script>window.main();</script></body></html>